{
    "Training": {
        "8_17": [
            0,
            1081,
            1197,
            1356,
            1376,
            1507,
            1682,
            1978,
            2186,
            2476,
            2737,
            2932,
            2935,
            2945,
            3023,
            3064,
            3096,
            3231,
            3487,
            3519,
            3704,
            3931,
            4179,
            4437,
            4719,
            4958,
            5468,
            5471,
            6753,
            6858,
            7869,
            8013,
            8371
        ]
    },
    "Tips": {
        "8_17": [
            1,
            2184,
            3229,
            3594,
            4112,
            5152,
            5598,
            6718,
            7263
        ]
    },
    "Transformer": {
        "8_17": [
            4,
            335,
            3734,
            6011,
            6034,
            6072,
            6390,
            6630,
            7322,
            7368,
            7404,
            7431,
            7488
        ]
    },
    "Model": {
        "8_17": [
            5,
            3341,
            3596
        ]
    },
    "Martin": {
        "8_17": [
            6,
            7624,
            7632,
            7676,
            8382
        ]
    },
    "Popel": {
        "8_17": [
            7,
            7633,
            7677,
            8383
        ]
    },
    "Ondrej": {
        "8_17": [
            8,
            7617,
            7620,
            7667,
            7668,
            7728,
            7755
        ]
    },
    "Bojar": {
        "8_17": [
            9,
            488,
            1864,
            1975,
            7616,
            7666,
            7727,
            7754
        ]
    },
    "Charles": {
        "8_17": [
            10,
            8400
        ]
    },
    "University": {
        "8_17": [
            11,
            7722,
            8401
        ]
    },
    "Faculty": {
        "8_17": [
            12,
            8395
        ]
    },
    "Mathematics": {
        "8_17": [
            14,
            8397
        ]
    },
    "Physics": {
        "8_17": [
            16,
            8399
        ]
    },
    "Institute": {
        "8_17": [
            17,
            8389
        ]
    },
    "Formal": {
        "8_17": [
            19,
            8391
        ]
    },
    "Applied": {
        "8_17": [
            21,
            8393
        ]
    },
    "Linguistics": {
        "8_17": [
            22,
            8394
        ]
    },
    "Prague": {
        "8_17": [
            23
        ]
    },
    "Czechia": {
        "8_17": [
            24
        ]
    },
    "Abstract": {
        "8_17": [
            25
        ]
    },
    "This": {
        "8_17": [
            26,
            748,
            934,
            970,
            1100,
            1144,
            2218,
            3150,
            4120,
            4495,
            5621,
            5854,
            6503,
            6538,
            6992,
            7554
        ]
    },
    "article": {
        "8_17": [
            27,
            322,
            421,
            1749,
            7472
        ]
    },
    "describes": {
        "8_17": [
            28
        ]
    },
    "our": {
        "8_17": [
            29,
            276,
            349,
            368,
            389,
            409,
            502,
            1017,
            1436,
            1801,
            1846,
            1902,
            2122,
            2177,
            2318,
            2410,
            2585,
            2642,
            2954,
            3857,
            4062,
            4528,
            4585,
            5616,
            6135,
            6240,
            6256,
            6604,
            6659,
            6987,
            7320,
            7403,
            7446
        ]
    },
    "experiments": {
        "8_17": [
            30,
            426,
            1018,
            1021,
            1596,
            1847,
            1850,
            2319,
            2327,
            2343,
            2411,
            2586,
            2661,
            2678,
            2782,
            3413,
            3858,
            3876,
            3924,
            4037,
            4263,
            4410,
            4529,
            4566,
            5628,
            5649,
            5656,
            6138,
            6174,
            6257,
            6605,
            6660,
            6740,
            6988,
            7428,
            7468,
            7540
        ]
    },
    "neural": {
        "8_17": [
            32,
            130,
            157,
            656,
            2024,
            7440,
            7900,
            7950,
            8039
        ]
    },
    "machine": {
        "8_17": [
            33,
            131,
            142,
            318,
            627,
            657,
            1007,
            5229,
            5455,
            6775,
            7441
        ]
    },
    "translation": {
        "8_17": [
            34,
            55,
            132,
            143,
            319,
            443,
            586,
            658,
            907,
            1055,
            1071,
            1080,
            1433,
            1713,
            1797,
            2484,
            2812,
            3793,
            4860,
            7317,
            7442
        ]
    },
    "using": {
        "8_17": [
            35,
            2551,
            4402,
            5231,
            5558,
            5685,
            6365,
            6668,
            6837,
            6981,
            7181,
            7333,
            7531
        ]
    },
    "recent": {
        "8_17": [
            37,
            149
        ]
    },
    "Ten": {
        "8_17": [
            38
        ]
    },
    "sorTensorframeworkandtheTransformersequence": {
        "8_17": [
            39
        ]
    },
    "sequencemodel": {
        "8_17": [
            41
        ]
    },
    "Vaswanietal": {
        "8_17": [
            42,
            251,
            700,
            6977
        ]
    },
    "examine": {
        "8_17": [
            44
        ]
    },
    "some": {
        "8_17": [
            45,
            269,
            451,
            1249,
            1849,
            2335,
            5409,
            6902,
            7046
        ]
    },
    "critical": {
        "8_17": [
            48,
            238
        ]
    },
    "parameters": {
        "8_17": [
            49,
            220,
            274,
            847,
            879,
            1345,
            2097,
            2359,
            2395,
            3060,
            3381,
            6904
        ]
    },
    "that": {
        "8_17": [
            50,
            129,
            221,
            375,
            606,
            696,
            707,
            764,
            782,
            905,
            1109,
            2339,
            2382,
            2580,
            2605,
            2681,
            3689,
            3811,
            4147,
            4344,
            4514,
            4713,
            4865,
            4945,
            5128,
            5183,
            5496,
            5537,
            5543,
            5583,
            5745,
            5892,
            5927,
            6200,
            6244,
            6579,
            6811,
            6997,
            7157,
            7195,
            7366,
            7485
        ]
    },
    "ect": {
        "8_17": [
            52,
            223,
            882,
            2686,
            2949,
            3507,
            3534,
            3842,
            3948,
            4077,
            4199,
            4460,
            4734,
            4978,
            5480,
            6680,
            6869,
            7014
        ]
    },
    "nal": {
        "8_17": [
            54,
            466,
            635,
            6748,
            7238
        ]
    },
    "quality": {
        "8_17": [
            56,
            908,
            1046,
            1072,
            1434,
            2485,
            2813,
            3803,
            7505
        ]
    },
    "memory": {
        "8_17": [
            57,
            2570,
            3619,
            3625,
            3743,
            4132,
            4826
        ]
    },
    "usage": {
        "8_17": [
            58,
            6932
        ]
    },
    "training": {
        "8_17": [
            59,
            62,
            102,
            190,
            202,
            225,
            359,
            608,
            681,
            734,
            810,
            917,
            1172,
            1177,
            1206,
            1219,
            1279,
            1285,
            1362,
            1367,
            1370,
            1399,
            1407,
            1424,
            1486,
            1525,
            1583,
            1802,
            1883,
            1896,
            2091,
            2124,
            2193,
            2211,
            2402,
            2465,
            2530,
            2598,
            2688,
            2745,
            2769,
            2854,
            2895,
            2911,
            2939,
            2942,
            2956,
            2965,
            3040,
            3085,
            3095,
            3111,
            3125,
            3200,
            3262,
            3272,
            3289,
            3297,
            3317,
            3326,
            3452,
            3550,
            3581,
            3593,
            3749,
            3825,
            3845,
            3873,
            3952,
            3998,
            4010,
            4103,
            4138,
            4145,
            4350,
            4543,
            4606,
            4770,
            4802,
            4844,
            4910,
            5032,
            5124,
            5163,
            5175,
            5302,
            5368,
            5383,
            5442,
            5460,
            5519,
            5532,
            5669,
            5844,
            6111,
            6123,
            6132,
            6195,
            6254,
            6321,
            6494,
            6641,
            6652,
            6770,
            6895,
            6923,
            6944,
            6950,
            7007,
            7062,
            7154,
            7197,
            7205,
            7216,
            7290,
            7411,
            7498,
            7516,
            7530,
            7898,
            7948
        ]
    },
    "stability": {
        "8_17": [
            60,
            186
        ]
    },
    "time": {
        "8_17": [
            63,
            765,
            826,
            967,
            1425,
            1468,
            2933,
            2936,
            3488,
            3520,
            3932,
            4043,
            4180,
            4312,
            4324,
            4438,
            4720,
            4959,
            5469,
            5472,
            6309,
            6844,
            6859,
            6999,
            7285,
            7478
        ]
    },
    "concluding": {
        "8_17": [
            64
        ]
    },
    "each": {
        "8_17": [
            65,
            427,
            1192,
            2137,
            2449,
            4086,
            7186
        ]
    },
    "experiment": {
        "8_17": [
            66,
            2353,
            2521,
            3182,
            3303,
            3358,
            3568,
            3971,
            5641
        ]
    },
    "with": {
        "8_17": [
            67,
            428,
            505,
            843,
            1019,
            1185,
            1695,
            1857,
            1894,
            1919,
            2029,
            2057,
            2222,
            2346,
            2354,
            2460,
            2574,
            2754,
            2774,
            2861,
            2899,
            2905,
            2958,
            2967,
            2973,
            3056,
            3138,
            3148,
            3183,
            3319,
            3328,
            3359,
            3410,
            3552,
            3559,
            3564,
            3587,
            3632,
            3775,
            3859,
            3877,
            3882,
            3892,
            3925,
            3964,
            4038,
            4044,
            4093,
            4140,
            4204,
            4264,
            4296,
            4320,
            4356,
            4434,
            4465,
            4491,
            4530,
            4567,
            4702,
            4747,
            4991,
            5056,
            5223,
            5248,
            5328,
            5451,
            5489,
            6007,
            6076,
            6090,
            6152,
            6474,
            6661,
            6786,
            7002,
            7283,
            7304,
            7319,
            7390,
            7429,
            7642,
            7689,
            8146,
            8174
        ]
    },
    "set": {
        "8_17": [
            69,
            423,
            430,
            637,
            910,
            1652,
            1891,
            1912,
            2179,
            2392,
            3453,
            4035,
            4231,
            4522,
            4811,
            4936,
            5432,
            5845,
            5874
        ]
    },
    "recom": {
        "8_17": [
            71
        ]
    },
    "mendations": {
        "8_17": [
            72
        ]
    },
    "fellow": {
        "8_17": [
            74
        ]
    },
    "researchers": {
        "8_17": [
            75,
            284,
            6609,
            7465
        ]
    },
    "addition": {
        "8_17": [
            77,
            6799
        ]
    },
    "con": {
        "8_17": [
            79,
            351,
            3407,
            4927,
            5287,
            5966
        ]
    },
    "rming": {
        "8_17": [
            80
        ]
    },
    "general": {
        "8_17": [
            82,
            354,
            1010,
            4510,
            5738,
            6942
        ]
    },
    "mantra": {
        "8_17": [
            83
        ]
    },
    "more": {
        "8_17": [
            84,
            379,
            472,
            728,
            786,
            793,
            2900,
            2910,
            2929,
            3618,
            4313,
            4680,
            4756,
            4763,
            5169,
            5500,
            5559,
            5627,
            6623,
            6650,
            7221,
            7450,
            7500
        ]
    },
    "data": {
        "8_17": [
            85,
            120,
            203,
            211,
            360,
            1207,
            1363,
            1584,
            1683,
            1803,
            1897,
            1999,
            2080,
            2125,
            2194,
            2912,
            2930,
            2946,
            3041,
            3273,
            3318,
            3327,
            3688,
            3826,
            3835,
            3846,
            3953,
            5369,
            5533,
            6945,
            6951,
            7206,
            7388,
            7412
        ]
    },
    "larger": {
        "8_17": [
            87,
            358,
            3353,
            7490,
            7518
        ]
    },
    "models": {
        "8_17": [
            88,
            205,
            758,
            818,
            1119,
            3354,
            3361,
            3774,
            3906,
            4092,
            4701,
            4861,
            7243,
            7392
        ]
    },
    "address": {
        "8_17": [
            90
        ]
    },
    "scaling": {
        "8_17": [
            91,
            1995,
            2982,
            2992,
            3010,
            5730,
            5806,
            5813,
            5958,
            5969,
            6032,
            6519,
            6621,
            6805
        ]
    },
    "multiple": {
        "8_17": [
            93,
            2404,
            2984,
            5224,
            5444
        ]
    },
    "GPUs": {
        "8_17": [
            94,
            377,
            2405,
            2508,
            2600,
            2837,
            2860,
            2879,
            2901,
            2906,
            2974,
            2985,
            3004,
            3061,
            3185,
            3292,
            3300,
            3526,
            3531,
            3542,
            5218,
            5225,
            5249,
            5263,
            5270,
            5323,
            5361,
            5485,
            5498,
            5560,
            5603,
            5612,
            5640,
            5648,
            5708,
            6113,
            6266,
            6366,
            6475,
            6624,
            6662,
            6727,
            6876,
            7088,
            7327,
            7534
        ]
    },
    "provide": {
        "8_17": [
            96,
            2087,
            2176,
            5916
        ]
    },
    "practical": {
        "8_17": [
            97,
            194,
            3351,
            7481
        ]
    },
    "tips": {
        "8_17": [
            98,
            2182,
            2338
        ]
    },
    "im": {
        "8_17": [
            100
        ]
    },
    "proved": {
        "8_17": [
            101
        ]
    },
    "regarding": {
        "8_17": [
            103
        ]
    },
    "batch": {
        "8_17": [
            104,
            401,
            1120,
            1143,
            1156,
            1267,
            1299,
            1388,
            2204,
            2503,
            2538,
            2554,
            2673,
            2756,
            2766,
            2776,
            2793,
            2996,
            3012,
            3492,
            3497,
            3502,
            3512,
            3524,
            3529,
            3539,
            3553,
            3560,
            3588,
            3636,
            3639,
            3757,
            4066,
            4126,
            4183,
            4186,
            4189,
            4192,
            4195,
            4202,
            4233,
            4275,
            4390,
            4441,
            4444,
            4447,
            4450,
            4453,
            4456,
            4463,
            4477,
            4485,
            4593,
            4636,
            4654,
            4665,
            4708,
            4750,
            4778,
            4796,
            4836,
            4994,
            5253,
            5265,
            5272,
            5278,
            5329,
            5546,
            5555,
            5687,
            5693,
            5749,
            5852,
            5868,
            5908,
            5943,
            6210,
            6223,
            6359,
            6383,
            6404,
            6409,
            6525,
            7491,
            7897,
            7947
        ]
    },
    "size": {
        "8_17": [
            105,
            185,
            402,
            1121,
            1300,
            1353,
            1389,
            2000,
            2108,
            2205,
            2377,
            2504,
            2511,
            2555,
            2757,
            2777,
            2794,
            2947,
            2997,
            3013,
            3347,
            3493,
            3498,
            3503,
            3510,
            3513,
            3525,
            3530,
            3537,
            3540,
            3554,
            3561,
            3589,
            3637,
            3640,
            3663,
            3698,
            3758,
            4067,
            4127,
            4184,
            4187,
            4190,
            4193,
            4196,
            4203,
            4234,
            4391,
            4442,
            4445,
            4448,
            4451,
            4454,
            4457,
            4464,
            4478,
            4486,
            4594,
            4637,
            4655,
            4666,
            4709,
            4751,
            4779,
            4797,
            4808,
            4837,
            4995,
            5254,
            5266,
            5273,
            5279,
            5330,
            5547,
            5556,
            5688,
            5694,
            5750,
            5846,
            5853,
            5869,
            5909,
            5944,
            6211,
            6224,
            6360
        ]
    },
    "learning": {
        "8_17": [
            106,
            398,
            628,
            1636,
            2487,
            2951,
            3887,
            4016,
            4508,
            4631,
            4722,
            4724,
            4726,
            4728,
            4730,
            4737,
            4856,
            4997,
            5011,
            5036,
            5058,
            5067,
            5180,
            5191,
            5199,
            5331,
            5589,
            5726,
            5757,
            5786,
            5840,
            5900,
            6053,
            6081,
            6095,
            6108,
            6116,
            6159,
            6182,
            6207,
            6216,
            6249,
            6284,
            6302,
            6335,
            6487,
            6559,
            6583,
            6596,
            6632,
            6666,
            6847,
            6928,
            6969,
            7066
        ]
    },
    "rate": {
        "8_17": [
            107,
            399,
            4017,
            4632,
            4723,
            4725,
            4727,
            4729,
            4731,
            4738,
            4857,
            4881,
            4998,
            5012,
            5037,
            5059,
            5181,
            5192,
            5200,
            5332,
            5590,
            5727,
            5758,
            5787,
            5841,
            5901,
            6054,
            6082,
            6096,
            6109,
            6117,
            6160,
            6183,
            6208,
            6217,
            6250,
            6285,
            6303,
            6336,
            6488,
            6560,
            6584,
            6597,
            6633,
            6667,
            6804,
            6848,
            6929,
            6970
        ]
    },
    "warmup": {
        "8_17": [
            108,
            4753,
            4961,
            4964,
            4967,
            4970,
            4973,
            4981,
            5045,
            5170,
            5187,
            5334,
            5592,
            6550,
            6564,
            6572,
            6619,
            6634,
            6651,
            6670,
            6702
        ]
    },
    "steps": {
        "8_17": [
            109,
            682,
            1280,
            1286,
            1294,
            2714,
            2838,
            4321,
            4754,
            4962,
            4965,
            4968,
            4971,
            4974,
            4982,
            5008,
            5046,
            5171,
            5176,
            5188,
            5303,
            5335,
            5593,
            6060,
            6376,
            6459,
            6463,
            6551,
            6573,
            6671,
            6703,
            6828,
            6838,
            6914,
            7234
        ]
    },
    "maximum": {
        "8_17": [
            110,
            395,
            1239,
            2130,
            2797,
            3634,
            3638,
            3657,
            5197,
            6581
        ]
    },
    "sentence": {
        "8_17": [
            111,
            396,
            1233,
            1812,
            1820,
            1842,
            1869,
            2138,
            2960,
            2969,
            3658
        ]
    },
    "length": {
        "8_17": [
            112,
            397,
            3659,
            3848,
            3935,
            3937,
            3939,
            3941,
            3943,
            3945
        ]
    },
    "andcheckpointaveraging": {
        "8_17": [
            113
        ]
    },
    "Wehopethatourobservationswillallowotherstogetbetterresults": {
        "8_17": [
            114
        ]
    },
    "given": {
        "8_17": [
            115,
            589,
            684,
            1460,
            1477,
            1726,
            1768,
            1952,
            2216,
            2520,
            3694,
            4251,
            6057,
            6491
        ]
    },
    "their": {
        "8_17": [
            116,
            771,
            2237,
            5338,
            5995
        ]
    },
    "particular": {
        "8_17": [
            117,
            345,
            1060
        ]
    },
    "hardware": {
        "8_17": [
            118,
            976,
            1328,
            3055
        ]
    },
    "constraints": {
        "8_17": [
            121
        ]
    },
    "Introduction": {
        "8_17": [
            122
        ]
    },
    "It": {
        "8_17": [
            123,
            778,
            1498,
            4828
        ]
    },
    "been": {
        "8_17": [
            125,
            1990,
            2002
        ]
    },
    "already": {
        "8_17": [
            126,
            5389
        ]
    },
    "clearly": {
        "8_17": [
            127,
            3118,
            3202,
            4279,
            5385
        ]
    },
    "established": {
        "8_17": [
            128
        ]
    },
    "NMT": {
        "8_17": [
            133,
            599,
            610,
            1996,
            4504,
            6006,
            7099
        ]
    },
    "new": {
        "8_17": [
            136,
            1957,
            4087
        ]
    },
    "state": {
        "8_17": [
            137,
            1921
        ]
    },
    "art": {
        "8_17": [
            140,
            1924
        ]
    },
    "see": {
        "8_17": [
            144,
            1784,
            2035,
            2148,
            2225,
            2412,
            2427,
            2451,
            2469,
            2579,
            2620,
            2817,
            4398,
            4572,
            5417,
            5495,
            5594,
            6429,
            7349,
            7365
        ]
    },
    "e": {
        "8_17": [
            145,
            295,
            356,
            373,
            671,
            698,
            783,
            1089,
            1297,
            1386,
            1729,
            1948,
            2036,
            2438,
            2634,
            2903,
            2948,
            3239,
            3841,
            4076,
            4309,
            4624,
            4792,
            5251,
            5276,
            5352,
            5376,
            5522,
            5783,
            5850,
            5906,
            5941,
            5991,
            6150,
            6233,
            6330,
            6357,
            6362,
            6523,
            6610,
            6679,
            6763,
            7013,
            7350,
            7393,
            7819,
            7954,
            8083,
            8179
        ]
    },
    "g": {
        "8_17": [
            146,
            296,
            357,
            374,
            672,
            699,
            784,
            1730,
            2037,
            2904,
            3240,
            4383,
            5833,
            5992,
            6151,
            6234,
            6331,
            6363,
            6611,
            6764,
            7351,
            7394
        ]
    },
    "most": {
        "8_17": [
            148,
            477,
            1845,
            6085,
            6299,
            6788
        ]
    },
    "evaluation": {
        "8_17": [
            150,
            1535,
            2079,
            2459,
            7177,
            7299,
            7344
        ]
    },
    "campaigns": {
        "8_17": [
            151
        ]
    },
    "Bojaretal": {
        "8_17": [
            152
        ]
    },
    "Cettoloetal": {
        "8_17": [
            154
        ]
    },
    "Manyfundamentalchangesofthe": {
        "8_17": [
            155
        ]
    },
    "underlying": {
        "8_17": [
            156
        ]
    },
    "network": {
        "8_17": [
            158,
            1011,
            1355,
            2025
        ]
    },
    "architecture": {
        "8_17": [
            159
        ]
    },
    "nevertheless": {
        "8_17": [
            161
        ]
    },
    "still": {
        "8_17": [
            162,
            1252,
            1944,
            2897,
            4053,
            4372,
            6396
        ]
    },
    "frequent": {
        "8_17": [
            163
        ]
    },
    "it": {
        "8_17": [
            165,
            639,
            717,
            893,
            1210,
            1447,
            1466,
            1589,
            2028,
            2047,
            2055,
            3409,
            3472,
            3484,
            3750,
            3910,
            3979,
            4934,
            5023,
            5403,
            5411,
            5452,
            5634,
            6163,
            6645,
            6685,
            7031,
            7070,
            7155,
            7268,
            7275,
            7381
        ]
    },
    "very": {
        "8_17": [
            167,
            868,
            872,
            1401,
            1992
        ]
    },
    "di": {
        "8_17": [
            168,
            768,
            815,
            851,
            1001,
            2372,
            2431,
            3236,
            3376,
            3400,
            3571,
            4330,
            4366,
            4574,
            4589,
            4694,
            4757,
            4874,
            5319,
            5798,
            6016,
            6388,
            6773
        ]
    },
    "cult": {
        "8_17": [
            169,
            4758,
            6389
        ]
    },
    "predict": {
        "8_17": [
            171
        ]
    },
    "which": {
        "8_17": [
            172,
            1470,
            1969,
            2277,
            2371,
            2396,
            2445,
            2455,
            3276,
            3330,
            3375,
            3721,
            3797,
            3894,
            4432,
            4595,
            4599,
            4892,
            5772,
            5870,
            5887,
            6025,
            6905,
            7226
        ]
    },
    "architectures": {
        "8_17": [
            175
        ]
    },
    "best": {
        "8_17": [
            178,
            341,
            859,
            1903,
            7138,
            7321,
            7372,
            7526
        ]
    },
    "combination": {
        "8_17": [
            179
        ]
    },
    "properties": {
        "8_17": [
            181
        ]
    },
    "towininthelongterm": {
        "8_17": [
            182
        ]
    },
    "consideringallrelevantcriterialiketranslationquality": {
        "8_17": [
            183
        ]
    },
    "model": {
        "8_17": [
            184,
            287,
            336,
            632,
            693,
            788,
            1062,
            1352,
            1411,
            1904,
            2380,
            2420,
            2510,
            2541,
            2548,
            2559,
            2565,
            2691,
            2716,
            2820,
            2836,
            2864,
            2871,
            2976,
            3346,
            3385,
            3417,
            3459,
            3491,
            3496,
            3501,
            3509,
            3523,
            3528,
            3536,
            3604,
            3662,
            3967,
            4207,
            4271,
            4468,
            4482,
            4533,
            4570,
            4716,
            4943,
            5136,
            5327,
            7225,
            7323,
            7369,
            7432,
            7489
        ]
    },
    "speed": {
        "8_17": [
            188,
            1323,
            1330,
            1349,
            1395,
            1416,
            1533,
            2513,
            2528,
            2637,
            2653,
            2713,
            2743,
            2752,
            2831,
            2852,
            2892,
            4554
        ]
    },
    "interpretability": {
        "8_17": [
            191
        ]
    },
    "but": {
        "8_17": [
            192,
            212,
            513,
            685,
            891,
            1014,
            3009,
            3117,
            3201,
            3471,
            3978,
            3999,
            4041,
            4080,
            4371,
            4415,
            4549,
            4678,
            5115,
            5401,
            5446,
            5684,
            6161,
            6395,
            6644,
            6695,
            7170,
            7235,
            7499
        ]
    },
    "also": {
        "8_17": [
            193,
            213,
            281,
            504,
            1102,
            2816,
            3167,
            3179,
            3457,
            4550,
            5194,
            5440,
            6000,
            6469,
            6561,
            6793,
            6897,
            6994,
            7525
        ]
    },
    "availability": {
        "8_17": [
            195
        ]
    },
    "goodimplementations": {
        "8_17": [
            197
        ]
    },
    "Aconsiderablepartofamodelssuccessintranslationquality": {
        "8_17": [
            198
        ]
    },
    "consists": {
        "8_17": [
            199
        ]
    },
    "sensitivity": {
        "8_17": [
            206,
            4706
        ]
    },
    "noise": {
        "8_17": [
            208,
            4621,
            5831,
            5855,
            5886
        ]
    },
    "wide": {
        "8_17": [
            216
        ]
    },
    "range": {
        "8_17": [
            217,
            4870,
            5151,
            5938,
            7425
        ]
    },
    "hyper": {
        "8_17": [
            219,
            273,
            846,
            2358,
            2394,
            2423,
            3059,
            3380,
            3398,
            6778,
            6903
        ]
    },
    "Having": {
        "8_17": [
            226
        ]
    },
    "right": {
        "8_17": [
            228,
            3345,
            7395
        ]
    },
    "setting": {
        "8_17": [
            229,
            346,
            2791,
            3812,
            3855,
            6502,
            6657
        ]
    },
    "them": {
        "8_17": [
            231,
            1038,
            5101
        ]
    },
    "turns": {
        "8_17": [
            232
        ]
    },
    "out": {
        "8_17": [
            233,
            1057,
            2568,
            3741,
            4130,
            4824,
            6104
        ]
    },
    "often": {
        "8_17": [
            236
        ]
    },
    "component": {
        "8_17": [
            239
        ]
    },
    "success": {
        "8_17": [
            242
        ]
    },
    "arXiv": {
        "8_17": [
            243
        ]
    },
    "v": {
        "8_17": [
            244,
            529,
            1663,
            1669,
            2348
        ]
    },
    "cs": {
        "8_17": [
            245,
            570,
            1875
        ]
    },
    "CL": {
        "8_17": [
            246
        ]
    },
    "May": {
        "8_17": [
            247,
            7658
        ]
    },
    "Inthisarticle": {
        "8_17": [
            248
        ]
    },
    "weexperimentwitharelativelynewNMTmodel": {
        "8_17": [
            249
        ]
    },
    "calledTransformer": {
        "8_17": [
            250
        ]
    },
    "asimplementedintheTensorTensor": {
        "8_17": [
            252
        ]
    },
    "one": {
        "8_17": [
            253,
            470,
            532,
            809,
            813,
            1078,
            1142,
            1155,
            1176,
            1195,
            1201,
            1645,
            1708,
            1814,
            1961,
            2110,
            2112,
            2195,
            2242,
            2246,
            2248,
            2267,
            2308,
            2414,
            2471,
            2522,
            2576,
            2582,
            2613,
            2627,
            2658,
            3132,
            3173,
            3286,
            3308,
            3339,
            3430,
            3547,
            3612,
            3781,
            3870,
            3899,
            5639,
            5732,
            5753,
            6307,
            6418
        ]
    },
    "superior": {
        "8_17": [
            254,
            1815,
            2111,
            2196,
            2198,
            2243,
            2245,
            2247,
            2268,
            2309,
            2415,
            2472,
            2523,
            3133,
            3340,
            3431,
            3780,
            3898,
            4029,
            4031,
            4170,
            4237,
            4380,
            5215,
            5962,
            6037,
            6306,
            6373,
            6417,
            6443,
            6535,
            6537,
            6796
        ]
    },
    "abbreviatedTT": {
        "8_17": [
            255
        ]
    },
    "toolkit": {
        "8_17": [
            256
        ]
    },
    "version": {
        "8_17": [
            257,
            578,
            1337,
            1340,
            1810,
            4253
        ]
    },
    "Themodelandthetoolkithavebeenreleasedshortlyaftertheevaluation": {
        "8_17": [
            258
        ]
    },
    "campaignatWMT": {
        "8_17": [
            259
        ]
    },
    "two": {
        "8_17": [
            260,
            376,
            538,
            1704,
            2197,
            2269,
            2355,
            2823,
            3082,
            3122,
            3177,
            3184,
            3197,
            3299,
            3360,
            3362,
            3454,
            3674,
            3779,
            3806,
            3897,
            4028,
            4030,
            4169,
            4171,
            4236,
            4272,
            4379,
            4405,
            4407,
            4603,
            4932,
            4947,
            5214,
            5235,
            5262,
            5393,
            5424,
            5497,
            5573,
            5647,
            5659,
            5961,
            6036,
            6129,
            6374,
            6444,
            7219
        ]
    },
    "superioranditsbehavioronlarge": {
        "8_17": [
            261
        ]
    },
    "datanewstranslationisnotyetfully": {
        "8_17": [
            262
        ]
    },
    "explored": {
        "8_17": [
            263
        ]
    },
    "want": {
        "8_17": [
            265,
            6554,
            6783
        ]
    },
    "empirically": {
        "8_17": [
            267,
            3767,
            5290,
            6105
        ]
    },
    "explore": {
        "8_17": [
            268
        ]
    },
    "important": {
        "8_17": [
            272,
            2501,
            3349,
            6029
        ]
    },
    "Hopefully": {
        "8_17": [
            275
        ]
    },
    "observations": {
        "8_17": [
            277,
            350,
            369,
            7482
        ]
    },
    "will": {
        "8_17": [
            278,
            2233,
            2800,
            4368,
            6585,
            6887
        ]
    },
    "useful": {
        "8_17": [
            280,
            7462
        ]
    },
    "other": {
        "8_17": [
            283,
            3412,
            4503,
            5877,
            6015,
            7391,
            7464,
            7480
        ]
    },
    "considering": {
        "8_17": [
            285,
            5580
        ]
    },
    "this": {
        "8_17": [
            286,
            321,
            344,
            562,
            1225,
            1441,
            1748,
            1752,
            1838,
            2043,
            2114,
            2322,
            2803,
            3165,
            3447,
            3854,
            4026,
            4042,
            4049,
            4081,
            4786,
            5150,
            5289,
            5576,
            5697,
            5923,
            6277,
            6453,
            6577,
            6599,
            6750,
            6833,
            7254,
            7458,
            7471
        ]
    },
    "framework": {
        "8_17": [
            289
        ]
    },
    "Whileinvestigationsintothee": {
        "8_17": [
            290
        ]
    },
    "ectofhyper": {
        "8_17": [
            291
        ]
    },
    "parameterslikelearningrateandbatch": {
        "8_17": [
            292
        ]
    },
    "sizeareavailableinthedeep": {
        "8_17": [
            293
        ]
    },
    "learningcommunity": {
        "8_17": [
            294,
            2013
        ]
    },
    "Bottouetal": {
        "8_17": [
            297
        ]
    },
    "Smithand": {
        "8_17": [
            298
        ]
    },
    "Le": {
        "8_17": [
            299,
            4614,
            8193,
            8231,
            8310
        ]
    },
    "Jastrzebski": {
        "8_17": [
            300,
            6196,
            7966
        ]
    },
    "et": {
        "8_17": [
            301,
            489,
            674,
            1865,
            1976,
            2039,
            2071,
            4512,
            4617,
            5964,
            6068,
            6197,
            6237,
            6613,
            6808,
            7434
        ]
    },
    "al": {
        "8_17": [
            302,
            490,
            675,
            1866,
            1977,
            2040,
            2072,
            4513,
            4618,
            5965,
            6069,
            6198,
            6238,
            6614,
            6809,
            7435
        ]
    },
    "these": {
        "8_17": [
            303,
            2018,
            2660,
            2781,
            4565,
            6173
        ]
    },
    "either": {
        "8_17": [
            305,
            755
        ]
    },
    "mostly": {
        "8_17": [
            306,
            5718
        ]
    },
    "theoretic": {
        "8_17": [
            307
        ]
    },
    "or": {
        "8_17": [
            308,
            388,
            471,
            643,
            742,
            812,
            951,
            1157,
            2306,
            3259,
            3293,
            3562,
            3617,
            3665,
            3670,
            3879,
            3884,
            4158,
            4658,
            4917,
            4920,
            5168,
            5298,
            5652,
            5734,
            6221,
            6245,
            6320,
            6712,
            6776,
            7220,
            7451
        ]
    },
    "experimentally": {
        "8_17": [
            309
        ]
    },
    "supported": {
        "8_17": [
            310,
            7557
        ]
    },
    "from": {
        "8_17": [
            311,
            1000,
            1009,
            1805,
            1823,
            1906,
            2301,
            2887,
            2999,
            3011,
            5047,
            5548,
            5569,
            5731,
            5859,
            6118,
            6262,
            6507,
            6832,
            6940,
            7026,
            7112,
            7199
        ]
    },
    "domains": {
        "8_17": [
            312
        ]
    },
    "like": {
        "8_17": [
            313
        ]
    },
    "image": {
        "8_17": [
            314
        ]
    },
    "recognition": {
        "8_17": [
            315
        ]
    },
    "rather": {
        "8_17": [
            316,
            715,
            1536,
            5644
        ]
    },
    "than": {
        "8_17": [
            317,
            380,
            384,
            802,
            1537,
            1573,
            2214,
            2556,
            2593,
            2988,
            3192,
            3214,
            3478,
            3546,
            3557,
            3585,
            3611,
            3692,
            3891,
            3907,
            4682,
            4956,
            5501,
            5505,
            5565,
            5645,
            5690,
            5956,
            7036,
            7168
        ]
    },
    "ll": {
        "8_17": [
            324
        ]
    },
    "gap": {
        "8_17": [
            326,
            6817,
            7894,
            7944
        ]
    },
    "by": {
        "8_17": [
            327,
            603,
            1058,
            1074,
            1295,
            1303,
            1314,
            1365,
            1384,
            1506,
            1731,
            2004,
            2069,
            2273,
            2499,
            4287,
            4634,
            4938,
            5465,
            5557,
            5675,
            5751,
            5788,
            6146,
            6235,
            6337,
            6364,
            6574,
            6635,
            6891,
            6910,
            6938,
            7042,
            7122,
            7558,
            7576,
            7605
        ]
    },
    "focusing": {
        "8_17": [
            328
        ]
    },
    "exclusively": {
        "8_17": [
            329
        ]
    },
    "MT": {
        "8_17": [
            331
        ]
    },
    "only": {
        "8_17": [
            337,
            1256,
            1275,
            2304,
            2783,
            3037,
            3819,
            3828,
            4375,
            4540,
            4608,
            6540,
            7495
        ]
    },
    "providing": {
        "8_17": [
            338
        ]
    },
    "hopefully": {
        "8_17": [
            339
        ]
    },
    "practices": {
        "8_17": [
            342
        ]
    },
    "Some": {
        "8_17": [
            347,
            366,
            984
        ]
    },
    "rm": {
        "8_17": [
            352,
            5967
        ]
    },
    "wisdom": {
        "8_17": [
            355
        ]
    },
    "aregenerallybetter": {
        "8_17": [
            361
        ]
    },
    "andquantifythebehavioronEnglish": {
        "8_17": [
            362
        ]
    },
    "Czechtranslationexper": {
        "8_17": [
            364
        ]
    },
    "iments": {
        "8_17": [
            365
        ]
    },
    "somewhat": {
        "8_17": [
            371,
            727,
            3212,
            5405
        ]
    },
    "surprising": {
        "8_17": [
            372,
            5578
        ]
    },
    "three": {
        "8_17": [
            381,
            520,
            544,
            1824,
            1927,
            1936,
            2244,
            2310,
            2500,
            3460,
            3578,
            4097,
            4238,
            4381,
            5283,
            5502,
            6070,
            6305,
            6372,
            6381,
            6416,
            6442,
            6534,
            6536,
            6795,
            6797
        ]
    },
    "times": {
        "8_17": [
            382,
            1093,
            1571,
            2824,
            2909,
            2928,
            3008,
            3022,
            3069,
            3332,
            3461,
            3466,
            3904,
            4310,
            5256,
            5503,
            5530,
            6361
        ]
    },
    "faster": {
        "8_17": [
            383,
            2241,
            2468,
            4541,
            4551,
            5345,
            5504,
            7009,
            7497
        ]
    },
    "single": {
        "8_17": [
            386,
            932,
            2534,
            2749,
            2918,
            3001,
            3017,
            3265,
            3516,
            3962,
            4212,
            4266,
            4473,
            4741,
            4985,
            5131,
            5454,
            5507,
            5654,
            5672,
            6136,
            6264,
            6500,
            6592,
            6639,
            6738,
            7538
        ]
    },
    "GPU": {
        "8_17": [
            387,
            1329,
            1331,
            2535,
            2750,
            2763,
            2883,
            2919,
            3002,
            3018,
            3266,
            3494,
            3499,
            3504,
            3517,
            3622,
            3762,
            3963,
            4213,
            4267,
            4474,
            4742,
            4853,
            4986,
            5132,
            5246,
            5474,
            5475,
            5476,
            5477,
            5508,
            5655,
            5668,
            5673,
            5733,
            6137,
            6501,
            6593,
            6640,
            6656,
            6739,
            7477,
            7514,
            7539
        ]
    },
    "ndings": {
        "8_17": [
            390
        ]
    },
    "about": {
        "8_17": [
            391,
            1570,
            2170,
            3080,
            3152,
            4304,
            6186,
            7043,
            7272,
            7474
        ]
    },
    "interaction": {
        "8_17": [
            393
        ]
    },
    "between": {
        "8_17": [
            394,
            817,
            1627,
            4332,
            4592,
            4696
        ]
    },
    "Thearticleisstructuredasfollows": {
        "8_17": [
            403
        ]
    },
    "InSection": {
        "8_17": [
            404
        ]
    },
    "wediscussourevaluationmethod": {
        "8_17": [
            405
        ]
    },
    "ologyandmaincriteria": {
        "8_17": [
            406
        ]
    },
    "translationqualityandspeedoftraining": {
        "8_17": [
            407
        ]
    },
    "Sectiondescribes": {
        "8_17": [
            408
        ]
    },
    "dataset": {
        "8_17": [
            410,
            1839,
            2152,
            2957,
            2966,
            3068,
            3100,
            3147,
            3157,
            3309,
            3313,
            4088
        ]
    },
    "its": {
        "8_17": [
            412,
            803,
            1579,
            1618,
            2058,
            6733,
            7360
        ]
    },
    "preparations": {
        "8_17": [
            413
        ]
    },
    "Section": {
        "8_17": [
            414,
            439,
            1785,
            1899,
            2149,
            2226,
            2413,
            2435,
            2452,
            2470,
            2806,
            4013,
            4639,
            5005,
            5239,
            5313,
            6139,
            6643,
            7208,
            7302
        ]
    },
    "main": {
        "8_17": [
            417,
            1344,
            2123,
            2955,
            3325,
            4841
        ]
    },
    "contribution": {
        "8_17": [
            418
        ]
    },
    "commented": {
        "8_17": [
            425
        ]
    },
    "recommendations": {
        "8_17": [
            432
        ]
    },
    "Finally": {
        "8_17": [
            433
        ]
    },
    "Sec": {
        "8_17": [
            434
        ]
    },
    "tioncomparesourbestTransformerrunwithsystemsparticipatinginWMT": {
        "8_17": [
            435
        ]
    },
    "conclude": {
        "8_17": [
            437,
            5127
        ]
    },
    "Evaluation": {
        "8_17": [
            440,
            1511,
            8102
        ]
    },
    "Methodology": {
        "8_17": [
            441
        ]
    },
    "Machine": {
        "8_17": [
            442,
            7603,
            7775,
            7815,
            8059,
            8104,
            8141
        ]
    },
    "evaluated": {
        "8_17": [
            446,
            500,
            705,
            7332
        ]
    },
    "many": {
        "8_17": [
            448,
            5611,
            6608,
            7533
        ]
    },
    "ways": {
        "8_17": [
            449,
            1705
        ]
    },
    "forms": {
        "8_17": [
            452
        ]
    },
    "human": {
        "8_17": [
            454,
            473
        ]
    },
    "judgment": {
        "8_17": [
            455
        ]
    },
    "should": {
        "8_17": [
            456,
            1412,
            3627,
            3850,
            4082,
            4809,
            5754
        ]
    },
    "always": {
        "8_17": [
            458,
            980,
            1989,
            2328,
            4230,
            7034
        ]
    },
    "used": {
        "8_17": [
            459,
            1702,
            1940,
            2507,
            2663,
            3727
        ]
    },
    "ultimate": {
        "8_17": [
            462
        ]
    },
    "resolution": {
        "8_17": [
            463
        ]
    },
    "any": {
        "8_17": [
            465,
            662,
            2922,
            3973,
            4426,
            5064,
            5735,
            5792,
            5940,
            6177,
            7175,
            7385
        ]
    },
    "application": {
        "8_17": [
            467
        ]
    },
    "ThecommonpracticeinMTresearchistoevaluatethemodelperformanceonatestset": {
        "8_17": [
            468
        ]
    },
    "against": {
        "8_17": [
            469,
            963,
            1077,
            4498
        ]
    },
    "reference": {
        "8_17": [
            474,
            585,
            1079,
            1717
        ]
    },
    "translations": {
        "8_17": [
            475,
            1723
        ]
    },
    "widespread": {
        "8_17": [
            478
        ]
    },
    "automatic": {
        "8_17": [
            479,
            1049,
            7295,
            7339,
            7343,
            7551
        ]
    },
    "metricisundoubtedlytheBLEUscore": {
        "8_17": [
            480
        ]
    },
    "Papinenietal": {
        "8_17": [
            481
        ]
    },
    "despiteitsacknowledged": {
        "8_17": [
            482
        ]
    },
    "problems": {
        "8_17": [
            483
        ]
    },
    "better": {
        "8_17": [
            485,
            2592,
            3119,
            3203,
            3476,
            3556,
            3584,
            4280,
            4488,
            5636,
            5955,
            7035,
            7072,
            7132,
            7164,
            7502,
            7890,
            7940
        ]
    },
    "performing": {
        "8_17": [
            486
        ]
    },
    "alternatives": {
        "8_17": [
            487
        ]
    },
    "b": {
        "8_17": [
            491,
            2736,
            4341,
            7780
        ]
    },
    "simplicity": {
        "8_17": [
            493
        ]
    },
    "stick": {
        "8_17": [
            495
        ]
    },
    "BLEU": {
        "8_17": [
            497,
            558,
            565,
            911,
            961,
            1075,
            1438,
            1461,
            1472,
            1497,
            1561,
            1576,
            1625,
            2486,
            2931,
            2950,
            3078,
            3128,
            3282,
            3486,
            3518,
            3576,
            3868,
            3886,
            3930,
            4079,
            4178,
            4284,
            4436,
            4523,
            4670,
            4718,
            4957,
            5297,
            5316,
            5359,
            5373,
            5467,
            5486,
            5607,
            6124,
            6189,
            6683,
            6708,
            6749,
            6857,
            7044,
            7056,
            7082,
            7278,
            7354,
            7375,
            8096
        ]
    },
    "too": {
        "8_17": [
            498,
            2294,
            4019,
            4156,
            4882,
            5102,
            6219,
            6226,
            6973
        ]
    },
    "results": {
        "8_17": [
            503,
            860,
            884,
            950,
            1738,
            3104,
            3120,
            3191,
            3204,
            3255,
            3310,
            3477,
            3816,
            4054,
            4257,
            4489,
            4889,
            5107,
            5294,
            5814,
            7134,
            7165,
            7192,
            7310,
            7417
        ]
    },
    "c": {
        "8_17": [
            506,
            1013
        ]
    },
    "sc": {
        "8_17": [
            507,
            509
        ]
    },
    "h": {
        "8_17": [
            508
        ]
    },
    "r": {
        "8_17": [
            510
        ]
    },
    "scF": {
        "8_17": [
            511
        ]
    },
    "Popovic": {
        "8_17": [
            512,
            8113
        ]
    },
    "foundnosubstantialdi": {
        "8_17": [
            514
        ]
    },
    "erencesfromBLEU": {
        "8_17": [
            515
        ]
    },
    "Inparticular": {
        "8_17": [
            516
        ]
    },
    "weusethecase": {
        "8_17": [
            517
        ]
    },
    "insensitive": {
        "8_17": [
            518,
            960
        ]
    },
    "sacrBLEU": {
        "8_17": [
            519,
            1694
        ]
    },
    "superiorwhich": {
        "8_17": [
            521
        ]
    },
    "uses": {
        "8_17": [
            522,
            2418,
            2868,
            6035,
            6073,
            6631,
            7405
        ]
    },
    "xed": {
        "8_17": [
            524,
            1061,
            5336,
            5414
        ]
    },
    "tokenization": {
        "8_17": [
            525,
            580,
            1562,
            1696,
            1985
        ]
    },
    "identical": {
        "8_17": [
            526
        ]
    },
    "mteval": {
        "8_17": [
            528
        ]
    },
    "pl": {
        "8_17": [
            530
        ]
    },
    "interna": {
        "8_17": [
            531
        ]
    },
    "superiorhttps": {
        "8_17": [
            533,
            545,
            4172
        ]
    },
    "github": {
        "8_17": [
            534,
            546,
            1269,
            2622,
            4173,
            5419
        ]
    },
    "com": {
        "8_17": [
            535,
            547,
            1270,
            2623,
            2890,
            4174,
            5420
        ]
    },
    "tensorflow": {
        "8_17": [
            536,
            1271,
            2624,
            4175,
            5421,
            6432
        ]
    },
    "tensortensor": {
        "8_17": [
            537,
            1272,
            2625,
            4176,
            5422
        ]
    },
    "superiorhttp": {
        "8_17": [
            539,
            1962
        ]
    },
    "www": {
        "8_17": [
            540,
            2263,
            6431,
            8160
        ]
    },
    "statmt": {
        "8_17": [
            541,
            7125
        ]
    },
    "org": {
        "8_17": [
            542,
            6433,
            7126,
            7800,
            7825,
            7877,
            7964,
            7994,
            8029,
            8046,
            8068,
            8130,
            8162,
            8185,
            8220,
            8245,
            8354,
            8377
        ]
    },
    "wmt": {
        "8_17": [
            543,
            575,
            1715,
            3687
        ]
    },
    "awslabs": {
        "8_17": [
            548
        ]
    },
    "sockeye": {
        "8_17": [
            549
        ]
    },
    "tree": {
        "8_17": [
            550
        ]
    },
    "master": {
        "8_17": [
            551,
            1934
        ]
    },
    "contrib": {
        "8_17": [
            552
        ]
    },
    "sacrebleu": {
        "8_17": [
            553
        ]
    },
    "signature": {
        "8_17": [
            555
        ]
    },
    "scores": {
        "8_17": [
            559,
            933,
            7110
        ]
    },
    "reported": {
        "8_17": [
            560,
            2588,
            6232,
            6272
        ]
    },
    "paper": {
        "8_17": [
            563,
            1044,
            7936,
            8295
        ]
    },
    "case": {
        "8_17": [
            566,
            959,
            1437,
            4007,
            4050,
            4063,
            4586,
            4652,
            4663,
            5160,
            6454
        ]
    },
    "lc": {
        "8_17": [
            567
        ]
    },
    "lang": {
        "8_17": [
            568
        ]
    },
    "en": {
        "8_17": [
            569,
            1874
        ]
    },
    "numrefs": {
        "8_17": [
            571
        ]
    },
    "smooth": {
        "8_17": [
            572
        ]
    },
    "exp": {
        "8_17": [
            573
        ]
    },
    "test": {
        "8_17": [
            574,
            636,
            909,
            1651,
            2671,
            3651,
            3686,
            3834,
            4521,
            5873
        ]
    },
    "tok": {
        "8_17": [
            576
        ]
    },
    "intl": {
        "8_17": [
            577,
            1697
        ]
    },
    "tional": {
        "8_17": [
            579
        ]
    },
    "automatically": {
        "8_17": [
            582
        ]
    },
    "downloads": {
        "8_17": [
            583
        ]
    },
    "WMT": {
        "8_17": [
            590,
            1886,
            1915,
            7116,
            7305,
            7312,
            7414,
            7545,
            7746,
            7764
        ]
    },
    "testset": {
        "8_17": [
            591
        ]
    },
    "Considerations": {
        "8_17": [
            592
        ]
    },
    "Stopping": {
        "8_17": [
            594
        ]
    },
    "Criterion": {
        "8_17": [
            595
        ]
    },
    "situation": {
        "8_17": [
            597
        ]
    },
    "further": {
        "8_17": [
            601,
            3923,
            6164
        ]
    },
    "complicated": {
        "8_17": [
            602
        ]
    },
    "fact": {
        "8_17": [
            605,
            5582,
            7194
        ]
    },
    "systemsisusuallynon": {
        "8_17": [
            611
        ]
    },
    "deterministic": {
        "8_17": [
            612
        ]
    },
    "esp": {
        "8_17": [
            614
        ]
    },
    "withthemostrecentmodels": {
        "8_17": [
            615
        ]
    },
    "hardly": {
        "8_17": [
            616
        ]
    },
    "everconvergesorstartsover": {
        "8_17": [
            617
        ]
    },
    "tting": {
        "8_17": [
            618,
            642,
            901
        ]
    },
    "onreasonablybigdatasets": {
        "8_17": [
            619
        ]
    },
    "Thisleadstolearning": {
        "8_17": [
            620
        ]
    },
    "curvesthatneverfully": {
        "8_17": [
            621
        ]
    },
    "attenletalonestartdecreasing": {
        "8_17": [
            622
        ]
    },
    "seeSection": {
        "8_17": [
            623,
            819,
            1305,
            3428
        ]
    },
    "Thecommon": {
        "8_17": [
            624
        ]
    },
    "practice": {
        "8_17": [
            625,
            652,
            5816
        ]
    },
    "evaluate": {
        "8_17": [
            630,
            1707,
            1721
        ]
    },
    "when": {
        "8_17": [
            638,
            836,
            2209,
            2401,
            2597,
            2790,
            2981,
            2991,
            3170,
            4014,
            4254,
            4353,
            4422,
            4563,
            4641,
            5033,
            5184,
            5509,
            5624,
            5729,
            5746,
            5903,
            6259,
            6354,
            6518,
            6620,
            6781
        ]
    },
    "started": {
        "8_17": [
            640
        ]
    },
    "over": {
        "8_17": [
            641,
            900,
            1204,
            3090,
            3127,
            3278,
            3601,
            6179,
            7055
        ]
    },
    "bit": {
        "8_17": [
            645,
            2240,
            2467,
            6688,
            7257
        ]
    },
    "sooner": {
        "8_17": [
            646
        ]
    },
    "thus": {
        "8_17": [
            648,
            1254,
            1312,
            1546,
            1598,
            2175,
            2463,
            2655,
            4762,
            5014
        ]
    },
    "not": {
        "8_17": [
            649,
            660,
            724,
            751,
            760,
            774,
            885,
            930,
            937,
            952,
            995,
            1212,
            1449,
            1591,
            1599,
            1892,
            2587,
            2684,
            2759,
            3088,
            3112,
            3474,
            3912,
            3976,
            4539,
            4689,
            4821,
            4884,
            5449,
            5586,
            5971,
            6392,
            6399,
            6743,
            6851,
            6972,
            7173,
            7346,
            7383,
            7494
        ]
    },
    "applicable": {
        "8_17": [
            650,
            2337
        ]
    },
    "Many": {
        "8_17": [
            653
        ]
    },
    "papers": {
        "8_17": [
            654,
            6087,
            7933,
            8292
        ]
    },
    "specify": {
        "8_17": [
            661
        ]
    },
    "stopping": {
        "8_17": [
            663,
            712,
            835,
            6893
        ]
    },
    "criteria": {
        "8_17": [
            664
        ]
    },
    "whatsoever": {
        "8_17": [
            665
        ]
    },
    "Sometimes": {
        "8_17": [
            666
        ]
    },
    "theymentiononlyanapproximatenumberofdaysthemodel": {
        "8_17": [
            667
        ]
    },
    "was": {
        "8_17": [
            668,
            694,
            1098,
            1530,
            4246,
            4780,
            4950,
            6231,
            6243,
            6686,
            7556
        ]
    },
    "trained": {
        "8_17": [
            669,
            2023,
            2972,
            3051,
            3959,
            4090,
            4209,
            4470,
            4744,
            4988,
            6874,
            7228,
            7325
        ]
    },
    "Bahdanau": {
        "8_17": [
            673,
            7595
        ]
    },
    "sometimes": {
        "8_17": [
            676
        ]
    },
    "exact": {
        "8_17": [
            678,
            7335
        ]
    },
    "number": {
        "8_17": [
            679,
            739,
            745,
            1085,
            1091,
            1101,
            1105,
            1128,
            1137,
            1150,
            1160,
            1170,
            1217,
            1228,
            1260,
            1277,
            1484,
            1953,
            2118,
            2145,
            2162,
            2505,
            2877,
            3073,
            3441,
            4357,
            5483,
            6058,
            6317,
            6492,
            6826,
            6912,
            7232,
            7549,
            7712
        ]
    },
    "indication": {
        "8_17": [
            687
        ]
    },
    "how": {
        "8_17": [
            689,
            1052,
            1451,
            3755,
            5205,
            5722,
            6283
        ]
    },
    "much": {
        "8_17": [
            690,
            2656,
            4679,
            5517
        ]
    },
    "converged": {
        "8_17": [
            691,
            762,
            1410,
            3321
        ]
    },
    "point": {
        "8_17": [
            697,
            708,
            3448,
            6834
        ]
    },
    "Mostprobably": {
        "8_17": [
            701
        ]
    },
    "thetrainingwasrununtilnofurther": {
        "8_17": [
            702
        ]
    },
    "improvementswereclearlyapparentonthedevelopmenttestset": {
        "8_17": [
            703
        ]
    },
    "andthemodelwas": {
        "8_17": [
            704
        ]
    },
    "Such": {
        "8_17": [
            709,
            1605
        ]
    },
    "an": {
        "8_17": [
            710,
            1048,
            1443,
            1858,
            2610,
            2963,
            5866,
            6077
        ]
    },
    "approximate": {
        "8_17": [
            711,
            1136
        ]
    },
    "criterion": {
        "8_17": [
            713
        ]
    },
    "risky": {
        "8_17": [
            716
        ]
    },
    "conceivablethatdi": {
        "8_17": [
            719
        ]
    },
    "erentsetupswerestoppedatdi": {
        "8_17": [
            720
        ]
    },
    "erentstagesoftrainingandtheir": {
        "8_17": [
            721
        ]
    },
    "comparison": {
        "8_17": [
            722,
            1918
        ]
    },
    "fair": {
        "8_17": [
            725
        ]
    },
    "reliable": {
        "8_17": [
            729,
            7348
        ]
    },
    "method": {
        "8_17": [
            730,
            2062
        ]
    },
    "keep": {
        "8_17": [
            733,
            5190,
            5761,
            6556
        ]
    },
    "speci": {
        "8_17": [
            737,
            1124,
            3709,
            3719,
            4393,
            6758
        ]
    },
    "ed": {
        "8_17": [
            738,
            1125,
            3720,
            4394
        ]
    },
    "iterations": {
        "8_17": [
            741,
            1087
        ]
    },
    "certain": {
        "8_17": [
            744,
            1430,
            1494
        ]
    },
    "epochs": {
        "8_17": [
            747,
            794,
            1220,
            1288,
            2147,
            3153,
            3443,
            6063,
            6319,
            6841,
            6956
        ]
    },
    "however": {
        "8_17": [
            750
        ]
    },
    "perfect": {
        "8_17": [
            753
        ]
    },
    "solution": {
        "8_17": [
            754,
            935,
            971,
            4906
        ]
    },
    "if": {
        "8_17": [
            756,
            3261,
            3605,
            4064,
            4105,
            6214,
            6476
        ]
    },
    "quite": {
        "8_17": [
            761,
            780,
            4573,
            5577
        ]
    },
    "erence": {
        "8_17": [
            769,
            3572,
            4331,
            4367,
            4590,
            4695,
            4875,
            5799
        ]
    },
    "performance": {
        "8_17": [
            772,
            1880,
            1908
        ]
    },
    "su": {
        "8_17": [
            775
        ]
    },
    "ciently": {
        "8_17": [
            776
        ]
    },
    "large": {
        "8_17": [
            777,
            869,
            3271,
            3463,
            3468,
            3756,
            6220,
            6941,
            7896,
            7946
        ]
    },
    "possible": {
        "8_17": [
            781,
            2034,
            3635,
            4815,
            4835,
            7536
        ]
    },
    "complex": {
        "8_17": [
            787
        ]
    },
    "would": {
        "8_17": [
            789,
            862,
            2925,
            3798,
            4335,
            5661,
            6567
        ]
    },
    "need": {
        "8_17": [
            790,
            1290,
            3249,
            4303,
            5516,
            5896,
            5947,
            6280,
            6568,
            6767,
            6819,
            8300
        ]
    },
    "few": {
        "8_17": [
            792,
            5029,
            5121,
            6192,
            6693,
            6954
        ]
    },
    "eventually": {
        "8_17": [
            796
        ]
    },
    "arrived": {
        "8_17": [
            797
        ]
    },
    "higher": {
        "8_17": [
            800,
            1149,
            1572,
            2208,
            2553,
            2995,
            4125,
            4142,
            4274,
            4349,
            4484,
            4520,
            5564,
            5571,
            5689,
            6588,
            6689
        ]
    },
    "score": {
        "8_17": [
            801,
            962,
            1076,
            1462,
            7355
        ]
    },
    "competitor": {
        "8_17": [
            804
        ]
    },
    "Also": {
        "8_17": [
            805,
            4139,
            4772
        ]
    },
    "duration": {
        "8_17": [
            807
        ]
    },
    "step": {
        "8_17": [
            811,
            1178,
            1196,
            5934
        ]
    },
    "epoch": {
        "8_17": [
            814,
            6347
        ]
    },
    "ers": {
        "8_17": [
            816
        ]
    },
    "andfromthepracticalpointofview": {
        "8_17": [
            820
        ]
    },
    "wearemostlyinterested": {
        "8_17": [
            821
        ]
    },
    "wall": {
        "8_17": [
            824,
            965
        ]
    },
    "clock": {
        "8_17": [
            825,
            966
        ]
    },
    "When": {
        "8_17": [
            827,
            5075
        ]
    },
    "tried": {
        "8_17": [
            829,
            3456
        ]
    },
    "standard": {
        "8_17": [
            831
        ]
    },
    "technique": {
        "8_17": [
            832
        ]
    },
    "early": {
        "8_17": [
            834,
            4769,
            7059
        ]
    },
    "Nsubsequent": {
        "8_17": [
            837
        ]
    },
    "evaluationsonthedevelopmenttestsetdonotgiveimprovementslargerthanagiven": {
        "8_17": [
            838
        ]
    },
    "delta": {
        "8_17": [
            839,
            874
        ]
    },
    "wesawabigvarianceinthetrainingtimeand": {
        "8_17": [
            840
        ]
    },
    "nalBLEU": {
        "8_17": [
            841
        ]
    },
    "evenforexperiments": {
        "8_17": [
            842
        ]
    },
    "same": {
        "8_17": [
            845,
            1006,
            1691,
            3054,
            3058,
            3982,
            4420,
            5086,
            5228,
            5293,
            5937,
            6188,
            6451,
            6485,
            6517,
            6558,
            6697,
            7231,
            7249,
            7336
        ]
    },
    "just": {
        "8_17": [
            849,
            931,
            2388,
            2786
        ]
    },
    "erent": {
        "8_17": [
            852,
            1002,
            2432,
            3237,
            5320,
            6774
        ]
    },
    "random": {
        "8_17": [
            853,
            897,
            7201
        ]
    },
    "seed": {
        "8_17": [
            854
        ]
    },
    "Moreover": {
        "8_17": [
            855
        ]
    },
    "get": {
        "8_17": [
            857,
            7218
        ]
    },
    "use": {
        "8_17": [
            866,
            1147,
            1440,
            1647,
            1837,
            1885,
            2050,
            2094,
            4123,
            4413,
            5461,
            5609,
            5979,
            6088,
            6158,
            6393,
            6617,
            6649,
            7074,
            7384
        ]
    },
    "Nand": {
        "8_17": [
            870
        ]
    },
    "small": {
        "8_17": [
            873,
            2788,
            3451,
            6227,
            6947,
            6974
        ]
    },
    "Evenifwe": {
        "8_17": [
            875
        ]
    },
    "xtherandomseed": {
        "8_17": [
            876
        ]
    },
    "whichwasnotdoneproperlyinTTv": {
        "8_17": [
            877
        ]
    },
    "achangeofsomehyper": {
        "8_17": [
            878
        ]
    },
    "may": {
        "8_17": [
            880,
            3267,
            4788,
            5412,
            6850
        ]
    },
    "because": {
        "8_17": [
            886,
            892,
            992,
            1446,
            1620,
            2758,
            3254,
            3909,
            5201,
            5274,
            6823
        ]
    },
    "change": {
        "8_17": [
            889,
            4107
        ]
    },
    "itself": {
        "8_17": [
            890,
            2690
        ]
    },
    "uenced": {
        "8_17": [
            895,
            6890
        ]
    },
    "initialization": {
        "8_17": [
            898
        ]
    },
    "By": {
        "8_17": [
            899,
            5291,
            6511
        ]
    },
    "mean": {
        "8_17": [
            903,
            5296
        ]
    },
    "here": {
        "8_17": [
            904,
            2183,
            2589,
            3485
        ]
    },
    "begins": {
        "8_17": [
            912
        ]
    },
    "worsen": {
        "8_17": [
            914
        ]
    },
    "while": {
        "8_17": [
            915,
            1941,
            2046,
            2807,
            2874,
            2920,
            4773,
            4816,
            6033,
            6084,
            7063
        ]
    },
    "loss": {
        "8_17": [
            918,
            5300,
            6414
        ]
    },
    "keeps": {
        "8_17": [
            919
        ]
    },
    "improving": {
        "8_17": [
            920,
            3335,
            3992
        ]
    },
    "Our": {
        "8_17": [
            921,
            1698,
            2416,
            6098
        ]
    },
    "Final": {
        "8_17": [
            922
        ]
    },
    "Choice": {
        "8_17": [
            923
        ]
    },
    "Full": {
        "8_17": [
            924
        ]
    },
    "Learning": {
        "8_17": [
            925,
            4845,
            5154,
            5701,
            6293,
            6720,
            7607,
            8016,
            8172,
            8211,
            8235
        ]
    },
    "Curves": {
        "8_17": [
            926
        ]
    },
    "Basedonthediscussionabove": {
        "8_17": [
            927
        ]
    },
    "wedecidedtoreportalwaysthefulllearningcurves": {
        "8_17": [
            928
        ]
    },
    "does": {
        "8_17": [
            936,
            2683,
            3087,
            3911,
            5970,
            6391,
            7382
        ]
    },
    "fully": {
        "8_17": [
            938,
            996,
            2765,
            6813,
            7347
        ]
    },
    "prevent": {
        "8_17": [
            939,
            4908,
            6143,
            6628
        ]
    },
    "risk": {
        "8_17": [
            941
        ]
    },
    "premature": {
        "8_17": [
            943
        ]
    },
    "judgments": {
        "8_17": [
            944
        ]
    },
    "butthereaderscanatleastjudgeforthemselvesiftheywouldexpectany": {
        "8_17": [
            945
        ]
    },
    "sudden": {
        "8_17": [
            946,
            4002
        ]
    },
    "twist": {
        "8_17": [
            947
        ]
    },
    "cases": {
        "8_17": [
            955,
            2159,
            5284
        ]
    },
    "plot": {
        "8_17": [
            957,
            1878
        ]
    },
    "hours": {
        "8_17": [
            969,
            2934,
            3109,
            3143,
            3258,
            3489,
            3521,
            3591,
            3747,
            3933,
            4136,
            4181,
            4439,
            4604,
            4721,
            4960,
            5030,
            5122,
            5362,
            5470,
            6130,
            6193,
            6694,
            6860,
            7161
        ]
    },
    "obviously": {
        "8_17": [
            972,
            1324
        ]
    },
    "depends": {
        "8_17": [
            973,
            1325
        ]
    },
    "chosen": {
        "8_17": [
            977
        ]
    },
    "so": {
        "8_17": [
            978,
            2296,
            2778,
            2902,
            3480,
            3543,
            3838,
            4352,
            5247,
            5433,
            5775,
            6047,
            7005,
            7274,
            7415
        ]
    },
    "usedthesameequipment": {
        "8_17": [
            981
        ]
    },
    "oneuptoeightGeForceGTXTiGPUswithNVIDIA": {
        "8_17": [
            982
        ]
    },
    "driver": {
        "8_17": [
            983,
            1336
        ]
    },
    "variation": {
        "8_17": [
            985,
            1023,
            1644
        ]
    },
    "measurements": {
        "8_17": [
            988
        ]
    },
    "unfortunately": {
        "8_17": [
            990
        ]
    },
    "unavoidable": {
        "8_17": [
            991
        ]
    },
    "could": {
        "8_17": [
            994,
            4546,
            5566
        ]
    },
    "isolate": {
        "8_17": [
            997
        ]
    },
    "computation": {
        "8_17": [
            999,
            1348,
            2527,
            2636,
            2652,
            2751,
            2830
        ]
    },
    "processes": {
        "8_17": [
            1003
        ]
    },
    "tra": {
        "8_17": [
            1012
        ]
    },
    "based": {
        "8_17": [
            1015,
            2779
        ]
    },
    "replicated": {
        "8_17": [
            1020
        ]
    },
    "such": {
        "8_17": [
            1022,
            1983,
            2314
        ]
    },
    "negligible": {
        "8_17": [
            1025
        ]
    },
    "Terminology": {
        "8_17": [
            1026
        ]
    },
    "clarity": {
        "8_17": [
            1028
        ]
    },
    "de": {
        "8_17": [
            1030,
            1235,
            1453,
            1464,
            1606,
            1716,
            1719,
            2361,
            3365
        ]
    },
    "ne": {
        "8_17": [
            1031,
            1454,
            1465
        ]
    },
    "following": {
        "8_17": [
            1033,
            1539
        ]
    },
    "terms": {
        "8_17": [
            1034,
            4282
        ]
    },
    "adhere": {
        "8_17": [
            1036
        ]
    },
    "rest": {
        "8_17": [
            1041,
            1818
        ]
    },
    "Translation": {
        "8_17": [
            1045,
            7604,
            7776,
            8060,
            8105,
            8142
        ]
    },
    "estimate": {
        "8_17": [
            1050,
            1070
        ]
    },
    "well": {
        "8_17": [
            1053,
            2828,
            4597,
            5894,
            5973,
            6019
        ]
    },
    "carried": {
        "8_17": [
            1056
        ]
    },
    "expresses": {
        "8_17": [
            1063
        ]
    },
    "meaning": {
        "8_17": [
            1065,
            4944
        ]
    },
    "source": {
        "8_17": [
            1068,
            1241,
            2099,
            2284
        ]
    },
    "solely": {
        "8_17": [
            1073
        ]
    },
    "Steps": {
        "8_17": [
            1082,
            4849,
            5158,
            5705,
            6724
        ]
    },
    "denote": {
        "8_17": [
            1083
        ]
    },
    "i": {
        "8_17": [
            1088,
            1947,
            2437,
            2633,
            4308,
            4623,
            4791,
            5351,
            5375,
            5521,
            5782
        ]
    },
    "opti": {
        "8_17": [
            1095
        ]
    },
    "mizer": {
        "8_17": [
            1096
        ]
    },
    "update": {
        "8_17": [
            1097,
            5933
        ]
    },
    "run": {
        "8_17": [
            1099,
            3740,
            5638
        ]
    },
    "equals": {
        "8_17": [
            1103,
            1378,
            1499
        ]
    },
    "mini": {
        "8_17": [
            1107
        ]
    },
    "batches": {
        "8_17": [
            1108,
            4346,
            4516,
            4537
        ]
    },
    "were": {
        "8_17": [
            1110,
            1750,
            2344,
            3158,
            5052,
            6141,
            6155,
            6398,
            7120
        ]
    },
    "processed": {
        "8_17": [
            1111,
            4360
        ]
    },
    "Batch": {
        "8_17": [
            1112,
            1166,
            4214,
            4805,
            4807,
            8012,
            8239,
            8365
        ]
    },
    "Size": {
        "8_17": [
            1113,
            1167,
            3025,
            3233,
            3342,
            3597,
            4215,
            4806,
            8240,
            8366
        ]
    },
    "isthenumberoftrainingexamplesusedbyoneGPUinonetrainingstep": {
        "8_17": [
            1114
        ]
    },
    "sequence": {
        "8_17": [
            1116,
            1118,
            6002,
            6004
        ]
    },
    "usually": {
        "8_17": [
            1123,
            1569,
            2515,
            5024,
            7041
        ]
    },
    "ofsentencepairs": {
        "8_17": [
            1129
        ]
    },
    "However": {
        "8_17": [
            1130,
            1248,
            2675,
            3217,
            3414,
            3856,
            4226,
            5552,
            5776,
            5910,
            6170,
            6348,
            6576,
            6880
        ]
    },
    "theparameter": {
        "8_17": [
            1131,
            1180
        ]
    },
    "batch_size": {
        "8_17": [
            1132,
            1181,
            1186,
            1255,
            2426,
            2692,
            2717,
            2866,
            2873,
            2978,
            3063,
            3135,
            3725,
            3860,
            3969,
            4045,
            4217,
            4297,
            4301,
            4385,
            4431,
            5242
        ]
    },
    "inTTtranslationspeci": {
        "8_17": [
            1133
        ]
    },
    "es": {
        "8_17": [
            1134
        ]
    },
    "tokens": {
        "8_17": [
            1139,
            1230
        ]
    },
    "subwords": {
        "8_17": [
            1140,
            1190,
            1244,
            1264,
            1309,
            1373,
            1489,
            2120,
            2156,
            2164,
            2739,
            2840,
            3661,
            4396,
            5363
        ]
    },
    "allows": {
        "8_17": [
            1145,
            2549,
            4121,
            5220,
            5439
        ]
    },
    "short": {
        "8_17": [
            1152
        ]
    },
    "sentences": {
        "8_17": [
            1153,
            1163,
            1653,
            2092,
            2212,
            2940,
            2943,
            3642,
            3680,
            3796,
            3822,
            3830,
            4146
        ]
    },
    "smaller": {
        "8_17": [
            1159,
            1825,
            1862,
            2151,
            2235,
            2987,
            3047,
            3067,
            3070,
            3156,
            3241,
            3316,
            3844,
            3905,
            4370,
            4515
        ]
    },
    "long": {
        "8_17": [
            1162,
            3252,
            4151,
            4843
        ]
    },
    "E": {
        "8_17": [
            1164,
            3506,
            3533,
            3947,
            4198,
            4459,
            4733,
            4977,
            5479,
            6868,
            7805,
            8078
        ]
    },
    "ective": {
        "8_17": [
            1165,
            1298,
            1387,
            5252,
            5277,
            5554,
            5851,
            5907,
            5942,
            6358,
            6524
        ]
    },
    "examples": {
        "8_17": [
            1173,
            1487,
            4307,
            4314,
            4359,
            5520,
            6322,
            6495,
            6653
        ]
    },
    "consumed": {
        "8_17": [
            1174,
            5370
        ]
    },
    "WhentrainingonmultipleGPUs": {
        "8_17": [
            1179
        ]
    },
    "isinterpreted": {
        "8_17": [
            1182
        ]
    },
    "perGPU": {
        "8_17": [
            1183
        ]
    },
    "Thatis": {
        "8_17": [
            1184
        ]
    },
    "andGPUs": {
        "8_17": [
            1187,
            3136
        ]
    },
    "thesystemactuallydigests": {
        "8_17": [
            1188
        ]
    },
    "k": {
        "8_17": [
            1189,
            1664,
            1670,
            1674,
            2109,
            2695,
            2696,
            2697,
            2698,
            2699,
            2700,
            2701,
            2702,
            2703,
            2704,
            2705,
            2707,
            2709,
            2842,
            2844,
            2846,
            2848,
            4755,
            4963,
            4966,
            4969,
            4972,
            4975,
            5007,
            5048,
            5050,
            5098,
            5104,
            5752,
            5789,
            6575,
            6669,
            6676,
            6711,
            6717
        ]
    },
    "language": {
        "8_17": [
            1193
        ]
    },
    "Epoch": {
        "8_17": [
            1198
        ]
    },
    "corresponds": {
        "8_17": [
            1199
        ]
    },
    "complete": {
        "8_17": [
            1202,
            6714
        ]
    },
    "pass": {
        "8_17": [
            1203
        ]
    },
    "Unfortu": {
        "8_17": [
            1208
        ]
    },
    "nately": {
        "8_17": [
            1209
        ]
    },
    "easy": {
        "8_17": [
            1213
        ]
    },
    "measure": {
        "8_17": [
            1215,
            1445
        ]
    },
    "TT": {
        "8_17": [
            1222,
            1223,
            1514,
            1545,
            1933,
            2041,
            2084,
            2347,
            2364,
            2607,
            3737,
            4252,
            4535,
            4859,
            4953,
            5219,
            5399,
            5438,
            6290,
            6297,
            6791,
            7087
        ]
    },
    "purpose": {
        "8_17": [
            1226
        ]
    },
    "ned": {
        "8_17": [
            1236,
            2362,
            3366
        ]
    },
    "target": {
        "8_17": [
            1243,
            2101,
            6948
        ]
    },
    "TTalsodoesreorderingandbucketingofthesentencesbytheirlengthtominimizetheuseof": {
        "8_17": [
            1245
        ]
    },
    "padding": {
        "8_17": [
            1246,
            1250,
            1263
        ]
    },
    "symbols": {
        "8_17": [
            1247
        ]
    },
    "needed": {
        "8_17": [
            1253,
            1426,
            1490,
            2141,
            2443,
            3159,
            3444,
            4798,
            5535,
            7286
        ]
    },
    "approximates": {
        "8_17": [
            1257
        ]
    },
    "actual": {
        "8_17": [
            1259,
            5010,
            5035,
            5198,
            5692,
            6486,
            6582,
            6595
        ]
    },
    "non": {
        "8_17": [
            1262,
            4684
        ]
    },
    "https": {
        "8_17": [
            1268,
            2621,
            5418,
            6430,
            7798,
            7823,
            8183
        ]
    },
    "issues": {
        "8_17": [
            1273,
            2626,
            4177,
            5423
        ]
    },
    "reports": {
        "8_17": [
            1274
        ]
    },
    "order": {
        "8_17": [
            1282,
            2666,
            6626
        ]
    },
    "convert": {
        "8_17": [
            1284
        ]
    },
    "multiply": {
        "8_17": [
            1292,
            5755
        ]
    },
    "divide": {
        "8_17": [
            1302,
            6478,
            6570
        ]
    },
    "thenumberofsubwordsinthetrainingdata": {
        "8_17": [
            1304
        ]
    },
    "Thesegmentation": {
        "8_17": [
            1306
        ]
    },
    "ofthetrainingdataintosubwordsisusuallyhiddentotheuserandthenumber": {
        "8_17": [
            1307
        ]
    },
    "must": {
        "8_17": [
            1310,
            2278
        ]
    },
    "computed": {
        "8_17": [
            1313
        ]
    },
    "special": {
        "8_17": [
            1316
        ]
    },
    "script": {
        "8_17": [
            1317,
            1699
        ]
    },
    "Computation": {
        "8_17": [
            1318,
            1381,
            2473,
            2712,
            2742,
            2851
        ]
    },
    "Speed": {
        "8_17": [
            1319,
            1382,
            1391,
            2474
        ]
    },
    "issimplytheobservednumberoftrainingstepsperhour": {
        "8_17": [
            1320
        ]
    },
    "Com": {
        "8_17": [
            1321
        ]
    },
    "putation": {
        "8_17": [
            1322,
            2891
        ]
    },
    "CPU": {
        "8_17": [
            1332
        ]
    },
    "communication": {
        "8_17": [
            1333
        ]
    },
    "software": {
        "8_17": [
            1335
        ]
    },
    "CUDA": {
        "8_17": [
            1338
        ]
    },
    "library": {
        "8_17": [
            1339
        ]
    },
    "imple": {
        "8_17": [
            1341
        ]
    },
    "mentation": {
        "8_17": [
            1342
        ]
    },
    "ecting": {
        "8_17": [
            1347
        ]
    },
    "optimizerandothersettingsthatdirectlymodifytheformulaoftheneural": {
        "8_17": [
            1354
        ]
    },
    "Throughput": {
        "8_17": [
            1357,
            1377,
            1508,
            2477
        ]
    },
    "amount": {
        "8_17": [
            1360
        ]
    },
    "digested": {
        "8_17": [
            1364
        ]
    },
    "report": {
        "8_17": [
            1369,
            3483,
            7459
        ]
    },
    "throughput": {
        "8_17": [
            1371,
            2531,
            2689,
            2738,
            2746,
            2770,
            2826,
            2855,
            2896,
            3007,
            3021,
            4351,
            4544,
            5572
        ]
    },
    "per": {
        "8_17": [
            1374,
            2165,
            2913,
            5245
        ]
    },
    "hour": {
        "8_17": [
            1375,
            2450,
            2715,
            2740,
            2839,
            2841,
            2914,
            3871,
            3996,
            7187
        ]
    },
    "multiplied": {
        "8_17": [
            1383,
            1505
        ]
    },
    "Convergence": {
        "8_17": [
            1390,
            1394
        ]
    },
    "orBLEUConvergence": {
        "8_17": [
            1392
        ]
    },
    "istheincreaseinBLEUdividedbytime": {
        "8_17": [
            1393
        ]
    },
    "changes": {
        "8_17": [
            1396
        ]
    },
    "heavily": {
        "8_17": [
            1397
        ]
    },
    "during": {
        "8_17": [
            1398,
            3194,
            6777,
            6922
        ]
    },
    "starting": {
        "8_17": [
            1400,
            4839
        ]
    },
    "high": {
        "8_17": [
            1402,
            1615,
            1624,
            4020,
            4069,
            4157,
            4813,
            4883,
            5103,
            7353
        ]
    },
    "decreasing": {
        "8_17": [
            1404,
            2889,
            5178,
            6700
        ]
    },
    "progresses": {
        "8_17": [
            1408
        ]
    },
    "conver": {
        "8_17": [
            1414
        ]
    },
    "gence": {
        "8_17": [
            1415
        ]
    },
    "zero": {
        "8_17": [
            1418,
            4899
        ]
    },
    "Time": {
        "8_17": [
            1419,
            1502,
            1609,
            4288,
            4555,
            5366,
            5377,
            5512
        ]
    },
    "Till": {
        "8_17": [
            1420,
            1480,
            1503,
            1610,
            4289,
            4556,
            4560,
            5378,
            5513
        ]
    },
    "Score": {
        "8_17": [
            1421,
            1481,
            1504,
            1611,
            4290,
            4557,
            4561,
            5379,
            5514
        ]
    },
    "achieve": {
        "8_17": [
            1428,
            1492,
            5353,
            6483
        ]
    },
    "level": {
        "8_17": [
            1431,
            1478,
            1495,
            5883
        ]
    },
    "informal": {
        "8_17": [
            1444
        ]
    },
    "clear": {
        "8_17": [
            1450
        ]
    },
    "moment": {
        "8_17": [
            1456,
            3169
        ]
    },
    "achieving": {
        "8_17": [
            1458
        ]
    },
    "after": {
        "8_17": [
            1469,
            3081,
            3121,
            3129,
            3205,
            3256,
            3285,
            3294,
            3322,
            3337,
            3544,
            3577,
            3590,
            3745,
            3869,
            3993,
            4134,
            4602,
            4674,
            5119,
            5642,
            6055,
            6128,
            6191,
            6489,
            7151
        ]
    },
    "never": {
        "8_17": [
            1473,
            1550,
            4159,
            5355
        ]
    },
    "falls": {
        "8_17": [
            1474
        ]
    },
    "below": {
        "8_17": [
            1475,
            4790,
            4793,
            5358
        ]
    },
    "Examples": {
        "8_17": [
            1479,
            4559
        ]
    },
    "Tools": {
        "8_17": [
            1509,
            7691
        ]
    },
    "within": {
        "8_17": [
            1512,
            4869,
            4946,
            5026,
            5149
        ]
    },
    "TensorTensor": {
        "8_17": [
            1513,
            3368,
            7523
        ]
    },
    "being": {
        "8_17": [
            1515,
            2648
        ]
    },
    "implemented": {
        "8_17": [
            1516,
            5213,
            6288
        ]
    },
    "TensorFlow": {
        "8_17": [
            1518
        ]
    },
    "provides": {
        "8_17": [
            1519,
            7308
        ]
    },
    "nice": {
        "8_17": [
            1520
        ]
    },
    "TensorBoard": {
        "8_17": [
            1521,
            1741
        ]
    },
    "visualizations": {
        "8_17": [
            1522
        ]
    },
    "progress": {
        "8_17": [
            1526,
            1946
        ]
    },
    "original": {
        "8_17": [
            1528,
            2031,
            6499
        ]
    },
    "implementation": {
        "8_17": [
            1529,
            3735,
            7337
        ]
    },
    "optimized": {
        "8_17": [
            1531
        ]
    },
    "towards": {
        "8_17": [
            1532,
            1538,
            3794
        ]
    },
    "standards": {
        "8_17": [
            1541
        ]
    },
    "eld": {
        "8_17": [
            1544
        ]
    },
    "reportsapprox": {
        "8_17": [
            1547
        ]
    },
    "bleubydefault": {
        "8_17": [
            1548
        ]
    },
    "whichiscomputedontheinternalsubwords": {
        "8_17": [
            1549
        ]
    },
    "exposed": {
        "8_17": [
            1551
        ]
    },
    "user": {
        "8_17": [
            1554
        ]
    },
    "actually": {
        "8_17": [
            1555,
            5770,
            6312,
            6527,
            7211
        ]
    },
    "instead": {
        "8_17": [
            1556,
            3728,
            4046,
            4322,
            6061,
            6367,
            6672,
            6839,
            6924
        ]
    },
    "words": {
        "8_17": [
            1558,
            1655,
            1657,
            1876,
            2302,
            3034,
            3075,
            5878
        ]
    },
    "according": {
        "8_17": [
            1559
        ]
    },
    "result": {
        "8_17": [
            1565,
            1692
        ]
    },
    "approx": {
        "8_17": [
            1566
        ]
    },
    "bleu": {
        "8_17": [
            1567,
            1687,
            1712
        ]
    },
    "real": {
        "8_17": [
            1575
        ]
    },
    "Due": {
        "8_17": [
            1577
        ]
    },
    "dependence": {
        "8_17": [
            1580
        ]
    },
    "subword": {
        "8_17": [
            1587,
            2008,
            2053,
            2105
        ]
    },
    "vocabulary": {
        "8_17": [
            1588,
            2106,
            2298
        ]
    },
    "easily": {
        "8_17": [
            1592,
            3306
        ]
    },
    "reproducible": {
        "8_17": [
            1593
        ]
    },
    "varying": {
        "8_17": [
            1595,
            2875,
            4039,
            4866
        ]
    },
    "suitable": {
        "8_17": [
            1600,
            6251
        ]
    },
    "reporting": {
        "8_17": [
            1602,
            4255
        ]
    },
    "publications": {
        "8_17": [
            1604
        ]
    },
    "nition": {
        "8_17": [
            1607
        ]
    },
    "leads": {
        "8_17": [
            1612,
            5888,
            6600
        ]
    },
    "variance": {
        "8_17": [
            1616,
            1626,
            5763,
            7024
        ]
    },
    "values": {
        "8_17": [
            1619,
            3786,
            3957,
            4406,
            5144,
            5340
        ]
    },
    "relatively": {
        "8_17": [
            1623,
            5140
        ]
    },
    "subsequent": {
        "8_17": [
            1628,
            1776
        ]
    },
    "checkpoints": {
        "8_17": [
            1629,
            1765,
            1958,
            6862,
            6864,
            7141,
            7158,
            7169,
            7270,
            7331
        ]
    },
    "visible": {
        "8_17": [
            1630,
            4373,
            5437
        ]
    },
    "ickering": {
        "8_17": [
            1633,
            7025
        ]
    },
    "curves": {
        "8_17": [
            1637,
            2488,
            2640,
            2952,
            4334,
            4421,
            4686,
            5068,
            5317
        ]
    },
    "gures": {
        "8_17": [
            1640,
            1746,
            4928
        ]
    },
    "decrease": {
        "8_17": [
            1642,
            4913,
            5186
        ]
    },
    "bigger": {
        "8_17": [
            1649,
            2672,
            2825,
            3099,
            3146,
            3172,
            3245,
            3333,
            4338,
            4345,
            4536,
            5257,
            6522
        ]
    },
    "development": {
        "8_17": [
            1650,
            1890,
            1911,
            3833
        ]
    },
    "EN": {
        "8_17": [
            1654
        ]
    },
    "CS": {
        "8_17": [
            1656
        ]
    },
    "CzEng": {
        "8_17": [
            1658,
            1807,
            1856,
            1863,
            1974,
            2153,
            3044,
            3048,
            3139,
            3149,
            3187,
            3193,
            3210,
            3215,
            3275,
            3320,
            3329,
            3684,
            4746,
            4990,
            7643,
            7683
        ]
    },
    "M": {
        "8_17": [
            1659,
            1660,
            1661,
            1665,
            1666,
            1671,
            1672,
            1675,
            1676,
            1678,
            1679,
            1680,
            1811,
            1819,
            1841,
            1868,
            1871,
            1872,
            2720,
            2721,
            2722,
            2723,
            2724,
            2725,
            2726,
            2727,
            2728,
            2729,
            2730,
            2732,
            2734,
            2843,
            2845,
            2847,
            2849,
            2938,
            2941,
            3031,
            4306,
            5364,
            8168
        ]
    },
    "europarl": {
        "8_17": [
            1662
        ]
    },
    "news": {
        "8_17": [
            1667,
            7316
        ]
    },
    "commentary": {
        "8_17": [
            1668
        ]
    },
    "commoncrawl": {
        "8_17": [
            1673
        ]
    },
    "Total": {
        "8_17": [
            1677
        ]
    },
    "Table": {
        "8_17": [
            1681,
            1835,
            2524,
            2741,
            2850,
            2867,
            3384,
            3392,
            3653,
            3763,
            3809,
            4340,
            5365,
            6274,
            7105,
            7307
        ]
    },
    "resources": {
        "8_17": [
            1684,
            2266,
            7574
        ]
    },
    "Weimplementedahelperscript": {
        "8_17": [
            1685
        ]
    },
    "tt": {
        "8_17": [
            1686,
            1711,
            1732,
            1755,
            1759,
            2229
        ]
    },
    "whichcomputestherealBLEU": {
        "8_17": [
            1688
        ]
    },
    "giving": {
        "8_17": [
            1689,
            2334
        ]
    },
    "translated": {
        "8_17": [
            1709,
            7387
        ]
    },
    "le": {
        "8_17": [
            1710,
            1743,
            6761
        ]
    },
    "my": {
        "8_17": [
            1714
        ]
    },
    "wmt_deen": {
        "8_17": [
            1718
        ]
    },
    "directory": {
        "8_17": [
            1727,
            1769
        ]
    },
    "created": {
        "8_17": [
            1728,
            1751
        ]
    },
    "translate": {
        "8_17": [
            1733,
            1756
        ]
    },
    "store": {
        "8_17": [
            1736,
            3913
        ]
    },
    "events": {
        "8_17": [
            1742
        ]
    },
    "way": {
        "8_17": [
            1753,
            5204,
            6751,
            7250
        ]
    },
    "Wealsoimplemented": {
        "8_17": [
            1754
        ]
    },
    "avg": {
        "8_17": [
            1760
        ]
    },
    "scripts": {
        "8_17": [
            1762,
            1928,
            1937
        ]
    },
    "whichtranslate": {
        "8_17": [
            1763
        ]
    },
    "average": {
        "8_17": [
            1771,
            2161,
            7167
        ]
    },
    "window": {
        "8_17": [
            1773
        ]
    },
    "N": {
        "8_17": [
            1775,
            5835,
            8166,
            8258
        ]
    },
    "check": {
        "8_17": [
            1777
        ]
    },
    "points": {
        "8_17": [
            1778
        ]
    },
    "respectively": {
        "8_17": [
            1779,
            5342
        ]
    },
    "details": {
        "8_17": [
            1781,
            5795
        ]
    },
    "averaging": {
        "8_17": [
            1783,
            6861,
            6863,
            6866,
            6872,
            7016,
            7040,
            7054,
            7143,
            7262,
            7297,
            7330
        ]
    },
    "Data": {
        "8_17": [
            1786,
            1979,
            1981,
            2187,
            3024,
            3232
        ]
    },
    "Selection": {
        "8_17": [
            1787
        ]
    },
    "Preprocessing": {
        "8_17": [
            1789,
            1980,
            2188
        ]
    },
    "focused": {
        "8_17": [
            1791
        ]
    },
    "English": {
        "8_17": [
            1794,
            2102,
            2132,
            7313,
            7437,
            7686
        ]
    },
    "Czech": {
        "8_17": [
            1796,
            2104,
            2134,
            3033,
            7315,
            7439,
            7564,
            7591,
            7685,
            8405
        ]
    },
    "direction": {
        "8_17": [
            1798
        ]
    },
    "Most": {
        "8_17": [
            1799
        ]
    },
    "comes": {
        "8_17": [
            1804,
            1822,
            2056
        ]
    },
    "parallel": {
        "8_17": [
            1808,
            5651,
            5658
        ]
    },
    "treebank": {
        "8_17": [
            1809
        ]
    },
    "pairs": {
        "8_17": [
            1813,
            1821,
            1843,
            1870,
            2961,
            2970
        ]
    },
    "sources": {
        "8_17": [
            1826
        ]
    },
    "Europarl": {
        "8_17": [
            1827
        ]
    },
    "News": {
        "8_17": [
            1828
        ]
    },
    "Commentary": {
        "8_17": [
            1829
        ]
    },
    "Common": {
        "8_17": [
            1830
        ]
    },
    "Crawl": {
        "8_17": [
            1831
        ]
    },
    "detailed": {
        "8_17": [
            1833
        ]
    },
    "Sections": {
        "8_17": [
            1852
        ]
    },
    "substitute": {
        "8_17": [
            1855
        ]
    },
    "older": {
        "8_17": [
            1859,
            4955
        ]
    },
    "considerably": {
        "8_17": [
            1861
        ]
    },
    "containing": {
        "8_17": [
            1867,
            6468
        ]
    },
    "throughout": {
        "8_17": [
            1881
        ]
    },
    "newstest": {
        "8_17": [
            1887,
            1916
        ]
    },
    "overlapping": {
        "8_17": [
            1893
        ]
    },
    "apply": {
        "8_17": [
            1901
        ]
    },
    "judged": {
        "8_17": [
            1905
        ]
    },
    "systems": {
        "8_17": [
            1925
        ]
    },
    "now": {
        "8_17": [
            1930
        ]
    },
    "mergedin": {
        "8_17": [
            1931
        ]
    },
    "trainingis": {
        "8_17": [
            1943
        ]
    },
    "they": {
        "8_17": [
            1949,
            5523
        ]
    },
    "wait": {
        "8_17": [
            1950
        ]
    },
    "minutes": {
        "8_17": [
            1955,
            7273
        ]
    },
    "appear": {
        "8_17": [
            1960
        ]
    },
    "ufal": {
        "8_17": [
            1963,
            8385
        ]
    },
    "mff": {
        "8_17": [
            1964,
            8386
        ]
    },
    "cuni": {
        "8_17": [
            1965,
            8387
        ]
    },
    "cz": {
        "8_17": [
            1966,
            8388
        ]
    },
    "czeng": {
        "8_17": [
            1967,
            1968
        ]
    },
    "subset": {
        "8_17": [
            1972,
            7407
        ]
    },
    "preprocessing": {
        "8_17": [
            1982,
            2115
        ]
    },
    "truecasing": {
        "8_17": [
            1987
        ]
    },
    "importantpartofthesetupofstatisticalmachinetranslationsystems": {
        "8_17": [
            1993
        ]
    },
    "Ahugeleapin": {
        "8_17": [
            1994
        ]
    },
    "realistic": {
        "8_17": [
            1998
        ]
    },
    "achieved": {
        "8_17": [
            2003
        ]
    },
    "introduction": {
        "8_17": [
            2006
        ]
    },
    "units": {
        "8_17": [
            2009,
            2054
        ]
    },
    "Sennrichetal": {
        "8_17": [
            2010
        ]
    },
    "butthelong": {
        "8_17": [
            2011
        ]
    },
    "termvisionofthedeep": {
        "8_17": [
            2012
        ]
    },
    "leave": {
        "8_17": [
            2016,
            3922,
            5696
        ]
    },
    "technicalities": {
        "8_17": [
            2019
        ]
    },
    "feed": {
        "8_17": [
            2027
        ]
    },
    "input": {
        "8_17": [
            2032
        ]
    },
    "Lee": {
        "8_17": [
            2038,
            8048
        ]
    },
    "adopts": {
        "8_17": [
            2042
        ]
    },
    "vision": {
        "8_17": [
            2044
        ]
    },
    "supports": {
        "8_17": [
            2048
        ]
    },
    "external": {
        "8_17": [
            2052
        ]
    },
    "own": {
        "8_17": [
            2059
        ]
    },
    "built": {
        "8_17": [
            2060
        ]
    },
    "similar": {
        "8_17": [
            2063,
            6229
        ]
    },
    "word": {
        "8_17": [
            2066,
            2168
        ]
    },
    "piece": {
        "8_17": [
            2067
        ]
    },
    "algorithm": {
        "8_17": [
            2068
        ]
    },
    "Wu": {
        "8_17": [
            2070,
            8302
        ]
    },
    "anddoesnotexpecttheinputtobeeventokenized": {
        "8_17": [
            2073
        ]
    },
    "Basedonasmallsampleof": {
        "8_17": [
            2074
        ]
    },
    "thetrainingdata": {
        "8_17": [
            2075
        ]
    },
    "TTwilltrainasubwordvocabularyandapplyittoallthetraining": {
        "8_17": [
            2076
        ]
    },
    "later": {
        "8_17": [
            2078,
            7145
        ]
    },
    "follow": {
        "8_17": [
            2082
        ]
    },
    "default": {
        "8_17": [
            2085,
            2096,
            2422,
            3724,
            4224,
            4248,
            4749,
            4855,
            4939,
            4993,
            5096,
            5143,
            5339,
            5466,
            6181,
            6636,
            6665,
            6675
        ]
    },
    "raw": {
        "8_17": [
            2088
        ]
    },
    "plain": {
        "8_17": [
            2089
        ]
    },
    "text": {
        "8_17": [
            2090
        ]
    },
    "shared": {
        "8_17": [
            2098
        ]
    },
    "superiorAfter": {
        "8_17": [
            2113
        ]
    },
    "total": {
        "8_17": [
            2117,
            5174
        ]
    },
    "millions": {
        "8_17": [
            2127
        ]
    },
    "taking": {
        "8_17": [
            2128,
            2808
        ]
    },
    "lengths": {
        "8_17": [
            2135
        ]
    },
    "pair": {
        "8_17": [
            2139
        ]
    },
    "computing": {
        "8_17": [
            2143
        ]
    },
    "million": {
        "8_17": [
            2155,
            2959,
            2968
        ]
    },
    "both": {
        "8_17": [
            2158,
            5917
        ]
    },
    "space": {
        "8_17": [
            2166
        ]
    },
    "delimited": {
        "8_17": [
            2167
        ]
    },
    "Evenwhenfollowingthedefaults": {
        "8_17": [
            2171
        ]
    },
    "therearesomeimportantdetailsthatshouldbe": {
        "8_17": [
            2172
        ]
    },
    "considered": {
        "8_17": [
            2173
        ]
    },
    "rst": {
        "8_17": [
            2178,
            3107,
            3196,
            3257,
            3914,
            3995,
            5028,
            5081,
            5114,
            6692
        ]
    },
    "technical": {
        "8_17": [
            2181
        ]
    },
    "Makesurethatthesubwordvocabularyistrainedonasu": {
        "8_17": [
            2189
        ]
    },
    "cientlylargesample": {
        "8_17": [
            2190
        ]
    },
    "AsdiscussedinSection": {
        "8_17": [
            2199
        ]
    },
    "ahigherbatchsizemaybebene": {
        "8_17": [
            2200
        ]
    },
    "cialforthetraining": {
        "8_17": [
            2201
        ]
    },
    "excluding": {
        "8_17": [
            2210,
            3818
        ]
    },
    "longer": {
        "8_17": [
            2213,
            3610,
            3641,
            3691,
            3837,
            4311,
            6822,
            7888,
            7938
        ]
    },
    "threshold": {
        "8_17": [
            2217,
            3695,
            5388
        ]
    },
    "controlled": {
        "8_17": [
            2221,
            2272
        ]
    },
    "parameter": {
        "8_17": [
            2223,
            3399,
            4110,
            4916,
            4926,
            5233,
            5241,
            6310,
            6448,
            6472,
            6480,
            6515,
            6731,
            6779,
            6845,
            7454
        ]
    },
    "max_length": {
        "8_17": [
            2224,
            2664,
            2682,
            3424,
            3565,
            3643,
            3708,
            3717,
            3730,
            3785,
            3788,
            3813,
            3878,
            3883,
            3893,
            3896,
            3956,
            3974,
            3985,
            3988,
            4040,
            4051,
            4058,
            4072,
            4095,
            4114,
            4119,
            4150,
            4162,
            4414,
            4427
        ]
    },
    "butitmaybeagoodideatoexcludetoolongsentencesevenbefore": {
        "8_17": [
            2227
        ]
    },
    "preparingthetrainingdatausing": {
        "8_17": [
            2228
        ]
    },
    "datagen": {
        "8_17": [
            2230
        ]
    },
    "ThiswaytheTFRecordstraining": {
        "8_17": [
            2231
        ]
    },
    "les": {
        "8_17": [
            2232
        ]
    },
    "processing": {
        "8_17": [
            2238
        ]
    },
    "superiorMoredetailsonTTwithBPEsubwordunitsbySennrichetal": {
        "8_17": [
            2249
        ]
    },
    "vs": {
        "8_17": [
            2250,
            3244
        ]
    },
    "theinternalimplementation": {
        "8_17": [
            2251
        ]
    },
    "canbefoundinthetechnicalreportMorphologicalandLanguage": {
        "8_17": [
            2252
        ]
    },
    "AgnosticWordSegmentationforNMT": {
        "8_17": [
            2253
        ]
    },
    "attached": {
        "8_17": [
            2254
        ]
    },
    "Deliverable": {
        "8_17": [
            2257
        ]
    },
    "project": {
        "8_17": [
            2260,
            7580
        ]
    },
    "QT": {
        "8_17": [
            2261,
            7570
        ]
    },
    "http": {
        "8_17": [
            2262,
            7123,
            7875,
            7932,
            7962,
            7992,
            8027,
            8044,
            8066,
            8128,
            8159,
            8218,
            8243,
            8291,
            8352,
            8375
        ]
    },
    "qt": {
        "8_17": [
            2264
        ]
    },
    "eu": {
        "8_17": [
            2265
        ]
    },
    "superiorThis": {
        "8_17": [
            2270,
            5394
        ]
    },
    "file_byte_budget": {
        "8_17": [
            2275
        ]
    },
    "constant": {
        "8_17": [
            2276,
            2517,
            5768,
            6094,
            6427,
            6467
        ]
    },
    "changed": {
        "8_17": [
            2280
        ]
    },
    "directly": {
        "8_17": [
            2281
        ]
    },
    "code": {
        "8_17": [
            2285
        ]
    },
    "inTTv": {
        "8_17": [
            2286
        ]
    },
    "Asignoftoosmalltrainingdataforthesubwordvocabularyisthatthe": {
        "8_17": [
            2287
        ]
    },
    "min_count": {
        "8_17": [
            2288
        ]
    },
    "asreported": {
        "8_17": [
            2289
        ]
    },
    "logs": {
        "8_17": [
            2292
        ]
    },
    "low": {
        "8_17": [
            2295,
            4118
        ]
    },
    "estimated": {
        "8_17": [
            2300
        ]
    },
    "seen": {
        "8_17": [
            2303,
            7050,
            7484
        ]
    },
    "twice": {
        "8_17": [
            2307
        ]
    },
    "superiorWe": {
        "8_17": [
            2311,
            2577,
            3174,
            3455,
            5574
        ]
    },
    "did": {
        "8_17": [
            2312,
            3473,
            4033
        ]
    },
    "pre": {
        "8_17": [
            2315,
            2360,
            3364
        ]
    },
    "ltering": {
        "8_17": [
            2316
        ]
    },
    "Experiments": {
        "8_17": [
            2320,
            6099
        ]
    },
    "section": {
        "8_17": [
            2323,
            5597,
            6510
        ]
    },
    "present": {
        "8_17": [
            2325
        ]
    },
    "several": {
        "8_17": [
            2326,
            3746,
            4091,
            4135,
            6014
        ]
    },
    "summarizing": {
        "8_17": [
            2329,
            7190
        ]
    },
    "obser": {
        "8_17": [
            2331
        ]
    },
    "vations": {
        "8_17": [
            2332
        ]
    },
    "generally": {
        "8_17": [
            2336
        ]
    },
    "learned": {
        "8_17": [
            2341
        ]
    },
    "done": {
        "8_17": [
            2345,
            5631,
            7174,
            7469
        ]
    },
    "unless": {
        "8_17": [
            2349
        ]
    },
    "stated": {
        "8_17": [
            2350
        ]
    },
    "otherwise": {
        "8_17": [
            2351,
            4160
        ]
    },
    "sets": {
        "8_17": [
            2356
        ]
    },
    "trans": {
        "8_17": [
            2365,
            2385,
            2594,
            3701,
            3801,
            7503
        ]
    },
    "former_big_single_gpu": {
        "8_17": [
            2366
        ]
    },
    "BIG": {
        "8_17": [
            2367,
            2545,
            2558,
            2564,
            2694,
            2719,
            2835,
            2863,
            2870,
            2975,
            3062,
            3371,
            3391,
            3394,
            3470,
            3479,
            3490,
            3522,
            3551,
            3600,
            3629,
            3644,
            3646,
            3773,
            3966,
            4440,
            4443,
            4446,
            4449,
            4452,
            4455,
            4467,
            4569,
            4700,
            4715,
            4785,
            4942,
            5135,
            5326,
            7324,
            7520
        ]
    },
    "transformer_base_single_gpu": {
        "8_17": [
            2369,
            3373,
            3396,
            4221
        ]
    },
    "BASE": {
        "8_17": [
            2370,
            2543,
            2547,
            2693,
            2718,
            2819,
            3374,
            3390,
            3397,
            3416,
            3465,
            3495,
            3500,
            3527,
            3558,
            3586,
            3603,
            3631,
            3648,
            3771,
            4182,
            4185,
            4188,
            4191,
            4194,
            4206,
            4270,
            4481,
            4532,
            4698,
            4775
        ]
    },
    "er": {
        "8_17": [
            2373,
            3036,
            3377,
            6807,
            7880
        ]
    },
    "mainly": {
        "8_17": [
            2374
        ]
    },
    "Note": {
        "8_17": [
            2381,
            5182
        ]
    },
    "transformer_big_single_gpu": {
        "8_17": [
            2383,
            2590,
            3393
        ]
    },
    "former_base_single_gpu": {
        "8_17": [
            2386
        ]
    },
    "names": {
        "8_17": [
            2389
        ]
    },
    "applied": {
        "8_17": [
            2399,
            5999
        ]
    },
    "even": {
        "8_17": [
            2400,
            2596,
            3284,
            3336,
            3563,
            3744,
            4104,
            4337,
            5062,
            5623,
            6258,
            6637
        ]
    },
    "baselinesetting": {
        "8_17": [
            2417
        ]
    },
    "theBIG": {
        "8_17": [
            2419
        ]
    },
    "withits": {
        "8_17": [
            2421
        ]
    },
    "parametersexcept": {
        "8_17": [
            2424
        ]
    },
    "discussion": {
        "8_17": [
            2429
        ]
    },
    "sizes": {
        "8_17": [
            2433,
            2539,
            2542,
            2674,
            7492
        ]
    },
    "train_steps": {
        "8_17": [
            2436
        ]
    },
    "highenough": {
        "8_17": [
            2439
        ]
    },
    "sowecanstopeachexperimentman": {
        "8_17": [
            2440
        ]
    },
    "ually": {
        "8_17": [
            2441
        ]
    },
    "save_checkpoints_secs": {
        "8_17": [
            2444
        ]
    },
    "forces": {
        "8_17": [
            2446
        ]
    },
    "checkpoint": {
        "8_17": [
            2447,
            2646,
            6760,
            6871,
            6964,
            7003,
            7027,
            7029,
            7239,
            7261,
            7296
        ]
    },
    "saving": {
        "8_17": [
            2448,
            7004
        ]
    },
    "schedule": {
        "8_17": [
            2453,
            4931,
            4949,
            5211,
            5728,
            6546
        ]
    },
    "train": {
        "8_17": [
            2454,
            3251,
            3609,
            3650,
            3683,
            5055,
            5222,
            5299,
            6436,
            6821,
            7937
        ]
    },
    "disables": {
        "8_17": [
            2456
        ]
    },
    "internal": {
        "8_17": [
            2458
        ]
    },
    "approx_bleu": {
        "8_17": [
            2461
        ]
    },
    "makes": {
        "8_17": [
            2464,
            4871,
            6646
        ]
    },
    "primarily": {
        "8_17": [
            2480
        ]
    },
    "interested": {
        "8_17": [
            2481
        ]
    },
    "TimeTillScore": {
        "8_17": [
            2490
        ]
    },
    "andwediscussitinthefollowingsections": {
        "8_17": [
            2491
        ]
    },
    "Inthissection": {
        "8_17": [
            2492
        ]
    },
    "focushoweveronlyonthe": {
        "8_17": [
            2494
        ]
    },
    "computationspeed": {
        "8_17": [
            2495
        ]
    },
    "andtrainingthroughput": {
        "8_17": [
            2496
        ]
    },
    "Botharea": {
        "8_17": [
            2497
        ]
    },
    "ected": {
        "8_17": [
            2498
        ]
    },
    "factors": {
        "8_17": [
            2502
        ]
    },
    "almost": {
        "8_17": [
            2516,
            4074,
            4149,
            4872,
            4897,
            6127,
            7033
        ]
    },
    "shows": {
        "8_17": [
            2525,
            2629,
            4000,
            4864,
            5315,
            6199,
            7011
        ]
    },
    "various": {
        "8_17": [
            2537,
            2857,
            3784,
            3955,
            4094
        ]
    },
    "cells": {
        "8_17": [
            2561
        ]
    },
    "where": {
        "8_17": [
            2562,
            3186,
            4222,
            4668,
            5837,
            6464
        ]
    },
    "resulted": {
        "8_17": [
            2566,
            6120,
            6704
        ]
    },
    "errors": {
        "8_17": [
            2571,
            4133,
            4827,
            6415
        ]
    },
    "marked": {
        "8_17": [
            2573,
            5488
        ]
    },
    "OOM": {
        "8_17": [
            2575,
            2706,
            2708,
            2710,
            2731,
            2733,
            2735,
            4435
        ]
    },
    "superiorAccording": {
        "8_17": [
            2583
        ]
    },
    "former_big": {
        "8_17": [
            2595
        ]
    },
    "although": {
        "8_17": [
            2601,
            4490
        ]
    },
    "naming": {
        "8_17": [
            2603
        ]
    },
    "suggests": {
        "8_17": [
            2604,
            5744,
            5774
        ]
    },
    "authors": {
        "8_17": [
            2608
        ]
    },
    "opposite": {
        "8_17": [
            2611
        ]
    },
    "experience": {
        "8_17": [
            2612
        ]
    },
    "superiorAlsotherearesomeproblemswiththealternativeschedules": {
        "8_17": [
            2614
        ]
    },
    "train_and_evaluate": {
        "8_17": [
            2615
        ]
    },
    "itneedsmoremem": {
        "8_17": [
            2616
        ]
    },
    "ory": {
        "8_17": [
            2617
        ]
    },
    "continuous_train_and_eval": {
        "8_17": [
            2619
        ]
    },
    "superiorTensorBoard": {
        "8_17": [
            2628
        ]
    },
    "global_step": {
        "8_17": [
            2630,
            6351
        ]
    },
    "sec": {
        "8_17": [
            2631
        ]
    },
    "statistics": {
        "8_17": [
            2632
        ]
    },
    "curve": {
        "8_17": [
            2638,
            3888,
            3983,
            5087,
            5106,
            6190,
            6684,
            6709,
            7021,
            7067
        ]
    },
    "These": {
        "8_17": [
            2639,
            7240
        ]
    },
    "experimentsarealmostconstantforthewholetrainingwithvariationwithin": {
        "8_17": [
            2643
        ]
    },
    "exceptformomentswhen": {
        "8_17": [
            2644
        ]
    },
    "saved": {
        "8_17": [
            2649
        ]
    },
    "slower": {
        "8_17": [
            2657,
            5111
        ]
    },
    "superiorFor": {
        "8_17": [
            2659
        ]
    },
    "able": {
        "8_17": [
            2669,
            5053,
            6142,
            6156
        ]
    },
    "additional": {
        "8_17": [
            2677
        ]
    },
    "checked": {
        "8_17": [
            2680,
            4084
        ]
    },
    "decreases": {
        "8_17": [
            2753
        ]
    },
    "increasing": {
        "8_17": [
            2755,
            2775,
            4776,
            5544,
            5904,
            6147,
            6162,
            6355
        ]
    },
    "operations": {
        "8_17": [
            2761
        ]
    },
    "parallelizable": {
        "8_17": [
            2767
        ]
    },
    "grows": {
        "8_17": [
            2771,
            2898,
            3573,
            7068
        ]
    },
    "sub": {
        "8_17": [
            2772
        ]
    },
    "linearly": {
        "8_17": [
            2773,
            5902
        ]
    },
    "there": {
        "8_17": [
            2784,
            4152,
            4902,
            5137,
            5625,
            5864
        ]
    },
    "advantage": {
        "8_17": [
            2789,
            4400,
            6996
        ]
    },
    "value": {
        "8_17": [
            2798,
            4868,
            6735
        ]
    },
    "return": {
        "8_17": [
            2801
        ]
    },
    "question": {
        "8_17": [
            2804,
            5721
        ]
    },
    "into": {
        "8_17": [
            2809
        ]
    },
    "account": {
        "8_17": [
            2810
        ]
    },
    "approximately": {
        "8_17": [
            2822
        ]
    },
    "relative": {
        "8_17": [
            2832,
            2915,
            6589
        ]
    },
    "numbers": {
        "8_17": [
            2858,
            5321
        ]
    },
    "overhead": {
        "8_17": [
            2881,
            2923,
            2980,
            2990
        ]
    },
    "synchronization": {
        "8_17": [
            2884
        ]
    },
    "apparent": {
        "8_17": [
            2886
        ]
    },
    "Nevertheless": {
        "8_17": [
            2893
        ]
    },
    "process": {
        "8_17": [
            2908
        ]
    },
    "without": {
        "8_17": [
            2921,
            3972,
            4425,
            5063,
            5384,
            5769,
            5791,
            7039,
            8061
        ]
    },
    "hypothetically": {
        "8_17": [
            2926
        ]
    },
    "expect": {
        "8_17": [
            2927,
            6744
        ]
    },
    "days": {
        "8_17": [
            2937,
            3083,
            3123,
            3131,
            3198,
            3207,
            3260,
            3295,
            3323,
            3338,
            3579,
            4098,
            4305,
            5473,
            7089,
            7152,
            7329
        ]
    },
    "Figure": {
        "8_17": [
            2944,
            3505,
            3532,
            3862,
            3946,
            4197,
            4319,
            4412,
            4458,
            4657,
            4732,
            4863,
            4976,
            5314,
            5392,
            5478,
            5539,
            6867,
            7010,
            7150
        ]
    },
    "alternative": {
        "8_17": [
            2964
        ]
    },
    "Both": {
        "8_17": [
            2971,
            3049,
            5453
        ]
    },
    "Scaling": {
        "8_17": [
            2998,
            5984,
            8363
        ]
    },
    "increases": {
        "8_17": [
            3005,
            3019
        ]
    },
    "Forthisexperiment": {
        "8_17": [
            3026
        ]
    },
    "wesubstitutedCzEng": {
        "8_17": [
            3027
        ]
    },
    "withCzEng": {
        "8_17": [
            3028
        ]
    },
    "inthetrainingdata": {
        "8_17": [
            3029
        ]
    },
    "sothetotaltrainingsizeismillionsentencepairs": {
        "8_17": [
            3030
        ]
    },
    "MofEnglish": {
        "8_17": [
            3032
        ]
    },
    "FigurecomparestheBLEUlearningcurvesoftwoexperimentswhichdi": {
        "8_17": [
            3035
        ]
    },
    "baseline": {
        "8_17": [
            3043,
            5090,
            5118,
            7038,
            7065
        ]
    },
    "versus": {
        "8_17": [
            3045,
            5301
        ]
    },
    "converges": {
        "8_17": [
            3076
        ]
    },
    "improve": {
        "8_17": [
            3089,
            6746
        ]
    },
    "next": {
        "8_17": [
            3092,
            5596
        ]
    },
    "week": {
        "8_17": [
            3093,
            3287
        ]
    },
    "gives": {
        "8_17": [
            3101,
            4487
        ]
    },
    "slightly": {
        "8_17": [
            3102,
            3189,
            4348,
            5110,
            6989,
            7163
        ]
    },
    "worse": {
        "8_17": [
            3103,
            3190,
            3890
        ]
    },
    "eight": {
        "8_17": [
            3108,
            3130,
            3206,
            3291,
            5653
        ]
    },
    "shown": {
        "8_17": [
            3113,
            3977,
            4885,
            5542,
            7148
        ]
    },
    "graph": {
        "8_17": [
            3116
        ]
    },
    "reaching": {
        "8_17": [
            3126,
            3161
        ]
    },
    "With": {
        "8_17": [
            3134,
            3623
        ]
    },
    "trainingoneepochofthesmallerdataset": {
        "8_17": [
            3137
        ]
    },
    "takesksteps": {
        "8_17": [
            3140
        ]
    },
    "hoursoftraining": {
        "8_17": [
            3141
        ]
    },
    "comparedtoksteps": {
        "8_17": [
            3142
        ]
    },
    "means": {
        "8_17": [
            3151,
            4893,
            6578
        ]
    },
    "convergence": {
        "8_17": [
            3163,
            3223,
            3228,
            4553,
            5112,
            5608
        ]
    },
    "compared": {
        "8_17": [
            3175,
            7282
        ]
    },
    "datasets": {
        "8_17": [
            3178,
            3238
        ]
    },
    "another": {
        "8_17": [
            3181,
            3302,
            3312,
            3567,
            4034,
            5643,
            6931
        ]
    },
    "gave": {
        "8_17": [
            3188
        ]
    },
    "hypothesize": {
        "8_17": [
            3209
        ]
    },
    "cleaner": {
        "8_17": [
            3213,
            3243
        ]
    },
    "datasetstartsbeingclearlybetter": {
        "8_17": [
            3216
        ]
    },
    "evenepochsinthebiggerdatasetwerenot": {
        "8_17": [
            3218
        ]
    },
    "enough": {
        "8_17": [
            3219,
            3224,
            3253,
            4070,
            5434
        ]
    },
    "reach": {
        "8_17": [
            3221,
            3226,
            3446,
            3475,
            5372
        ]
    },
    "comparing": {
        "8_17": [
            3235
        ]
    },
    "noisier": {
        "8_17": [
            3247
        ]
    },
    "misleading": {
        "8_17": [
            3269
        ]
    },
    "half": {
        "8_17": [
            3279
        ]
    },
    "gigaword": {
        "8_17": [
            3281
        ]
    },
    "improves": {
        "8_17": [
            3283
        ]
    },
    "cannot": {
        "8_17": [
            3305,
            6906
        ]
    },
    "interpolate": {
        "8_17": [
            3307
        ]
    },
    "While": {
        "8_17": [
            3314,
            7341,
            7443
        ]
    },
    "continues": {
        "8_17": [
            3334,
            4671
        ]
    },
    "Choosing": {
        "8_17": [
            3343
        ]
    },
    "reasons": {
        "8_17": [
            3352
        ]
    },
    "maynot": {
        "8_17": [
            3355
        ]
    },
    "tanymoreonyourGPUortheymayrequiretouseaverysmallbatchsize": {
        "8_17": [
            3356
        ]
    },
    "superioras": {
        "8_17": [
            3363
        ]
    },
    "transfor": {
        "8_17": [
            3369
        ]
    },
    "mer_big_single_gpu": {
        "8_17": [
            3370
        ]
    },
    "four": {
        "8_17": [
            3379,
            5269
        ]
    },
    "summarized": {
        "8_17": [
            3382
        ]
    },
    "hidden_size": {
        "8_17": [
            3386
        ]
    },
    "lter_size": {
        "8_17": [
            3387
        ]
    },
    "num_heads": {
        "8_17": [
            3388
        ]
    },
    "adam_beta": {
        "8_17": [
            3389
        ]
    },
    "erences": {
        "8_17": [
            3401,
            6017
        ]
    },
    "FigureshowsthatonasingleGPU": {
        "8_17": [
            3402
        ]
    },
    "theBIGmodelbecomesclearlybetterthanthe": {
        "8_17": [
            3403
        ]
    },
    "BASEmodelafterhoursoftrainingifwekeepthebatchsizethesame": {
        "8_17": [
            3404
        ]
    },
    "andwe": {
        "8_17": [
            3405
        ]
    },
    "rmed": {
        "8_17": [
            3408,
            5288
        ]
    },
    "takes": {
        "8_17": [
            3418,
            7271
        ]
    },
    "lessmemory": {
        "8_17": [
            3419
        ]
    },
    "sowecana": {
        "8_17": [
            3420
        ]
    },
    "ordahigherbatchsize": {
        "8_17": [
            3421
        ]
    },
    "inourcase": {
        "8_17": [
            3422
        ]
    },
    "withno": {
        "8_17": [
            3423
        ]
    },
    "restriction": {
        "8_17": [
            3425,
            3986,
            4059
        ]
    },
    "seethenextsection": {
        "8_17": [
            3426
        ]
    },
    "whichimprovestheBLEU": {
        "8_17": [
            3427
        ]
    },
    "Buteven": {
        "8_17": [
            3429
        ]
    },
    "Althoughsuchanexpectationmayseemnave": {
        "8_17": [
            3432
        ]
    },
    "wecan": {
        "8_17": [
            3433
        ]
    },
    "nditinliterature": {
        "8_17": [
            3434
        ]
    },
    "Forexample": {
        "8_17": [
            3435,
            4294
        ]
    },
    "Bottou": {
        "8_17": [
            3436,
            5820,
            6236,
            7782,
            7802
        ]
    },
    "inSection": {
        "8_17": [
            3437
        ]
    },
    "writes": {
        "8_17": [
            3438
        ]
    },
    "Expectthevalidationperformancetoplateauafteranumberofepochsroughlycomparableto": {
        "8_17": [
            3439
        ]
    },
    "dont": {
        "8_17": [
            3482
        ]
    },
    "less": {
        "8_17": [
            3545,
            3624,
            5518,
            5531,
            6998,
            7452
        ]
    },
    "day": {
        "8_17": [
            3548,
            3613,
            7510
        ]
    },
    "becomes": {
        "8_17": [
            3555,
            5038
        ]
    },
    "Figurecon": {
        "8_17": [
            3582
        ]
    },
    "rmsthiswithGPUshereBIGwithbatchsizebecomesclearly": {
        "8_17": [
            3583
        ]
    },
    "Prefer": {
        "8_17": [
            3598
        ]
    },
    "you": {
        "8_17": [
            3606,
            3626,
            5185,
            5193,
            8299
        ]
    },
    "plan": {
        "8_17": [
            3607
        ]
    },
    "GB": {
        "8_17": [
            3616,
            7513
        ]
    },
    "available": {
        "8_17": [
            3620,
            5614
        ]
    },
    "benchmark": {
        "8_17": [
            3628
        ]
    },
    "Adam": {
        "8_17": [
            3645,
            3649,
            3669,
            3776,
            3908,
            5463,
            6074,
            6794
        ]
    },
    "Adafactor": {
        "8_17": [
            3647,
            3671,
            3778,
            3926,
            8170
        ]
    },
    "none": {
        "8_17": [
            3652,
            6171
        ]
    },
    "Maximumbatchsizewhich": {
        "8_17": [
            3654
        ]
    },
    "tsintoGBmemoryforvariouscombinations": {
        "8_17": [
            3655
        ]
    },
    "ofmax_length": {
        "8_17": [
            3656
        ]
    },
    "base": {
        "8_17": [
            3664
        ]
    },
    "big": {
        "8_17": [
            3666
        ]
    },
    "optimizer": {
        "8_17": [
            3668
        ]
    },
    "last": {
        "8_17": [
            3673,
            3805,
            6955,
            7160
        ]
    },
    "columns": {
        "8_17": [
            3675,
            3807
        ]
    },
    "show": {
        "8_17": [
            3676,
            3810,
            3863,
            5926,
            6810
        ]
    },
    "percentage": {
        "8_17": [
            3678,
            4143
        ]
    },
    "Forfastdebugging": {
        "8_17": [
            3696
        ]
    },
    "ofmodel": {
        "8_17": [
            3697
        ]
    },
    "unrelatedaspects": {
        "8_17": [
            3699
        ]
    },
    "useamodelcalled": {
        "8_17": [
            3700
        ]
    },
    "former_tiny": {
        "8_17": [
            3702
        ]
    },
    "Maximum": {
        "8_17": [
            3703
        ]
    },
    "Sentence": {
        "8_17": [
            3705
        ]
    },
    "Length": {
        "8_17": [
            3706
        ]
    },
    "Theparameter": {
        "8_17": [
            3707
        ]
    },
    "esthemaximumlengthofasentenceinsubwords": {
        "8_17": [
            3710
        ]
    },
    "Longersentences": {
        "8_17": [
            3711
        ]
    },
    "eitherinsourceortargetlanguage": {
        "8_17": [
            3712
        ]
    },
    "areexcludedfromthetraining": {
        "8_17": [
            3713
        ]
    },
    "completely": {
        "8_17": [
            3714,
            6854
        ]
    },
    "If": {
        "8_17": [
            3715,
            5017,
            6552
        ]
    },
    "Loweringthe": {
        "8_17": [
            3729
        ]
    },
    "allowstouseahigherbatchsizeorabiggermodel": {
        "8_17": [
            3731
        ]
    },
    "Since": {
        "8_17": [
            3732
        ]
    },
    "suddenly": {
        "8_17": [
            3739
        ]
    },
    "good": {
        "8_17": [
            3752,
            5812
        ]
    },
    "know": {
        "8_17": [
            3754,
            4343
        ]
    },
    "ts": {
        "8_17": [
            3759
        ]
    },
    "your": {
        "8_17": [
            3761
        ]
    },
    "presents": {
        "8_17": [
            3764
        ]
    },
    "what": {
        "8_17": [
            3765,
            4245,
            4691
        ]
    },
    "measured": {
        "8_17": [
            3768,
            4286
        ]
    },
    "superioroptimizers": {
        "8_17": [
            3782
        ]
    },
    "Setting": {
        "8_17": [
            3787,
            4876,
            5100
        ]
    },
    "toolowwouldresultinexcludingtoomanytrainingsentences": {
        "8_17": [
            3789
        ]
    },
    "biasing": {
        "8_17": [
            3791
        ]
    },
    "shorter": {
        "8_17": [
            3795
        ]
    },
    "hurt": {
        "8_17": [
            3799
        ]
    },
    "lation": {
        "8_17": [
            3802,
            7504,
            7745
        ]
    },
    "resp": {
        "8_17": [
            3815,
            3820,
            3829
        ]
    },
    "detrimental": {
        "8_17": [
            3840
        ]
    },
    "bias": {
        "8_17": [
            3849
        ]
    },
    "minimal": {
        "8_17": [
            3852,
            4795
        ]
    },
    "strange": {
        "8_17": [
            3865
        ]
    },
    "drop": {
        "8_17": [
            3866,
            4677
        ]
    },
    "lower": {
        "8_17": [
            3880,
            7023,
            7130,
            7361
        ]
    },
    "Even": {
        "8_17": [
            3881
        ]
    },
    "nallygivesthesameresultasnotusingany": {
        "8_17": [
            3895
        ]
    },
    "superiorTheAdafactoroptimizer": {
        "8_17": [
            3900
        ]
    },
    "ShazeerandStern": {
        "8_17": [
            3901
        ]
    },
    "isavailableonlyinTT": {
        "8_17": [
            3902
        ]
    },
    "ornewerandhasthree": {
        "8_17": [
            3903
        ]
    },
    "second": {
        "8_17": [
            3916,
            7137
        ]
    },
    "moments": {
        "8_17": [
            3917
        ]
    },
    "weights": {
        "8_17": [
            3920
        ]
    },
    "future": {
        "8_17": [
            3928,
            5416,
            5699
        ]
    },
    "work": {
        "8_17": [
            3929,
            5700
        ]
    },
    "max": {
        "8_17": [
            3934,
            3936,
            3938,
            3940,
            3942,
            3944
        ]
    },
    "restricting": {
        "8_17": [
            3950
        ]
    },
    "An": {
        "8_17": [
            3970
        ]
    },
    "Thetraininglossof": {
        "8_17": [
            3987
        ]
    },
    "andand": {
        "8_17": [
            3989
        ]
    },
    "hashighvarianceand": {
        "8_17": [
            3990
        ]
    },
    "stops": {
        "8_17": [
            3991
        ]
    },
    "increase": {
        "8_17": [
            4003,
            4918,
            5195,
            6528
        ]
    },
    "diverged": {
        "8_17": [
            4009,
            4685,
            4801,
            4909,
            5162,
            6122
        ]
    },
    "discussed": {
        "8_17": [
            4011
        ]
    },
    "explanation": {
        "8_17": [
            4024,
            5793
        ]
    },
    "phenomenon": {
        "8_17": [
            4027
        ]
    },
    "slowergrowingBLEUcurves": {
        "8_17": [
            4056
        ]
    },
    "butandhigherhasthesamecurveasno": {
        "8_17": [
            4057
        ]
    },
    "So": {
        "8_17": [
            4060,
            6353,
            6473,
            6831
        ]
    },
    "observed": {
        "8_17": [
            4100
        ]
    },
    "thattheyarenotabletoproducelongertranslationsthanwhatwasthemaximumlengthused": {
        "8_17": [
            4101
        ]
    },
    "decoding": {
        "8_17": [
            4109
        ]
    },
    "alpha": {
        "8_17": [
            4111
        ]
    },
    "Set": {
        "8_17": [
            4115
        ]
    },
    "reasonably": {
        "8_17": [
            4117
        ]
    },
    "prevents": {
        "8_17": [
            4129
        ]
    },
    "isahigherchancethatthetrainingwillfaileitherimmediately": {
        "8_17": [
            4153
        ]
    },
    "ifthebatchsize": {
        "8_17": [
            4154
        ]
    },
    "Setareasonablyhigh": {
        "8_17": [
            4161
        ]
    },
    "Considerthepercentageofsentencesexcluded": {
        "8_17": [
            4163
        ]
    },
    "fromtrainingandfromthetargeteddevelopmenttestsetandalsowatchforun": {
        "8_17": [
            4164
        ]
    },
    "expecteddrops": {
        "8_17": [
            4165
        ]
    },
    "orstagnations": {
        "8_17": [
            4166
        ]
    },
    "oftheBLEUcurveinthe": {
        "8_17": [
            4167
        ]
    },
    "rsthoursoftraining": {
        "8_17": [
            4168
        ]
    },
    "Thedefault": {
        "8_17": [
            4216
        ]
    },
    "valueinrecentTTversionsissubwordsforallmodels": {
        "8_17": [
            4218
        ]
    },
    "except": {
        "8_17": [
            4219,
            4429
        ]
    },
    "recommend": {
        "8_17": [
            4228
        ]
    },
    "explicitly": {
        "8_17": [
            4235
        ]
    },
    "superioror": {
        "8_17": [
            4239
        ]
    },
    "least": {
        "8_17": [
            4241,
            5397,
            7508
        ]
    },
    "make": {
        "8_17": [
            4242,
            6966
        ]
    },
    "note": {
        "8_17": [
            4244
        ]
    },
    "experimental": {
        "8_17": [
            4256
        ]
    },
    "Figureshowslearningcurvesfor": {
        "8_17": [
            4258
        ]
    },
    "vedi": {
        "8_17": [
            4259
        ]
    },
    "erentbatchsizes": {
        "8_17": [
            4260
        ]
    },
    "superiorA": {
        "8_17": [
            4273
        ]
    },
    "sizeup": {
        "8_17": [
            4276
        ]
    },
    "ExamplesTillScoremetricsde": {
        "8_17": [
            4292
        ]
    },
    "nedinSection": {
        "8_17": [
            4293
        ]
    },
    "togetoverBLEUof": {
        "8_17": [
            4295
        ]
    },
    "weneedhours": {
        "8_17": [
            4298
        ]
    },
    "Mexamples": {
        "8_17": [
            4299
        ]
    },
    "andwith": {
        "8_17": [
            4300
        ]
    },
    "FromTableaweknowthatbiggerbatcheshaveslowercomputationspeed": {
        "8_17": [
            4315
        ]
    },
    "sowhen": {
        "8_17": [
            4316
        ]
    },
    "re": {
        "8_17": [
            4317,
            4354,
            4423
        ]
    },
    "plotting": {
        "8_17": [
            4318,
            4355
        ]
    },
    "x": {
        "8_17": [
            4327,
            4363,
            5306
        ]
    },
    "axis": {
        "8_17": [
            4328,
            4364,
            5307
        ]
    },
    "From": {
        "8_17": [
            4339
        ]
    },
    "exceptionisthedi": {
        "8_17": [
            4376
        ]
    },
    "erencebetweenbatchsizeand": {
        "8_17": [
            4377
        ]
    },
    "whichisverysmalland": {
        "8_17": [
            4378
        ]
    },
    "superiore": {
        "8_17": [
            4382
        ]
    },
    "hparams": {
        "8_17": [
            4384
        ]
    },
    "learning_rate": {
        "8_17": [
            4386,
            4915,
            5145,
            6438,
            6447,
            6471,
            6514,
            6730
        ]
    },
    "learning_rate_warmup_steps": {
        "8_17": [
            4387,
            4919,
            4925,
            5147
        ]
    },
    "power": {
        "8_17": [
            4403
        ]
    },
    "superiorAll": {
        "8_17": [
            4408
        ]
    },
    "got": {
        "8_17": [
            4418
        ]
    },
    "running": {
        "8_17": [
            4424,
            5646
        ]
    },
    "restrictions": {
        "8_17": [
            4428
        ]
    },
    "failed": {
        "8_17": [
            4433
        ]
    },
    "canbefullyexplainedbythefactthatbatchsizehas": {
        "8_17": [
            4475
        ]
    },
    "higherthroughputthan": {
        "8_17": [
            4476
        ]
    },
    "Sofor": {
        "8_17": [
            4479
        ]
    },
    "dimin": {
        "8_17": [
            4492
        ]
    },
    "ishing": {
        "8_17": [
            4493
        ]
    },
    "returns": {
        "8_17": [
            4494
        ]
    },
    "observation": {
        "8_17": [
            4496,
            6230
        ]
    },
    "goes": {
        "8_17": [
            4497
        ]
    },
    "common": {
        "8_17": [
            4500,
            4905
        ]
    },
    "knowledge": {
        "8_17": [
            4501
        ]
    },
    "frameworks": {
        "8_17": [
            4505
        ]
    },
    "deep": {
        "8_17": [
            4507
        ]
    },
    "Keskar": {
        "8_17": [
            4511,
            7996
        ]
    },
    "proceedslower": {
        "8_17": [
            4517
        ]
    },
    "trainingexamplesperhour": {
        "8_17": [
            4518
        ]
    },
    "butresultinbettergeneralization": {
        "8_17": [
            4519
        ]
    },
    "end": {
        "8_17": [
            4526
        ]
    },
    "expected": {
        "8_17": [
            4548,
            5568
        ]
    },
    "Interestingly": {
        "8_17": [
            4562
        ]
    },
    "replicating": {
        "8_17": [
            4564
        ]
    },
    "erentresults": {
        "8_17": [
            4575
        ]
    },
    "asshowninFigure": {
        "8_17": [
            4576
        ]
    },
    "TheBIGmodelneedsacertainminimalbatchsize": {
        "8_17": [
            4577
        ]
    },
    "tostartconvergingatall": {
        "8_17": [
            4578
        ]
    },
    "butforhigherbatchsizesthereisalmostnodi": {
        "8_17": [
            4579
        ]
    },
    "erenceinthe": {
        "8_17": [
            4580
        ]
    },
    "BLEUcurves": {
        "8_17": [
            4581
        ]
    },
    "butstill": {
        "8_17": [
            4582
        ]
    },
    "biggerbatchnevermakestheBLEUworseinourexperiments": {
        "8_17": [
            4583
        ]
    },
    "sharp": {
        "8_17": [
            4588,
            5860
        ]
    },
    "trains": {
        "8_17": [
            4596
        ]
    },
    "drops": {
        "8_17": [
            4600
        ]
    },
    "o": {
        "8_17": [
            4601,
            7114
        ]
    },
    "recovering": {
        "8_17": [
            4607
        ]
    },
    "slowly": {
        "8_17": [
            4609,
            4681
        ]
    },
    "According": {
        "8_17": [
            4610,
            6985
        ]
    },
    "Smith": {
        "8_17": [
            4612,
            4616,
            6917,
            8187,
            8222,
            8336
        ]
    },
    "gradient": {
        "8_17": [
            4620,
            4922,
            5165,
            5766,
            5830,
            5885
        ]
    },
    "scale": {
        "8_17": [
            4622,
            5832,
            5898,
            5949,
            6261
        ]
    },
    "scaleofrandom": {
        "8_17": [
            4625
        ]
    },
    "uctuationsintheSGD": {
        "8_17": [
            4626
        ]
    },
    "orAdametc": {
        "8_17": [
            4627
        ]
    },
    "dynamics": {
        "8_17": [
            4628
        ]
    },
    "isproportional": {
        "8_17": [
            4629
        ]
    },
    "divided": {
        "8_17": [
            4633
        ]
    },
    "cf": {
        "8_17": [
            4638,
            5004,
            6642,
            7207
        ]
    },
    "Thus": {
        "8_17": [
            4640,
            6239
        ]
    },
    "lowering": {
        "8_17": [
            4642
        ]
    },
    "batchsize": {
        "8_17": [
            4644
        ]
    },
    "weincreasethenoisescaleandthetrainingmay": {
        "8_17": [
            4645
        ]
    },
    "diverge": {
        "8_17": [
            4646
        ]
    },
    "Thismaybeeither": {
        "8_17": [
            4647
        ]
    },
    "permanent": {
        "8_17": [
            4648
        ]
    },
    "temporary": {
        "8_17": [
            4659,
            4676
        ]
    },
    "grow": {
        "8_17": [
            4673
        ]
    },
    "sure": {
        "8_17": [
            4690,
            5427,
            6967
        ]
    },
    "causes": {
        "8_17": [
            4692
        ]
    },
    "regards": {
        "8_17": [
            4703
        ]
    },
    "One": {
        "8_17": [
            4710,
            8033
        ]
    },
    "hypothesis": {
        "8_17": [
            4711,
            6242
        ]
    },
    "initialize": {
        "8_17": [
            4760
        ]
    },
    "sensitive": {
        "8_17": [
            4764
        ]
    },
    "divergence": {
        "8_17": [
            4766,
            5019,
            5065,
            6145,
            6168,
            6602,
            6629,
            6715
        ]
    },
    "phase": {
        "8_17": [
            4771,
            6565
        ]
    },
    "highly": {
        "8_17": [
            4781
        ]
    },
    "helpful": {
        "8_17": [
            4782
        ]
    },
    "until": {
        "8_17": [
            4783
        ]
    },
    "limit": {
        "8_17": [
            4787,
            7445
        ]
    },
    "preventing": {
        "8_17": [
            4800
        ]
    },
    "Tip": {
        "8_17": [
            4803
        ]
    },
    "keeping": {
        "8_17": [
            4817,
            5880,
            6512
        ]
    },
    "reserve": {
        "8_17": [
            4819
        ]
    },
    "hitting": {
        "8_17": [
            4822
        ]
    },
    "advisable": {
        "8_17": [
            4830
        ]
    },
    "establish": {
        "8_17": [
            4832
        ]
    },
    "largest": {
        "8_17": [
            4834
        ]
    },
    "before": {
        "8_17": [
            4838
        ]
    },
    "Rate": {
        "8_17": [
            4846,
            5155,
            5702,
            5983,
            6294,
            6721,
            8236
        ]
    },
    "Warmup": {
        "8_17": [
            4848,
            5157,
            5704,
            6723
        ]
    },
    "Single": {
        "8_17": [
            4852
        ]
    },
    "learningratetoolow": {
        "8_17": [
            4878
        ]
    },
    "resultsinnotablyslowerconvergence": {
        "8_17": [
            4879
        ]
    },
    "Settingthelearning": {
        "8_17": [
            4880
        ]
    },
    "gure": {
        "8_17": [
            4888
        ]
    },
    "divergedtraining": {
        "8_17": [
            4891
        ]
    },
    "inthiscasethatthelearningcurvestartsgrowingasusual": {
        "8_17": [
            4894
        ]
    },
    "butatonemomentdrops": {
        "8_17": [
            4895
        ]
    },
    "down": {
        "8_17": [
            4896,
            6213
        ]
    },
    "stays": {
        "8_17": [
            4901,
            6449
        ]
    },
    "forever": {
        "8_17": [
            4903
        ]
    },
    "introduce": {
        "8_17": [
            4921,
            6043
        ]
    },
    "clipping": {
        "8_17": [
            4923,
            5166
        ]
    },
    "linear_warmup_rsqrt_decay": {
        "8_17": [
            4930,
            6543
        ]
    },
    "superiorand": {
        "8_17": [
            4933,
            5425
        ]
    },
    "superiorThe": {
        "8_17": [
            4948
        ]
    },
    "called": {
        "8_17": [
            4951,
            6048
        ]
    },
    "noamin": {
        "8_17": [
            4952
        ]
    },
    "versions": {
        "8_17": [
            4954,
            5400
        ]
    },
    "rstkstepsthelearningrategrowslinearlyandthenfollowsaninversesquare": {
        "8_17": [
            5000
        ]
    },
    "root": {
        "8_17": [
            5001,
            6080,
            6380
        ]
    },
    "decay": {
        "8_17": [
            5002,
            6083,
            6097,
            6428,
            6455
        ]
    },
    "t": {
        "8_17": [
            5003,
            7527
        ]
    },
    "highest": {
        "8_17": [
            5016,
            5040
        ]
    },
    "happen": {
        "8_17": [
            5022
        ]
    },
    "happens": {
        "8_17": [
            5025
        ]
    },
    "increased": {
        "8_17": [
            5043
        ]
    },
    "looked": {
        "8_17": [
            5069
        ]
    },
    "similarly": {
        "8_17": [
            5070
        ]
    },
    "baselineone": {
        "8_17": [
            5073
        ]
    },
    "withdefaultvaluesofkwarmupstepsandlearningrate": {
        "8_17": [
            5074
        ]
    },
    "tryinglearningrate": {
        "8_17": [
            5076
        ]
    },
    "wehadtoincreasewarmupstepstok": {
        "8_17": [
            5077
        ]
    },
    "withkthetraining": {
        "8_17": [
            5078
        ]
    },
    "divergedafteronehour": {
        "8_17": [
            5079
        ]
    },
    "thisresultedinaslowerconvergenceat": {
        "8_17": [
            5080
        ]
    },
    "aboutBLEU": {
        "8_17": [
            5082
        ]
    },
    "lowerthanthebaselineafterhoursoftraining": {
        "8_17": [
            5083
        ]
    },
    "butafterdaysoftraininghaving": {
        "8_17": [
            5084
        ]
    },
    "Figureshowsthee": {
        "8_17": [
            5091
        ]
    },
    "ectofdi": {
        "8_17": [
            5092
        ]
    },
    "erentwarmupstepswitha": {
        "8_17": [
            5093
        ]
    },
    "xedlearningrate": {
        "8_17": [
            5094
        ]
    },
    "Settingwarmupstepstoolow": {
        "8_17": [
            5097
        ]
    },
    "resultsindivergedtraining": {
        "8_17": [
            5099
        ]
    },
    "green": {
        "8_17": [
            5105
        ]
    },
    "matching": {
        "8_17": [
            5116
        ]
    },
    "largerangeoflearningrateandwarmupstepsvaluesthatachievetheoptimalresults": {
        "8_17": [
            5141
        ]
    },
    "try": {
        "8_17": [
            5164,
            5177,
            5665
        ]
    },
    "Ifthatdoesnothelp": {
        "8_17": [
            5172
        ]
    },
    "orifthewarmupstepsaretoohighrelativetotheexpected": {
        "8_17": [
            5173
        ]
    },
    "lin": {
        "8_17": [
            5207
        ]
    },
    "ear_warmup_rsqrt_decay": {
        "8_17": [
            5208
        ]
    },
    "aka": {
        "8_17": [
            5209,
            6544
        ]
    },
    "noam": {
        "8_17": [
            5210,
            6545
        ]
    },
    "Number": {
        "8_17": [
            5216,
            5601
        ]
    },
    "simply": {
        "8_17": [
            5230,
            5674
        ]
    },
    "worker_gpus": {
        "8_17": [
            5234
        ]
    },
    "superiorAs": {
        "8_17": [
            5236
        ]
    },
    "explained": {
        "8_17": [
            5237
        ]
    },
    "interpreted": {
        "8_17": [
            5244
        ]
    },
    "Asingle": {
        "8_17": [
            5258
        ]
    },
    "GPUexperimentwithbatchsize": {
        "8_17": [
            5259
        ]
    },
    "shouldgiveexactlythesameresults": {
        "8_17": [
            5260
        ]
    },
    "Whenconsideringtime": {
        "8_17": [
            5308
        ]
    },
    "thefour": {
        "8_17": [
            5309
        ]
    },
    "GPUexperimentwillbethefastestone": {
        "8_17": [
            5310
        ]
    },
    "asexplained": {
        "8_17": [
            5311
        ]
    },
    "andk": {
        "8_17": [
            5341
        ]
    },
    "Ascouldbeexpected": {
        "8_17": [
            5343
        ]
    },
    "trainingwithmoreGPUsconverges": {
        "8_17": [
            5344
        ]
    },
    "WhatisinterestingistheTimeTillScore": {
        "8_17": [
            5346
        ]
    },
    "Tableliststheapproximatetraining": {
        "8_17": [
            5347
        ]
    },
    "timeandnumberoftrainingexamples": {
        "8_17": [
            5348
        ]
    },
    "inmillionsofsubwords": {
        "8_17": [
            5349
        ]
    },
    "neededtosurpass": {
        "8_17": [
            5350
        ]
    },
    "again": {
        "8_17": [
            5356,
            5790
        ]
    },
    "fall": {
        "8_17": [
            5357
        ]
    },
    "andExamplesTillScore": {
        "8_17": [
            5380
        ]
    },
    "NotethattheexperimentonGPUwasendedafterdays": {
        "8_17": [
            5381
        ]
    },
    "surpassing": {
        "8_17": [
            5386
        ]
    },
    "outside": {
        "8_17": [
            5390
        ]
    },
    "holds": {
        "8_17": [
            5395,
            5622,
            6539
        ]
    },
    "unexpected": {
        "8_17": [
            5406
        ]
    },
    "unintuitive": {
        "8_17": [
            5407
        ]
    },
    "users": {
        "8_17": [
            5410
        ]
    },
    "making": {
        "8_17": [
            5426
        ]
    },
    "environment": {
        "8_17": [
            5428
        ]
    },
    "variable": {
        "8_17": [
            5429
        ]
    },
    "CUDA_VISIBLE_DEVICES": {
        "8_17": [
            5430
        ]
    },
    "cards": {
        "8_17": [
            5435
        ]
    },
    "distributed": {
        "8_17": [
            5441,
            5459,
            7575
        ]
    },
    "machines": {
        "8_17": [
            5445
        ]
    },
    "experimented": {
        "8_17": [
            5450
        ]
    },
    "multi": {
        "8_17": [
            5456,
            5667,
            6655
        ]
    },
    "gpu": {
        "8_17": [
            5457
        ]
    },
    "synchronous": {
        "8_17": [
            5462
        ]
    },
    "updates": {
        "8_17": [
            5464,
            6829
        ]
    },
    "black": {
        "8_17": [
            5491
        ]
    },
    "line": {
        "8_17": [
            5492
        ]
    },
    "measuring": {
        "8_17": [
            5510
        ]
    },
    "lowerExamplesTillScore": {
        "8_17": [
            5525
        ]
    },
    "Similarly": {
        "8_17": [
            5526,
            6133
        ]
    },
    "eightGPUsaremorethan": {
        "8_17": [
            5527
        ]
    },
    "vetimesfasterthantwo": {
        "8_17": [
            5528
        ]
    },
    "GPUsand": {
        "8_17": [
            5529
        ]
    },
    "Recall": {
        "8_17": [
            5536
        ]
    },
    "hasalmostnoe": {
        "8_17": [
            5550
        ]
    },
    "ectontheBLEUcurve": {
        "8_17": [
            5551
        ]
    },
    "whenincreasingthee": {
        "8_17": [
            5553
        ]
    },
    "improvement": {
        "8_17": [
            5562
        ]
    },
    "nd": {
        "8_17": [
            5575,
            6103
        ]
    },
    "especially": {
        "8_17": [
            5579
        ]
    },
    "tuned": {
        "8_17": [
            5587
        ]
    },
    "fastest": {
        "8_17": [
            5606
        ]
    },
    "experi": {
        "8_17": [
            5617
        ]
    },
    "ments": {
        "8_17": [
            5618
        ]
    },
    "example": {
        "8_17": [
            5633,
            6324,
            6916
        ]
    },
    "superiorIt": {
        "8_17": [
            5660
        ]
    },
    "interesting": {
        "8_17": [
            5663
        ]
    },
    "simulating": {
        "8_17": [
            5666
        ]
    },
    "doing": {
        "8_17": [
            5676
        ]
    },
    "updateonceafterNbatches": {
        "8_17": [
            5678
        ]
    },
    "andsummingthegradients": {
        "8_17": [
            5679
        ]
    },
    "Thisissimilartothe": {
        "8_17": [
            5680
        ]
    },
    "ghostbatches": {
        "8_17": [
            5681
        ]
    },
    "ofHo": {
        "8_17": [
            5682
        ]
    },
    "eretal": {
        "8_17": [
            5683,
            5912,
            6042,
            6533
        ]
    },
    "ghost": {
        "8_17": [
            5686,
            6408
        ]
    },
    "Multiple": {
        "8_17": [
            5707,
            6726
        ]
    },
    "Related": {
        "8_17": [
            5709
        ]
    },
    "Work": {
        "8_17": [
            5710
        ]
    },
    "Thereisagrowingnumberofpapersonscalingdeeplearningtomultiplemachines": {
        "8_17": [
            5711
        ]
    },
    "withsynchronousSGD": {
        "8_17": [
            5712
        ]
    },
    "oritsvariants": {
        "8_17": [
            5713
        ]
    },
    "byincreasingthee": {
        "8_17": [
            5714
        ]
    },
    "ectivebatchsize": {
        "8_17": [
            5715,
            6920
        ]
    },
    "Wewill": {
        "8_17": [
            5716
        ]
    },
    "focus": {
        "8_17": [
            5717
        ]
    },
    "adapt": {
        "8_17": [
            5724
        ]
    },
    "device": {
        "8_17": [
            5736
        ]
    },
    "kGPUs": {
        "8_17": [
            5740
        ]
    },
    "Krizhevsky": {
        "8_17": [
            5741,
            8031
        ]
    },
    "says": {
        "8_17": [
            5742
        ]
    },
    "Theory": {
        "8_17": [
            5743
        ]
    },
    "multiplying": {
        "8_17": [
            5747,
            5784
        ]
    },
    "byv": {
        "8_17": [
            5759,
            6481
        ]
    },
    "kto": {
        "8_17": [
            5760
        ]
    },
    "expectation": {
        "8_17": [
            5767
        ]
    },
    "explaining": {
        "8_17": [
            5771
        ]
    },
    "theory": {
        "8_17": [
            5773
        ]
    },
    "experimentalparthereportsthatwhatworkedthebest": {
        "8_17": [
            5779
        ]
    },
    "wasa": {
        "8_17": [
            5780
        ]
    },
    "linearscalingheuristics": {
        "8_17": [
            5781
        ]
    },
    "nor": {
        "8_17": [
            5794
        ]
    },
    "betweenv": {
        "8_17": [
            5800
        ]
    },
    "kscaling": {
        "8_17": [
            5801,
            5803,
            6046
        ]
    },
    "linear": {
        "8_17": [
            5805,
            5957,
            5968
        ]
    },
    "heuristics": {
        "8_17": [
            5807
        ]
    },
    "become": {
        "8_17": [
            5808
        ]
    },
    "popular": {
        "8_17": [
            5809,
            6326
        ]
    },
    "leading": {
        "8_17": [
            5810
        ]
    },
    "Goyaletal": {
        "8_17": [
            5817,
            6332
        ]
    },
    "Smithetal": {
        "8_17": [
            5818
        ]
    },
    "andalsotheoreticalexplanations": {
        "8_17": [
            5819
        ]
    },
    "etal": {
        "8_17": [
            5821,
            6918
        ]
    },
    "SmithandLe": {
        "8_17": [
            5822,
            5824
        ]
    },
    "Jastrzebskietal": {
        "8_17": [
            5823
        ]
    },
    "interpret": {
        "8_17": [
            5825
        ]
    },
    "SGD": {
        "8_17": [
            5826,
            5857,
            6089,
            7988,
            8364
        ]
    },
    "anditsvariants": {
        "8_17": [
            5827
        ]
    },
    "asastochasticdi": {
        "8_17": [
            5828
        ]
    },
    "erentialequationandshowthatthe": {
        "8_17": [
            5829
        ]
    },
    "equalx": {
        "8_17": [
            5834
        ]
    },
    "B": {
        "8_17": [
            5836,
            5945,
            5952,
            7093
        ]
    },
    "Nis": {
        "8_17": [
            5842
        ]
    },
    "Bis": {
        "8_17": [
            5848
        ]
    },
    "drives": {
        "8_17": [
            5856
        ]
    },
    "away": {
        "8_17": [
            5858
        ]
    },
    "minima": {
        "8_17": [
            5861,
            5891
        ]
    },
    "therefore": {
        "8_17": [
            5863
        ]
    },
    "optimal": {
        "8_17": [
            5867,
            5882,
            6107,
            6734
        ]
    },
    "maximizes": {
        "8_17": [
            5871
        ]
    },
    "accuracy": {
        "8_17": [
            5875
        ]
    },
    "generalize": {
        "8_17": [
            5893,
            7889,
            7939
        ]
    },
    "Ho": {
        "8_17": [
            5911,
            6041,
            6806,
            7879
        ]
    },
    "suggesttousev": {
        "8_17": [
            5913
        ]
    },
    "kscalinginsteadofthelinearscaling": {
        "8_17": [
            5914
        ]
    },
    "theoretical": {
        "8_17": [
            5918
        ]
    },
    "empirical": {
        "8_17": [
            5920
        ]
    },
    "support": {
        "8_17": [
            5921
        ]
    },
    "claim": {
        "8_17": [
            5924
        ]
    },
    "They": {
        "8_17": [
            5925
        ]
    },
    "cov": {
        "8_17": [
            5928
        ]
    },
    "w": {
        "8_17": [
            5929,
            5930
        ]
    },
    "NB": {
        "8_17": [
            5931
        ]
    },
    "thusifwewanttokeepthethecovariancematrixoftheparameters": {
        "8_17": [
            5932
        ]
    },
    "win": {
        "8_17": [
            5935
        ]
    },
    "learningrateproportionallytothesquarerootof": {
        "8_17": [
            5951
        ]
    },
    "Theyfoundthatv": {
        "8_17": [
            5953
        ]
    },
    "kscalingworks": {
        "8_17": [
            5954
        ]
    },
    "CIFAR": {
        "8_17": [
            5960
        ]
    },
    "You": {
        "8_17": [
            5963,
            8356
        ]
    },
    "perform": {
        "8_17": [
            5972
        ]
    },
    "ImageNet": {
        "8_17": [
            5975,
            6086,
            7870,
            8370
        ]
    },
    "suggest": {
        "8_17": [
            5977,
            6615
        ]
    },
    "Layer": {
        "8_17": [
            5980,
            8080
        ]
    },
    "wise": {
        "8_17": [
            5981
        ]
    },
    "Adaptive": {
        "8_17": [
            5982,
            8171
        ]
    },
    "Wecanseethatlarge": {
        "8_17": [
            5985
        ]
    },
    "batchtrainingisstillanopenresearchquestion": {
        "8_17": [
            5986
        ]
    },
    "Mostofthe": {
        "8_17": [
            5987
        ]
    },
    "paperscitedabovehaveexperimentalsupportonlyfromtheimagerecognitiontasks": {
        "8_17": [
            5988
        ]
    },
    "usuallyImageNet": {
        "8_17": [
            5989
        ]
    },
    "andconvolutionalnetworks": {
        "8_17": [
            5990
        ]
    },
    "ResNet": {
        "8_17": [
            5993
        ]
    },
    "soitisnotclearwhether": {
        "8_17": [
            5994
        ]
    },
    "suggestions": {
        "8_17": [
            5996
        ]
    },
    "tasks": {
        "8_17": [
            6005
        ]
    },
    "self": {
        "8_17": [
            6008
        ]
    },
    "attentional": {
        "8_17": [
            6009
        ]
    },
    "networks": {
        "8_17": [
            6010,
            7901,
            7951,
            8040
        ]
    },
    "There": {
        "8_17": [
            6012
        ]
    },
    "Modernconvolutionalnetworksareusuallytrainedwith": {
        "8_17": [
            6020
        ]
    },
    "batchnormalization": {
        "8_17": [
            6021
        ]
    },
    "Io": {
        "8_17": [
            6022,
            7953
        ]
    },
    "eand": {
        "8_17": [
            6023
        ]
    },
    "Szegedy": {
        "8_17": [
            6024
        ]
    },
    "seems": {
        "8_17": [
            6026,
            7156
        ]
    },
    "Toclosethegapbetweensmall": {
        "8_17": [
            6038
        ]
    },
    "batchtrainingandlarge": {
        "8_17": [
            6039
        ]
    },
    "batchtraining": {
        "8_17": [
            6040
        ]
    },
    "additiontov": {
        "8_17": [
            6045
        ]
    },
    "ghostbatchnormalization": {
        "8_17": [
            6049
        ]
    },
    "andadaptedtrainingregime": {
        "8_17": [
            6050
        ]
    },
    "whichmeansdecaying": {
        "8_17": [
            6051
        ]
    },
    "layer": {
        "8_17": [
            6064
        ]
    },
    "normalization": {
        "8_17": [
            6065,
            6384,
            6405,
            6410
        ]
    },
    "Lei": {
        "8_17": [
            6066,
            8070
        ]
    },
    "Ba": {
        "8_17": [
            6067,
            8071
        ]
    },
    "superiorAlso": {
        "8_17": [
            6071
        ]
    },
    "together": {
        "8_17": [
            6075
        ]
    },
    "inverse": {
        "8_17": [
            6078,
            6422
        ]
    },
    "square": {
        "8_17": [
            6079,
            6379,
            6420
        ]
    },
    "momentum": {
        "8_17": [
            6091
        ]
    },
    "piecewise": {
        "8_17": [
            6093,
            6426
        ]
    },
    "decided": {
        "8_17": [
            6101
        ]
    },
    "Increasing": {
        "8_17": [
            6114
        ]
    },
    "dropped": {
        "8_17": [
            6125
        ]
    },
    "warmupstepsorbyintroducinggradientclipping": {
        "8_17": [
            6149
        ]
    },
    "clip_grad_norm": {
        "8_17": [
            6153
        ]
    },
    "led": {
        "8_17": [
            6166,
            6175
        ]
    },
    "anyway": {
        "8_17": [
            6169
        ]
    },
    "improvements": {
        "8_17": [
            6178,
            7051
        ]
    },
    "invariance": {
        "8_17": [
            6202
        ]
    },
    "under": {
        "8_17": [
            6203
        ]
    },
    "simultaneous": {
        "8_17": [
            6204
        ]
    },
    "rescaling": {
        "8_17": [
            6205
        ]
    },
    "breaks": {
        "8_17": [
            6212
        ]
    },
    "gets": {
        "8_17": [
            6218,
            6225
        ]
    },
    "initial": {
        "8_17": [
            6241
        ]
    },
    "maximal": {
        "8_17": [
            6248,
            6594
        ]
    },
    "stable": {
        "8_17": [
            6253
        ]
    },
    "GPUto": {
        "8_17": [
            6265
        ]
    },
    "Consideringthisinitialhypothesis": {
        "8_17": [
            6267
        ]
    },
    "weweresurprisedthatwewereabletoachieveso": {
        "8_17": [
            6268
        ]
    },
    "goodTimeTillScorewithGPUs": {
        "8_17": [
            6269
        ]
    },
    "morethantimessmallerrelativetoasingleGPU": {
        "8_17": [
            6270
        ]
    },
    "answer": {
        "8_17": [
            6276
        ]
    },
    "riddle": {
        "8_17": [
            6278,
            6506
        ]
    },
    "understand": {
        "8_17": [
            6282
        ]
    },
    "schedules": {
        "8_17": [
            6286,
            6304,
            6849
        ]
    },
    "Parametrization": {
        "8_17": [
            6291
        ]
    },
    "Schedules": {
        "8_17": [
            6295
        ]
    },
    "works": {
        "8_17": [
            6300
        ]
    },
    "superiorthe": {
        "8_17": [
            6308
        ]
    },
    "inter": {
        "8_17": [
            6313
        ]
    },
    "preted": {
        "8_17": [
            6314
        ]
    },
    "setup": {
        "8_17": [
            6327,
            7519
        ]
    },
    "forpiecewise": {
        "8_17": [
            6328
        ]
    },
    "constantdecayinImageNettraining": {
        "8_17": [
            6329
        ]
    },
    "istodivide": {
        "8_17": [
            6333
        ]
    },
    "factor": {
        "8_17": [
            6339
        ]
    },
    "th": {
        "8_17": [
            6343,
            6344,
            6346,
            7708
        ]
    },
    "inTT": {
        "8_17": [
            6349
        ]
    },
    "itisthe": {
        "8_17": [
            6350
        ]
    },
    "variablethatisusedasthetimeparameter": {
        "8_17": [
            6352
        ]
    },
    "singleGPU": {
        "8_17": [
            6370
        ]
    },
    "theactuallearningrate": {
        "8_17": [
            6371
        ]
    },
    "superiorachievesagivenvalueafterthesamenumberof": {
        "8_17": [
            6375
        ]
    },
    "butthismeansaftertimeslesstrainingexamples": {
        "8_17": [
            6377
        ]
    },
    "Fortheinverse": {
        "8_17": [
            6378
        ]
    },
    "superiorApplying": {
        "8_17": [
            6382
        ]
    },
    "RNN": {
        "8_17": [
            6386,
            6394
        ]
    },
    "successful": {
        "8_17": [
            6400
        ]
    },
    "switching": {
        "8_17": [
            6402,
            6939
        ]
    },
    "possibly": {
        "8_17": [
            6407
        ]
    },
    "due": {
        "8_17": [
            6411,
            7052
        ]
    },
    "superiorExamplesoflearningrateschedulesareinverse": {
        "8_17": [
            6419
        ]
    },
    "rootdecay": {
        "8_17": [
            6421
        ]
    },
    "timedecay": {
        "8_17": [
            6423
        ]
    },
    "exponentialde": {
        "8_17": [
            6424
        ]
    },
    "cay": {
        "8_17": [
            6425
        ]
    },
    "api_guides": {
        "8_17": [
            6434
        ]
    },
    "python": {
        "8_17": [
            6435
        ]
    },
    "Decaying_the_": {
        "8_17": [
            6437
        ]
    },
    "TF": {
        "8_17": [
            6440
        ]
    },
    "implementations": {
        "8_17": [
            6441
        ]
    },
    "superiorByactuallearningratewemeanthelearningrateafterapplyingthedecayschedule": {
        "8_17": [
            6445
        ]
    },
    "actual_lr": {
        "8_17": [
            6458,
            6462
        ]
    },
    "equalxcsteps": {
        "8_17": [
            6460
        ]
    },
    "equalxv": {
        "8_17": [
            6461
        ]
    },
    "cis": {
        "8_17": [
            6465
        ]
    },
    "thelearning_rate": {
        "8_17": [
            6479
        ]
    },
    "explains": {
        "8_17": [
            6504
        ]
    },
    "previous": {
        "8_17": [
            6509
        ]
    },
    "ktimes": {
        "8_17": [
            6521,
            6531,
            6587
        ]
    },
    "actuallearningratev": {
        "8_17": [
            6530
        ]
    },
    "inaccordancewiththesuggestionofHo": {
        "8_17": [
            6532
        ]
    },
    "ignoring": {
        "8_17": [
            6548
        ]
    },
    "bev": {
        "8_17": [
            6586
        ]
    },
    "deed": {
        "8_17": [
            6607
        ]
    },
    "Goyal": {
        "8_17": [
            6612,
            7856
        ]
    },
    "sense": {
        "8_17": [
            6647
        ]
    },
    "afterwards": {
        "8_17": [
            6698
        ]
    },
    "Further": {
        "8_17": [
            6699
        ]
    },
    "retarded": {
        "8_17": [
            6707
        ]
    },
    "Keep": {
        "8_17": [
            6728
        ]
    },
    "found": {
        "8_17": [
            6736
        ]
    },
    "Youcantrydecreasingthewarmupsteps": {
        "8_17": [
            6741
        ]
    },
    "butlessthanlinearlyandyoushould": {
        "8_17": [
            6742
        ]
    },
    "Resumed": {
        "8_17": [
            6752,
            6894
        ]
    },
    "TTallowstoresumetrainingfromacheckpoint": {
        "8_17": [
            6754
        ]
    },
    "simplybypointingthe": {
        "8_17": [
            6755
        ]
    },
    "output_dir": {
        "8_17": [
            6756
        ]
    },
    "parametertoadirectorywithanexistingcheckpoint": {
        "8_17": [
            6757
        ]
    },
    "edinthe": {
        "8_17": [
            6759
        ]
    },
    "Thismaybeusefulwhenthetrainingfails": {
        "8_17": [
            6762
        ]
    },
    "becauseofhardwareerror": {
        "8_17": [
            6765
        ]
    },
    "whenwe": {
        "8_17": [
            6766
        ]
    },
    "continue": {
        "8_17": [
            6769,
            6785
        ]
    },
    "search": {
        "8_17": [
            6780
        ]
    },
    "promising": {
        "8_17": [
            6789
        ]
    },
    "setups": {
        "8_17": [
            6790,
            7047
        ]
    },
    "saves": {
        "8_17": [
            6792
        ]
    },
    "superiorIn": {
        "8_17": [
            6798
        ]
    },
    "suggesting": {
        "8_17": [
            6801
        ]
    },
    "thev": {
        "8_17": [
            6802
        ]
    },
    "klearning": {
        "8_17": [
            6803
        ]
    },
    "close": {
        "8_17": [
            6814
        ]
    },
    "generalization": {
        "8_17": [
            6816,
            7893,
            7943
        ]
    },
    "absolute": {
        "8_17": [
            6825
        ]
    },
    "matters": {
        "8_17": [
            6830
        ]
    },
    "view": {
        "8_17": [
            6836
        ]
    },
    "wrong": {
        "8_17": [
            6855
        ]
    },
    "idea": {
        "8_17": [
            6856
        ]
    },
    "momentumintothecheckpoint": {
        "8_17": [
            6877
        ]
    },
    "sothetrainingcontinuesalmostasifithadnotbeen": {
        "8_17": [
            6878
        ]
    },
    "stopped": {
        "8_17": [
            6879
        ]
    },
    "itdoesnotstorethepositioninthetrainingdataitstartsfroma": {
        "8_17": [
            6881
        ]
    },
    "randomposition": {
        "8_17": [
            6882
        ]
    },
    "Alsotherelativetime": {
        "8_17": [
            6883
        ]
    },
    "andwall": {
        "8_17": [
            6884
        ]
    },
    "clocktime": {
        "8_17": [
            6885
        ]
    },
    "inTensorBoardgraphs": {
        "8_17": [
            6886
        ]
    },
    "exploited": {
        "8_17": [
            6899,
            7212
        ]
    },
    "changing": {
        "8_17": [
            6901
        ]
    },
    "meta": {
        "8_17": [
            6908
        ]
    },
    "parametrized": {
        "8_17": [
            6909
        ]
    },
    "suggesttoincreasethee": {
        "8_17": [
            6919
        ]
    },
    "andnumberofGPUs": {
        "8_17": [
            6921
        ]
    },
    "decaying": {
        "8_17": [
            6926
        ]
    },
    "Yet": {
        "8_17": [
            6930
        ]
    },
    "domain": {
        "8_17": [
            6936,
            6943,
            6949
        ]
    },
    "adaptation": {
        "8_17": [
            6937
        ]
    },
    "Inthiscase": {
        "8_17": [
            6957
        ]
    },
    "considereditingalsothelearningrateorlearningrateschedule": {
        "8_17": [
            6958
        ]
    },
    "orfaking": {
        "8_17": [
            6959
        ]
    },
    "theglobal_step": {
        "8_17": [
            6960
        ]
    },
    "stored": {
        "8_17": [
            6961
        ]
    },
    "Checkpoint": {
        "8_17": [
            6975,
            7265
        ]
    },
    "Averaging": {
        "8_17": [
            6976,
            7266,
            7269
        ]
    },
    "suggesttoaveragethelastcheckpointssavedin": {
        "8_17": [
            6978
        ]
    },
    "minute": {
        "8_17": [
            6979
        ]
    },
    "intervals": {
        "8_17": [
            6980
        ]
    },
    "utils": {
        "8_17": [
            6982
        ]
    },
    "avg_checkpoints": {
        "8_17": [
            6983
        ]
    },
    "py": {
        "8_17": [
            6984
        ]
    },
    "betterresultsareachievedwithaveragingcheckpointssavedin": {
        "8_17": [
            6990
        ]
    },
    "hourintervals": {
        "8_17": [
            6991
        ]
    },
    "spent": {
        "8_17": [
            7001
        ]
    },
    "twofold": {
        "8_17": [
            7018
        ]
    },
    "averaged": {
        "8_17": [
            7020,
            7246
        ]
    },
    "phases": {
        "8_17": [
            7060,
            7146
        ]
    },
    "fast": {
        "8_17": [
            7069
        ]
    },
    "fewer": {
        "8_17": [
            7075
        ]
    },
    "Manual": {
        "8_17": [
            7076,
            7109
        ]
    },
    "Automatic": {
        "8_17": [
            7077,
            7118
        ]
    },
    "Scores": {
        "8_17": [
            7078
        ]
    },
    "Ave": {
        "8_17": [
            7079,
            7080
        ]
    },
    "z": {
        "8_17": [
            7081
        ]
    },
    "TER": {
        "8_17": [
            7083,
            7128,
            7376
        ]
    },
    "CharacTER": {
        "8_17": [
            7084,
            7377
        ]
    },
    "BEER": {
        "8_17": [
            7085,
            7379
        ]
    },
    "System": {
        "8_17": [
            7086
        ]
    },
    "uedin": {
        "8_17": [
            7090
        ]
    },
    "nmt": {
        "8_17": [
            7091
        ]
    },
    "online": {
        "8_17": [
            7092,
            7102
        ]
    },
    "limsi": {
        "8_17": [
            7094
        ]
    },
    "factored": {
        "8_17": [
            7095
        ]
    },
    "LIUM": {
        "8_17": [
            7096,
            7098
        ]
    },
    "FNMT": {
        "8_17": [
            7097
        ]
    },
    "CU": {
        "8_17": [
            7100,
            7357
        ]
    },
    "Chimera": {
        "8_17": [
            7101,
            7358
        ]
    },
    "PJATK": {
        "8_17": [
            7104
        ]
    },
    "WMTsystemsforEnglish": {
        "8_17": [
            7106
        ]
    },
    "CzechandourbestTTtrainingrun": {
        "8_17": [
            7108
        ]
    },
    "cial": {
        "8_17": [
            7115,
            7718
        ]
    },
    "ranking": {
        "8_17": [
            7117
        ]
    },
    "metrics": {
        "8_17": [
            7119,
            7129,
            7340,
            7552
        ]
    },
    "provided": {
        "8_17": [
            7121
        ]
    },
    "matrix": {
        "8_17": [
            7124
        ]
    },
    "Best": {
        "8_17": [
            7133
        ]
    },
    "bold": {
        "8_17": [
            7136
        ]
    },
    "italics": {
        "8_17": [
            7140
        ]
    },
    "covering": {
        "8_17": [
            7159
        ]
    },
    "give": {
        "8_17": [
            7162
        ]
    },
    "proper": {
        "8_17": [
            7176
        ]
    },
    "signi": {
        "8_17": [
            7179
        ]
    },
    "cance": {
        "8_17": [
            7180
        ]
    },
    "paired": {
        "8_17": [
            7182
        ]
    },
    "bootstrap": {
        "8_17": [
            7183
        ]
    },
    "testing": {
        "8_17": [
            7184
        ]
    },
    "then": {
        "8_17": [
            7189
        ]
    },
    "resumed": {
        "8_17": [
            7196
        ]
    },
    "starts": {
        "8_17": [
            7198
        ]
    },
    "position": {
        "8_17": [
            7202
        ]
    },
    "forking": {
        "8_17": [
            7214
        ]
    },
    "copies": {
        "8_17": [
            7222
        ]
    },
    "independentlyinthelaterstagesandthusendingwithdi": {
        "8_17": [
            7236
        ]
    },
    "erentweightssavedinthe": {
        "8_17": [
            7237
        ]
    },
    "semi": {
        "8_17": [
            7241
        ]
    },
    "independent": {
        "8_17": [
            7242
        ]
    },
    "ascheckpointsfromthesamerun": {
        "8_17": [
            7251
        ]
    },
    "asdescribedabove": {
        "8_17": [
            7252
        ]
    },
    "Ourpreliminaryresultsshow": {
        "8_17": [
            7253
        ]
    },
    "helps": {
        "8_17": [
            7255
        ]
    },
    "top": {
        "8_17": [
            7259
        ]
    },
    "Use": {
        "8_17": [
            7267
        ]
    },
    "boost": {
        "8_17": [
            7279
        ]
    },
    "free": {
        "8_17": [
            7281
        ]
    },
    "whole": {
        "8_17": [
            7289
        ]
    },
    "See": {
        "8_17": [
            7291
        ]
    },
    "tools": {
        "8_17": [
            7293
        ]
    },
    "described": {
        "8_17": [
            7300
        ]
    },
    "Comparison": {
        "8_17": [
            7303
        ]
    },
    "Systems": {
        "8_17": [
            7306,
            7926,
            8285
        ]
    },
    "task": {
        "8_17": [
            7318
        ]
    },
    "despite": {
        "8_17": [
            7359,
            7380
        ]
    },
    "manual": {
        "8_17": [
            7362
        ]
    },
    "rank": {
        "8_17": [
            7363
        ]
    },
    "outperforms": {
        "8_17": [
            7370
        ]
    },
    "system": {
        "8_17": [
            7373
        ]
    },
    "back": {
        "8_17": [
            7386
        ]
    },
    "reranking": {
        "8_17": [
            7389,
            7398
        ]
    },
    "left": {
        "8_17": [
            7397
        ]
    },
    "norensembling": {
        "8_17": [
            7399
        ]
    },
    "asisthecaseofuedin": {
        "8_17": [
            7400
        ]
    },
    "nmtandothersystems": {
        "8_17": [
            7401
        ]
    },
    "Notethat": {
        "8_17": [
            7402
        ]
    },
    "constrained": {
        "8_17": [
            7410
        ]
    },
    "comparable": {
        "8_17": [
            7419
        ]
    },
    "Conclusion": {
        "8_17": [
            7420
        ]
    },
    "presented": {
        "8_17": [
            7422
        ]
    },
    "broad": {
        "8_17": [
            7424
        ]
    },
    "basic": {
        "8_17": [
            7427,
            7453
        ]
    },
    "Vaswani": {
        "8_17": [
            7433,
            8247
        ]
    },
    "exploration": {
        "8_17": [
            7447
        ]
    },
    "settings": {
        "8_17": [
            7455
        ]
    },
    "believe": {
        "8_17": [
            7457
        ]
    },
    "sum": {
        "8_17": [
            7467
        ]
    },
    "took": {
        "8_17": [
            7473
        ]
    },
    "years": {
        "8_17": [
            7475
        ]
    },
    "Among": {
        "8_17": [
            7479
        ]
    },
    "weve": {
        "8_17": [
            7483
        ]
    },
    "lead": {
        "8_17": [
            7493
        ]
    },
    "importantly": {
        "8_17": [
            7501
        ]
    },
    "Given": {
        "8_17": [
            7506
        ]
    },
    "shouldbealwayspreferred": {
        "8_17": [
            7521
        ]
    },
    "TheTransformermodelanditsimplementationin": {
        "8_17": [
            7522
        ]
    },
    "intense": {
        "8_17": [
            7529
        ]
    },
    "andrunningexperimentsoneafteranothershouldbepreferredoverrunningseveral": {
        "8_17": [
            7537
        ]
    },
    "concurrently": {
        "8_17": [
            7541
        ]
    },
    "ThebestperformingmodelweobtainedonGPUstrainedfordayshasoutper": {
        "8_17": [
            7542
        ]
    },
    "formed": {
        "8_17": [
            7543
        ]
    },
    "winner": {
        "8_17": [
            7546
        ]
    },
    "Acknowledgements": {
        "8_17": [
            7553
        ]
    },
    "research": {
        "8_17": [
            7555
        ]
    },
    "grants": {
        "8_17": [
            7560
        ]
    },
    "S": {
        "8_17": [
            7561,
            7908,
            7914,
            8268,
            8274
        ]
    },
    "Science": {
        "8_17": [
            7565
        ]
    },
    "Foun": {
        "8_17": [
            7566
        ]
    },
    "dation": {
        "8_17": [
            7567
        ]
    },
    "H": {
        "8_17": [
            7568,
            7910,
            8270
        ]
    },
    "ICT": {
        "8_17": [
            7569
        ]
    },
    "oftheEU": {
        "8_17": [
            7571
        ]
    },
    "SVV": {
        "8_17": [
            7572
        ]
    },
    "andusinglanguage": {
        "8_17": [
            7573
        ]
    },
    "LINDAT": {
        "8_17": [
            7578
        ]
    },
    "CLARIN": {
        "8_17": [
            7579
        ]
    },
    "Ministry": {
        "8_17": [
            7583
        ]
    },
    "Education": {
        "8_17": [
            7585
        ]
    },
    "Youth": {
        "8_17": [
            7586
        ]
    },
    "Sports": {
        "8_17": [
            7588
        ]
    },
    "Republic": {
        "8_17": [
            7592,
            8406
        ]
    },
    "LM": {
        "8_17": [
            7593
        ]
    },
    "Bibliography": {
        "8_17": [
            7594
        ]
    },
    "Dzmitry": {
        "8_17": [
            7596
        ]
    },
    "Kyunghyun": {
        "8_17": [
            7597,
            8050
        ]
    },
    "Cho": {
        "8_17": [
            7598,
            8051
        ]
    },
    "Yoshua": {
        "8_17": [
            7600,
            7976
        ]
    },
    "Bengio": {
        "8_17": [
            7601,
            7909,
            7977,
            8269
        ]
    },
    "Neural": {
        "8_17": [
            7602,
            7923,
            8058,
            8140,
            8282
        ]
    },
    "Jointly": {
        "8_17": [
            7606
        ]
    },
    "Align": {
        "8_17": [
            7609
        ]
    },
    "Translate": {
        "8_17": [
            7611
        ]
    },
    "Proceedings": {
        "8_17": [
            7613,
            7645,
            7769,
            8023,
            8107,
            8150,
            8204
        ]
    },
    "ICLR": {
        "8_17": [
            7615,
            8025
        ]
    },
    "Zdenek": {
        "8_17": [
            7618
        ]
    },
    "abokrtsk": {
        "8_17": [
            7619
        ]
    },
    "Duek": {
        "8_17": [
            7621,
            7669
        ]
    },
    "Petra": {
        "8_17": [
            7622
        ]
    },
    "Galuckov": {
        "8_17": [
            7623
        ]
    },
    "Majli": {
        "8_17": [
            7625
        ]
    },
    "David": {
        "8_17": [
            7626
        ]
    },
    "Marecek": {
        "8_17": [
            7627
        ]
    },
    "Jir": {
        "8_17": [
            7628
        ]
    },
    "Mark": {
        "8_17": [
            7629
        ]
    },
    "Michal": {
        "8_17": [
            7630,
            7674
        ]
    },
    "Novk": {
        "8_17": [
            7631,
            7675
        ]
    },
    "Ale": {
        "8_17": [
            7635,
            7696
        ]
    },
    "Tamchyna": {
        "8_17": [
            7636
        ]
    },
    "Joy": {
        "8_17": [
            7638
        ]
    },
    "Par": {
        "8_17": [
            7640
        ]
    },
    "allelism": {
        "8_17": [
            7641
        ]
    },
    "Eighth": {
        "8_17": [
            7648
        ]
    },
    "International": {
        "8_17": [
            7649,
            7709,
            7724
        ]
    },
    "Language": {
        "8_17": [
            7650,
            7662
        ]
    },
    "Resources": {
        "8_17": [
            7651,
            7663
        ]
    },
    "EvaluationConference": {
        "8_17": [
            7653
        ]
    },
    "LREC": {
        "8_17": [
            7654
        ]
    },
    "pages": {
        "8_17": [
            7655,
            7720,
            7788,
            7853,
            7927,
            8110,
            8122,
            8153,
            8286
        ]
    },
    "Istanbul": {
        "8_17": [
            7656
        ]
    },
    "Turkey": {
        "8_17": [
            7657
        ]
    },
    "ELRA": {
        "8_17": [
            7659
        ]
    },
    "Euro": {
        "8_17": [
            7660
        ]
    },
    "pean": {
        "8_17": [
            7661
        ]
    },
    "Association": {
        "8_17": [
            7664
        ]
    },
    "ISBN": {
        "8_17": [
            7665,
            7726,
            7794
        ]
    },
    "Tom": {
        "8_17": [
            7670
        ]
    },
    "Kocmi": {
        "8_17": [
            7671
        ]
    },
    "Jindrich": {
        "8_17": [
            7672
        ]
    },
    "Libovick": {
        "8_17": [
            7673
        ]
    },
    "Roman": {
        "8_17": [
            7678
        ]
    },
    "Sudarikov": {
        "8_17": [
            7679
        ]
    },
    "Duan": {
        "8_17": [
            7681
        ]
    },
    "Vari": {
        "8_17": [
            7682
        ]
    },
    "Enlarged": {
        "8_17": [
            7684
        ]
    },
    "Parallel": {
        "8_17": [
            7687
        ]
    },
    "Corpus": {
        "8_17": [
            7688
        ]
    },
    "Processing": {
        "8_17": [
            7690,
            7925,
            8284
        ]
    },
    "Dockered": {
        "8_17": [
            7692
        ]
    },
    "Sojka": {
        "8_17": [
            7694
        ]
    },
    "Petr": {
        "8_17": [
            7695
        ]
    },
    "Hork": {
        "8_17": [
            7697
        ]
    },
    "Ivan": {
        "8_17": [
            7698
        ]
    },
    "Kopecek": {
        "8_17": [
            7699
        ]
    },
    "Karel": {
        "8_17": [
            7701
        ]
    },
    "Pala": {
        "8_17": [
            7702
        ]
    },
    "editors": {
        "8_17": [
            7703,
            7919,
            8279
        ]
    },
    "Text": {
        "8_17": [
            7704
        ]
    },
    "Speech": {
        "8_17": [
            7705
        ]
    },
    "Dialogue": {
        "8_17": [
            7707
        ]
    },
    "Conference": {
        "8_17": [
            7710,
            7773
        ]
    },
    "TSD": {
        "8_17": [
            7711
        ]
    },
    "Lecture": {
        "8_17": [
            7714
        ]
    },
    "Notes": {
        "8_17": [
            7715
        ]
    },
    "Arti": {
        "8_17": [
            7717
        ]
    },
    "Intelligence": {
        "8_17": [
            7719
        ]
    },
    "Masaryk": {
        "8_17": [
            7721
        ]
    },
    "Springer": {
        "8_17": [
            7723,
            7789
        ]
    },
    "Publishing": {
        "8_17": [
            7725
        ]
    },
    "RajenChatterjee": {
        "8_17": [
            7729
        ]
    },
    "ChristianFedermann": {
        "8_17": [
            7730
        ]
    },
    "YvetteGraham": {
        "8_17": [
            7731
        ]
    },
    "BarryHaddow": {
        "8_17": [
            7732
        ]
    },
    "Matthias": {
        "8_17": [
            7733
        ]
    },
    "Huck": {
        "8_17": [
            7734
        ]
    },
    "PhilippKoehn": {
        "8_17": [
            7735
        ]
    },
    "VarvaraLogacheva": {
        "8_17": [
            7736
        ]
    },
    "ChristofMonz": {
        "8_17": [
            7737
        ]
    },
    "MatteoNegri": {
        "8_17": [
            7738
        ]
    },
    "MattPost": {
        "8_17": [
            7739
        ]
    },
    "Raphael": {
        "8_17": [
            7740
        ]
    },
    "Rubino": {
        "8_17": [
            7741
        ]
    },
    "LuciaSpecia": {
        "8_17": [
            7742
        ]
    },
    "andMarcoTurchi": {
        "8_17": [
            7743
        ]
    },
    "FindingsoftheConferenceonMachineTrans": {
        "8_17": [
            7744
        ]
    },
    "ProceedingsoftheSecondConferenceonMachineTranslation": {
        "8_17": [
            7748
        ]
    },
    "Copenhagen": {
        "8_17": [
            7749,
            7777
        ]
    },
    "Denmark": {
        "8_17": [
            7750,
            7778
        ]
    },
    "September": {
        "8_17": [
            7751,
            7779,
            8125
        ]
    },
    "ACL": {
        "8_17": [
            7753,
            7781,
            8109,
            8126,
            8152,
            8157
        ]
    },
    "Yvette": {
        "8_17": [
            7756
        ]
    },
    "Graham": {
        "8_17": [
            7757
        ]
    },
    "Amir": {
        "8_17": [
            7759
        ]
    },
    "Kamran": {
        "8_17": [
            7760
        ]
    },
    "Results": {
        "8_17": [
            7761
        ]
    },
    "Metrics": {
        "8_17": [
            7765
        ]
    },
    "Shared": {
        "8_17": [
            7766
        ]
    },
    "Task": {
        "8_17": [
            7767
        ]
    },
    "Second": {
        "8_17": [
            7772,
            8206
        ]
    },
    "Lon": {
        "8_17": [
            7783
        ]
    },
    "Stochastic": {
        "8_17": [
            7784,
            8200
        ]
    },
    "Gradient": {
        "8_17": [
            7785,
            8201
        ]
    },
    "Descent": {
        "8_17": [
            7786,
            8202
        ]
    },
    "Tricks": {
        "8_17": [
            7787
        ]
    },
    "Berlin": {
        "8_17": [
            7790,
            7792,
            8154
        ]
    },
    "Heidelberg": {
        "8_17": [
            7791,
            7793
        ]
    },
    "doi": {
        "8_17": [
            7795,
            7799
        ]
    },
    "_": {
        "8_17": [
            7796,
            7801
        ]
    },
    "URL": {
        "8_17": [
            7797,
            7822,
            7874,
            7931,
            7961,
            7991,
            8026,
            8043,
            8065,
            8127,
            8158,
            8182,
            8217,
            8242,
            8290,
            8351,
            8374
        ]
    },
    "L": {
        "8_17": [
            7803,
            8189,
            8224
        ]
    },
    "F": {
        "8_17": [
            7804
        ]
    },
    "Curtis": {
        "8_17": [
            7806
        ]
    },
    "J": {
        "8_17": [
            7808,
            7980,
            8072,
            8073
        ]
    },
    "Nocedal": {
        "8_17": [
            7809,
            8002
        ]
    },
    "Optimization": {
        "8_17": [
            7810
        ]
    },
    "Methods": {
        "8_17": [
            7811
        ]
    },
    "Large": {
        "8_17": [
            7813,
            8011
        ]
    },
    "Scale": {
        "8_17": [
            7814
        ]
    },
    "Learn": {
        "8_17": [
            7816
        ]
    },
    "ing": {
        "8_17": [
            7817
        ]
    },
    "ArXiv": {
        "8_17": [
            7818,
            8082,
            8178
        ]
    },
    "prints": {
        "8_17": [
            7820,
            8084,
            8180
        ]
    },
    "June": {
        "8_17": [
            7821
        ]
    },
    "arxiv": {
        "8_17": [
            7824,
            7876,
            7963,
            7993,
            8028,
            8045,
            8067,
            8184,
            8219,
            8244,
            8353,
            8376
        ]
    },
    "abs": {
        "8_17": [
            7826,
            7878,
            7960,
            7965,
            7990,
            7995,
            8030,
            8042,
            8047,
            8069,
            8186,
            8221,
            8246,
            8350,
            8355,
            8373,
            8378
        ]
    },
    "Cettolo": {
        "8_17": [
            7827
        ]
    },
    "Mauro": {
        "8_17": [
            7828
        ]
    },
    "Marcello": {
        "8_17": [
            7829
        ]
    },
    "Federico": {
        "8_17": [
            7830
        ]
    },
    "Luisa": {
        "8_17": [
            7831
        ]
    },
    "Bentivogli": {
        "8_17": [
            7832
        ]
    },
    "Jan": {
        "8_17": [
            7833,
            8226
        ]
    },
    "Niehues": {
        "8_17": [
            7834
        ]
    },
    "Sebastian": {
        "8_17": [
            7835
        ]
    },
    "Stker": {
        "8_17": [
            7836
        ]
    },
    "Katsuhito": {
        "8_17": [
            7837
        ]
    },
    "Sudoh": {
        "8_17": [
            7838
        ]
    },
    "Koichiro": {
        "8_17": [
            7839
        ]
    },
    "Yoshino": {
        "8_17": [
            7840
        ]
    },
    "Christian": {
        "8_17": [
            7842
        ]
    },
    "Federmann": {
        "8_17": [
            7843
        ]
    },
    "Overview": {
        "8_17": [
            7844
        ]
    },
    "IWSLT": {
        "8_17": [
            7847,
            7852
        ]
    },
    "Evalua": {
        "8_17": [
            7848
        ]
    },
    "tionCampaign": {
        "8_17": [
            7849
        ]
    },
    "ProceedingsofthethInternationalWorkshoponSpokenLanguageTranslation": {
        "8_17": [
            7851
        ]
    },
    "Tokyo": {
        "8_17": [
            7854
        ]
    },
    "Japan": {
        "8_17": [
            7855
        ]
    },
    "Priya": {
        "8_17": [
            7857
        ]
    },
    "PiotrDollr": {
        "8_17": [
            7858
        ]
    },
    "RossB": {
        "8_17": [
            7859
        ]
    },
    "Girshick": {
        "8_17": [
            7860
        ]
    },
    "PieterNoordhuis": {
        "8_17": [
            7861
        ]
    },
    "LukaszWesolowski": {
        "8_17": [
            7862
        ]
    },
    "AapoKyrola": {
        "8_17": [
            7863
        ]
    },
    "AndrewTulloch": {
        "8_17": [
            7864
        ]
    },
    "YangqingJia": {
        "8_17": [
            7865
        ]
    },
    "andKaimingHe": {
        "8_17": [
            7866
        ]
    },
    "Accurate": {
        "8_17": [
            7867
        ]
    },
    "LargeMinibatchSGD": {
        "8_17": [
            7868
        ]
    },
    "Hour": {
        "8_17": [
            7872
        ]
    },
    "CoRR": {
        "8_17": [
            7873,
            7959,
            7989,
            8041,
            8064,
            8241,
            8349,
            8372
        ]
    },
    "Elad": {
        "8_17": [
            7881
        ]
    },
    "Itay": {
        "8_17": [
            7882
        ]
    },
    "Hubara": {
        "8_17": [
            7883
        ]
    },
    "Daniel": {
        "8_17": [
            7885
        ]
    },
    "Soudry": {
        "8_17": [
            7886
        ]
    },
    "Train": {
        "8_17": [
            7887
        ]
    },
    "closing": {
        "8_17": [
            7891,
            7941
        ]
    },
    "Guyon": {
        "8_17": [
            7903
        ]
    },
    "I": {
        "8_17": [
            7904,
            8264
        ]
    },
    "U": {
        "8_17": [
            7905,
            8265
        ]
    },
    "V": {
        "8_17": [
            7906,
            8192,
            8230,
            8266,
            8309
        ]
    },
    "Luxburg": {
        "8_17": [
            7907,
            8267
        ]
    },
    "Wallach": {
        "8_17": [
            7911,
            8271
        ]
    },
    "R": {
        "8_17": [
            7912,
            7917,
            8074,
            8272,
            8277
        ]
    },
    "Fergus": {
        "8_17": [
            7913,
            8273
        ]
    },
    "Vishwanathan": {
        "8_17": [
            7915,
            8275
        ]
    },
    "Garnett": {
        "8_17": [
            7918,
            8278
        ]
    },
    "Ad": {
        "8_17": [
            7920
        ]
    },
    "vances": {
        "8_17": [
            7921
        ]
    },
    "Information": {
        "8_17": [
            7924,
            8283
        ]
    },
    "Curran": {
        "8_17": [
            7928,
            8287
        ]
    },
    "Associates": {
        "8_17": [
            7929,
            8288
        ]
    },
    "Inc": {
        "8_17": [
            7930,
            8289
        ]
    },
    "nips": {
        "8_17": [
            7934,
            8293
        ]
    },
    "cc": {
        "8_17": [
            7935,
            8294
        ]
    },
    "pdf": {
        "8_17": [
            7952,
            8301
        ]
    },
    "SergeyandChristianSzegedy": {
        "8_17": [
            7955
        ]
    },
    "BatchNormalization": {
        "8_17": [
            7956
        ]
    },
    "AcceleratingDeepNetworkTraining": {
        "8_17": [
            7957
        ]
    },
    "byReducingInternalCovariateShift": {
        "8_17": [
            7958
        ]
    },
    "Stanislaw": {
        "8_17": [
            7967
        ]
    },
    "Zachary": {
        "8_17": [
            7968
        ]
    },
    "Kenton": {
        "8_17": [
            7969
        ]
    },
    "Devansh": {
        "8_17": [
            7970
        ]
    },
    "Arpit": {
        "8_17": [
            7971
        ]
    },
    "Nicolas": {
        "8_17": [
            7972
        ]
    },
    "Ballas": {
        "8_17": [
            7973
        ]
    },
    "Asja": {
        "8_17": [
            7974
        ]
    },
    "Fischer": {
        "8_17": [
            7975
        ]
    },
    "Amos": {
        "8_17": [
            7979
        ]
    },
    "Storkey": {
        "8_17": [
            7981
        ]
    },
    "Three": {
        "8_17": [
            7982
        ]
    },
    "Factors": {
        "8_17": [
            7983
        ]
    },
    "uencing": {
        "8_17": [
            7985
        ]
    },
    "Minima": {
        "8_17": [
            7986,
            8021
        ]
    },
    "Nitish": {
        "8_17": [
            7997
        ]
    },
    "Shirish": {
        "8_17": [
            7998
        ]
    },
    "Dheevatsa": {
        "8_17": [
            7999
        ]
    },
    "Mudigere": {
        "8_17": [
            8000
        ]
    },
    "Jorge": {
        "8_17": [
            8001
        ]
    },
    "Mikhail": {
        "8_17": [
            8003
        ]
    },
    "Smelyanskiy": {
        "8_17": [
            8004
        ]
    },
    "Ping": {
        "8_17": [
            8006
        ]
    },
    "Tak": {
        "8_17": [
            8007
        ]
    },
    "Peter": {
        "8_17": [
            8008
        ]
    },
    "Tang": {
        "8_17": [
            8009
        ]
    },
    "Deep": {
        "8_17": [
            8015,
            8210
        ]
    },
    "Generalization": {
        "8_17": [
            8017,
            8198
        ]
    },
    "Gap": {
        "8_17": [
            8018
        ]
    },
    "Sharp": {
        "8_17": [
            8020
        ]
    },
    "Alex": {
        "8_17": [
            8032
        ]
    },
    "weird": {
        "8_17": [
            8034
        ]
    },
    "trick": {
        "8_17": [
            8035
        ]
    },
    "parallelizing": {
        "8_17": [
            8037
        ]
    },
    "convolutional": {
        "8_17": [
            8038
        ]
    },
    "Jason": {
        "8_17": [
            8049,
            8335
        ]
    },
    "Thomas": {
        "8_17": [
            8053
        ]
    },
    "Hofmann": {
        "8_17": [
            8054
        ]
    },
    "Fully": {
        "8_17": [
            8055
        ]
    },
    "Character": {
        "8_17": [
            8056
        ]
    },
    "Level": {
        "8_17": [
            8057
        ]
    },
    "Explicit": {
        "8_17": [
            8062
        ]
    },
    "Segmentation": {
        "8_17": [
            8063
        ]
    },
    "Kiros": {
        "8_17": [
            8075
        ]
    },
    "G": {
        "8_17": [
            8077
        ]
    },
    "Hinton": {
        "8_17": [
            8079
        ]
    },
    "Normalization": {
        "8_17": [
            8081
        ]
    },
    "July": {
        "8_17": [
            8085
        ]
    },
    "Papineni": {
        "8_17": [
            8086
        ]
    },
    "Kishore": {
        "8_17": [
            8087
        ]
    },
    "Salim": {
        "8_17": [
            8088
        ]
    },
    "Roukos": {
        "8_17": [
            8089
        ]
    },
    "Todd": {
        "8_17": [
            8090
        ]
    },
    "Ward": {
        "8_17": [
            8091
        ]
    },
    "Wei": {
        "8_17": [
            8093
        ]
    },
    "Jing": {
        "8_17": [
            8094
        ]
    },
    "Zhu": {
        "8_17": [
            8095
        ]
    },
    "Method": {
        "8_17": [
            8098
        ]
    },
    "Au": {
        "8_17": [
            8100
        ]
    },
    "tomatic": {
        "8_17": [
            8101
        ]
    },
    "Philadelphia": {
        "8_17": [
            8111
        ]
    },
    "Pennsylvania": {
        "8_17": [
            8112
        ]
    },
    "Maja": {
        "8_17": [
            8114
        ]
    },
    "chrF": {
        "8_17": [
            8115
        ]
    },
    "charactern": {
        "8_17": [
            8116
        ]
    },
    "gramF": {
        "8_17": [
            8117
        ]
    },
    "scoreforautomaticMTevaluation": {
        "8_17": [
            8118
        ]
    },
    "Proceedingsofthe": {
        "8_17": [
            8120
        ]
    },
    "TenthWorkshoponStatisticalMachineTranslation": {
        "8_17": [
            8121
        ]
    },
    "Lisbon": {
        "8_17": [
            8123
        ]
    },
    "Portugal": {
        "8_17": [
            8124
        ]
    },
    "aclweb": {
        "8_17": [
            8129,
            8161
        ]
    },
    "anthology": {
        "8_17": [
            8131,
            8163
        ]
    },
    "W": {
        "8_17": [
            8132
        ]
    },
    "Sennrich": {
        "8_17": [
            8133
        ]
    },
    "Rico": {
        "8_17": [
            8134
        ]
    },
    "Barry": {
        "8_17": [
            8135
        ]
    },
    "Haddow": {
        "8_17": [
            8136
        ]
    },
    "Alexandra": {
        "8_17": [
            8138
        ]
    },
    "Birch": {
        "8_17": [
            8139
        ]
    },
    "Rare": {
        "8_17": [
            8144
        ]
    },
    "Words": {
        "8_17": [
            8145
        ]
    },
    "Subword": {
        "8_17": [
            8147
        ]
    },
    "Units": {
        "8_17": [
            8148
        ]
    },
    "Germany": {
        "8_17": [
            8155
        ]
    },
    "August": {
        "8_17": [
            8156
        ]
    },
    "P": {
        "8_17": [
            8164
        ]
    },
    "Shazeer": {
        "8_17": [
            8165,
            8250
        ]
    },
    "Stern": {
        "8_17": [
            8169
        ]
    },
    "Rates": {
        "8_17": [
            8173
        ]
    },
    "Sublinear": {
        "8_17": [
            8175
        ]
    },
    "Memory": {
        "8_17": [
            8176
        ]
    },
    "Cost": {
        "8_17": [
            8177
        ]
    },
    "Apr": {
        "8_17": [
            8181
        ]
    },
    "Samuel": {
        "8_17": [
            8188,
            8223
        ]
    },
    "Quoc": {
        "8_17": [
            8191,
            8229,
            8308
        ]
    },
    "Bayesian": {
        "8_17": [
            8195,
            8209
        ]
    },
    "Perspective": {
        "8_17": [
            8196
        ]
    },
    "workshop": {
        "8_17": [
            8207
        ]
    },
    "NIPS": {
        "8_17": [
            8212
        ]
    },
    "Long": {
        "8_17": [
            8213
        ]
    },
    "Beach": {
        "8_17": [
            8214
        ]
    },
    "CA": {
        "8_17": [
            8215
        ]
    },
    "USA": {
        "8_17": [
            8216
        ]
    },
    "Pieter": {
        "8_17": [
            8225
        ]
    },
    "Kindermans": {
        "8_17": [
            8227
        ]
    },
    "Dont": {
        "8_17": [
            8232
        ]
    },
    "Decay": {
        "8_17": [
            8233
        ]
    },
    "Increase": {
        "8_17": [
            8237
        ]
    },
    "Ashish": {
        "8_17": [
            8248
        ]
    },
    "Noam": {
        "8_17": [
            8249
        ]
    },
    "Niki": {
        "8_17": [
            8251
        ]
    },
    "Parmar": {
        "8_17": [
            8252
        ]
    },
    "Jakob": {
        "8_17": [
            8253
        ]
    },
    "Uszkoreit": {
        "8_17": [
            8254
        ]
    },
    "Llion": {
        "8_17": [
            8255
        ]
    },
    "Jones": {
        "8_17": [
            8256
        ]
    },
    "Aidan": {
        "8_17": [
            8257
        ]
    },
    "Gomez": {
        "8_17": [
            8259
        ]
    },
    "LukaszKaiser": {
        "8_17": [
            8260,
            8324
        ]
    },
    "andIlliaPolosukhin": {
        "8_17": [
            8261
        ]
    },
    "AttentionisAllyouNeed": {
        "8_17": [
            8262
        ]
    },
    "InGuyon": {
        "8_17": [
            8263
        ]
    },
    "Advances": {
        "8_17": [
            8280
        ]
    },
    "attention": {
        "8_17": [
            8296
        ]
    },
    "Yonghui": {
        "8_17": [
            8303
        ]
    },
    "Mike": {
        "8_17": [
            8304
        ]
    },
    "Schuster": {
        "8_17": [
            8305
        ]
    },
    "Zhifeng": {
        "8_17": [
            8306
        ]
    },
    "Chen": {
        "8_17": [
            8307
        ]
    },
    "Mohammad": {
        "8_17": [
            8311
        ]
    },
    "Norouzi": {
        "8_17": [
            8312
        ]
    },
    "Wolfgang": {
        "8_17": [
            8313
        ]
    },
    "Macherey": {
        "8_17": [
            8314
        ]
    },
    "MaximKrikun": {
        "8_17": [
            8315
        ]
    },
    "YuanCao": {
        "8_17": [
            8316
        ]
    },
    "QinGao": {
        "8_17": [
            8317
        ]
    },
    "KlausMacherey": {
        "8_17": [
            8318
        ]
    },
    "Je": {
        "8_17": [
            8319
        ]
    },
    "Klingner": {
        "8_17": [
            8320
        ]
    },
    "ApurvaShah": {
        "8_17": [
            8321
        ]
    },
    "MelvinJohnson": {
        "8_17": [
            8322
        ]
    },
    "XiaobingLiu": {
        "8_17": [
            8323
        ]
    },
    "StephanGouws": {
        "8_17": [
            8325
        ]
    },
    "YoshikiyoKato": {
        "8_17": [
            8326
        ]
    },
    "TakuKudo": {
        "8_17": [
            8327
        ]
    },
    "HidetoKazawa": {
        "8_17": [
            8328
        ]
    },
    "KeithStevens": {
        "8_17": [
            8329
        ]
    },
    "GeorgeKurian": {
        "8_17": [
            8330
        ]
    },
    "NishantPatil": {
        "8_17": [
            8331
        ]
    },
    "WeiWang": {
        "8_17": [
            8332
        ]
    },
    "Cli": {
        "8_17": [
            8333
        ]
    },
    "Young": {
        "8_17": [
            8334
        ]
    },
    "JasonRiesa": {
        "8_17": [
            8337
        ]
    },
    "AlexRudnick": {
        "8_17": [
            8338
        ]
    },
    "OriolVinyals": {
        "8_17": [
            8339
        ]
    },
    "GregCorrado": {
        "8_17": [
            8340
        ]
    },
    "Macdu": {
        "8_17": [
            8341
        ]
    },
    "Hughes": {
        "8_17": [
            8342
        ]
    },
    "andJe": {
        "8_17": [
            8343
        ]
    },
    "rey": {
        "8_17": [
            8344
        ]
    },
    "Dean": {
        "8_17": [
            8345
        ]
    },
    "GooglesNeuralMachineTranslationSystem": {
        "8_17": [
            8346
        ]
    },
    "BridgingtheGapbetweenHumanand": {
        "8_17": [
            8347
        ]
    },
    "MachineTranslation": {
        "8_17": [
            8348
        ]
    },
    "Yang": {
        "8_17": [
            8357
        ]
    },
    "Igor": {
        "8_17": [
            8358
        ]
    },
    "Gitman": {
        "8_17": [
            8359
        ]
    },
    "Boris": {
        "8_17": [
            8361
        ]
    },
    "Ginsburg": {
        "8_17": [
            8362
        ]
    },
    "K": {
        "8_17": [
            8368
        ]
    },
    "Address": {
        "8_17": [
            8379
        ]
    },
    "correspondence": {
        "8_17": [
            8381
        ]
    },
    "popel": {
        "8_17": [
            8384
        ]
    },
    "Malostransk": {
        "8_17": [
            8402
        ]
    },
    "nmest": {
        "8_17": [
            8403
        ]
    },
    "Praha": {
        "8_17": [
            8404
        ]
    }
}